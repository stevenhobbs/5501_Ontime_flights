{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "\n",
    "from keras import layers, models, Sequential, regularizers\n",
    "from keras.layers import SimpleRNN, Dense, Dropout, Embedding, LSTM, GRU\n",
    "from keras.optimizers.legacy import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data & column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA_PATH = \"data.v3/daily\" \n",
    "\n",
    "df = pd.read_parquet(os.path.join(DAILY_DATA_PATH, \"daily_flights_and_weather_merged.parquet\"))\n",
    "\n",
    "# Flights column groups\n",
    "flights_terminal_cols = ['flights_arr_A', 'flights_arr_B', 'flights_arr_C', 'flights_arr_D', 'flights_arr_E',\n",
    "                         'flights_dep_A', 'flights_dep_B', 'flights_dep_C', 'flights_dep_D', 'flights_dep_E']\n",
    "\n",
    "flights_non_terminal_cols = ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime',\n",
    "                             'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel',\n",
    "                             'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel']\n",
    "\n",
    "flights_percentage_cols = ['flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct',\n",
    "                            'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct',\n",
    "                            'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
    "\n",
    "# Date column groups\n",
    "date_cols = ['date', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day']\n",
    "\n",
    "# Weather column groups\n",
    "weather_cols = ['wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction']\n",
    "\n",
    "# Lag column groups\n",
    "lag_cols =  ['flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7',\n",
    "             'flights_delay_lag_1', 'flights_delay_lag_2', 'flights_delay_lag_3', 'flights_delay_lag_4', 'flights_delay_lag_5', 'flights_delay_lag_6', 'flights_delay_lag_7',\n",
    "             'flights_ontime_lag_1', 'flights_ontime_lag_2', 'flights_ontime_lag_3', 'flights_ontime_lag_4', 'flights_ontime_lag_5', 'flights_ontime_lag_6', 'flights_ontime_lag_7',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split - \"flights_ontime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full shape: (1516, 54)\n",
      "y_train_full shape: (1516,)\n",
      "X_train shape: (1364, 54)\n",
      "y_train shape: (1364,)\n",
      "X_Test shape: (169, 54)\n",
      "y_Test shape: (169,)\n"
     ]
    }
   ],
   "source": [
    "# Select features and targets\n",
    "train_features = ['random'] + date_cols + weather_cols + lag_cols\n",
    "targets = flights_non_terminal_cols + flights_percentage_cols\n",
    "\n",
    "# Create X and y\n",
    "X = df[train_features].drop('date', axis=1)\n",
    "y = df[targets]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y['flights_ontime'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Split data into X_train_rull and y_train_full into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes\n",
    "print(\"X_train_full shape:\", X_train_full.shape)\n",
    "print(\"y_train_full shape:\", y_train_full.shape)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_Test shape:\", X_test.shape)\n",
    "print(\"y_Test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS FOR DENSE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['random', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day', 'wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7', 'flights_delay_lag_1', 'flights_delay_lag_2', 'flights_delay_lag_3', 'flights_delay_lag_4', 'flights_delay_lag_5', 'flights_delay_lag_6', 'flights_delay_lag_7', 'flights_ontime_lag_1', 'flights_ontime_lag_2', 'flights_ontime_lag_3', 'flights_ontime_lag_4', 'flights_ontime_lag_5', 'flights_ontime_lag_6', 'flights_ontime_lag_7']\n",
      "Target columns: ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime', 'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel', 'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel', 'flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct', 'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct', 'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
      "\n",
      "Unique data types in X\n",
      "float64    30\n",
      "object     11\n",
      "int64       7\n",
      "float32     4\n",
      "int32       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns to one-hot-encode: ['covid', 'month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "print(f\"Target columns: {y.columns.tolist()}\", end=\"\\n\\n\")\n",
    "print(\"Unique data types in X\", X.dtypes.value_counts(), sep = '\\n')\n",
    "\n",
    "# Identify categorical and numeric columns in X\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include = ['float64', 'float32', 'int32', 'int64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns to one-hot-encode: {categorical_cols}\")\n",
    "\n",
    "# Fit transformers to the training data\n",
    "f_scaler = StandardScaler()\n",
    "f_scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # Some observed holidays may not be in the training data\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "t_scaler = StandardScaler()\n",
    "t_scaler.fit(y_train.values.reshape(-1, 1)) # reshape y_train to be 2D\n",
    "\n",
    "# Define preprocessor\n",
    "def preprocess(features, target, set_global_scaler = False):\n",
    "    global global_targer_scaler\n",
    "\n",
    "    scaled_features = f_scaler.transform(features[numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1))\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "\n",
    "    if set_global_scaler:\n",
    "        global_targer_scaler = t_scaler\n",
    "\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_d, y_train_d = preprocess(X_train, y_train, set_global_scaler=True)\n",
    "X_val_d, y_val_d = preprocess(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-NEURON \"LINEAR MODEL\"\n",
    "\n",
    "The goal of this section is to simulate linear regression using a neural newtork with one neuron and no activation function. I'll use L1 and L2 regularization to simulate elastic net regression and compare results to those found in 3.daily_linear_regression.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow datasets\n",
    "train_ds_flights_ontime_d = Dataset.from_tensor_slices((X_train_d, y_train_d)).shuffle(len(X_train_d))\n",
    "val_ds_flights_ontime_d = Dataset.from_tensor_slices((X_val_d, y_val_d)).shuffle(len(X_val_d))\n",
    "\n",
    "# Batch and prefetch\n",
    "batch_size = 32\n",
    "train_ds_flights_ontime_d = train_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n",
    "val_ds_flights_ontime_d = val_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create R-squared metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    y_true_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_true], tf.float32)\n",
    "    y_pred_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_pred], tf.float32)\n",
    "    SS_res =  K.sum(K.square(y_true_inv - y_pred_inv)) \n",
    "    SS_tot = K.sum(K.square(y_true_inv - K.mean(y_true_inv))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    l1_regularization = hp.Float('l1_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(units = 1, \n",
    "            input_dim=X_train_d.shape[1], \n",
    "            kernel_regularizer=L1L2(l1_regularization, l2_regularization))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one-neuron hyperparameters using Keras random search tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks & Tensorboard Setup\n",
    "early_stopping_1n_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Create a Keras Tuner\n",
    "OneNeuron_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory='logs/flights_ontime/dense_lr/',\n",
    "    project_name='tuner',\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 06s]\n",
      "val_loss: 0.41847823560237885\n",
      "\n",
      "Best val_loss So Far: 0.4020496606826782\n",
      "Total elapsed time: 00h 16m 12s\n"
     ]
    }
   ],
   "source": [
    "# Search for best hyperparameters\n",
    "OneNeuron_tuner_RS.search(train_ds_flights_ontime_d, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             callbacks=[early_stopping_1n_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best 3 one-model fits: hyperparameters and validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in logs/flights_ontime/dense_lr/tuner\n",
      "Showing 3 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 019 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.009929423316917789\n",
      "l1_regularization: 1.3613167506559008e-05\n",
      "l2_regularization: 0.00012991522868696756\n",
      "Score: 0.4020496606826782\n",
      "\n",
      "Trial 059 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.004606695421104385\n",
      "l1_regularization: 0.00029860952692165044\n",
      "l2_regularization: 5.808762353159573e-05\n",
      "Score: 0.4038938581943512\n",
      "\n",
      "Trial 054 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0006717233174087713\n",
      "l1_regularization: 9.528015594093438e-05\n",
      "l2_regularization: 0.00024633112762105513\n",
      "Score: 0.4060898572206497\n"
     ]
    }
   ],
   "source": [
    "OneNeuron_tuner_RS.results_summary(num_trials=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save best one-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Tensorboard setup\n",
    "!rm -rf ./logs/flights_ontime/OneNeuron/tensorboard/ \n",
    "log_dir = \"logs/flights_ontime/OneNeuron/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_best = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneNeuron_LR_model = OneNeuron_tuner_RS.hypermodel.build(best_hps)\n",
    "history = OneNeuron_LR_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneNeuron_LR_model.save('models/flights_ontime/OneNeuron_LR_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TensorBoard for best 1-neuron model\n",
    "The TensorBoard dashboard shows plots generated from training logs that provide insight into the training of a model. \n",
    "\n",
    "The time series tab shows several plots within expandable windows for our one-neuronal model, \"dense_#\" and for the loss and training metrics by epoch.  Under dense_#, TesnorBoard shows histograms of the bias values \"bias_0\" and weight values, \"kernel_0\" by epoch. The epoch number is on the y-axis with the first epochs at the top and the most recent epoch at the bottom. These plots show how the bias and weight distributions change with training. For the one-neuron model, the weights appear to stabilize well before the training ended, at around 50 to 60 epochs, while the bias terms continued to drift downwards with training.\n",
    "\n",
    "The other plots under Time Series show how the loss and metrics change with training epoch or iteration (batch number). Based on these plots, the one-neuron model appears to have high bias and high variance. High bias is indicated by the large difference in loss and performance metrics between the train and validation datasets. High variance is indicated by the large variation in the validation loss, mae, and r-squared metrics that persists through training, even after these metrics stabilize on the training set at around epoch 40. Taken together, the one-neuron model appears to lack flexibility and would also benefit from having more data to train the weights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 3470), started 23:22:38 ago. (Use '!kill 3470' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4c9a5a16167bf48b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4c9a5a16167bf48b\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneNeuron/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evalute the best 1-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 584us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 117.60\n",
      "- Validation MSE: 31933.98\n",
      "- Validation R^2: 0.688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "OneNeuron_LR_model = models.load_model('models/flights_ontime/OneNeuron_LR_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneNeuron_LR_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "OneNeuron_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneNeuron_val_mae:.2f}\n",
    "- Validation MSE: {OneNeuron_val_mse:.2f}\n",
    "- Validation R^2: {OneNeuron_val_r2:.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW DENSE NEURAL NETWORK (SDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SDNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_input_neurons = hp.Int('n_input_neurons', min_value=4, max_value=16, default=8)\n",
    "    n_hidden_neurons = hp.Int('n_hidden_neurons', min_value=4, max_value=16, default=8)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.02, max_value=0.03, default=0.0)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    model.add(Dense(units=n_input_neurons, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=L2(l2_regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Hidden layer\n",
    "    model.add(Dense(units=n_hidden_neurons, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=L2(l2_regularization)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 05s]\n",
      "val_loss: 0.4497844725847244\n",
      "\n",
      "Best val_loss So Far: 0.38925886154174805\n",
      "Total elapsed time: 00h 11m 41s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_BO = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_BO = kt.BayesianOptimization(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    num_initial_points=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"bayesian_optimization_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_BO.search(train_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             callbacks=[early_stopping_BO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using random search\n",
    "In the interest of time, I didn't use the random search tuner on the last training run. This approach consistently underperformed compared to Bayesian optimization and hyperband."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# SDNN_tuner_RS = kt.RandomSearch(\n",
    "#     hypermodel = build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_trials=100,\n",
    "#     executions_per_trial=2,\n",
    "#     directory = \"logs/flights_ontime/SDNN\",\n",
    "#     project_name = \"random_search_tuner\",\n",
    "#     overwrite=True\n",
    "# )\n",
    "\n",
    "# SDNN_tuner_RS.search(train_ds_flights_ontime_d,\n",
    "#                 epochs=500, \n",
    "#                 validation_data=val_ds_flights_ontime_d, \n",
    "#                 callbacks=[early_stopping_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for best SDNN model using hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 02s]\n",
      "val_loss: 0.44303569197654724\n",
      "\n",
      "Best val_loss So Far: 0.3603585958480835\n",
      "Total elapsed time: 00h 21m 51s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_HB = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"hyperband_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_HB.search(train_ds_flights_ontime_d,\n",
    "                epochs=600, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_HB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best SDNN model (from hyperband search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters from Hyperband tuner\n",
    "best_hps = SDNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Initialize Early Stopping\n",
    "early_stopping_SDNN_best = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/SDNN_HB/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/SDNN_HB/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "SDNN_model = SDNN_tuner_HB.hypermodel.build(best_hps)\n",
    "history = SDNN_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_SDNN_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "SDNN_model.save('models/flights_ontime/SDNN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 27548), started 23:29:38 ago. (Use '!kill 27548' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c430a06c5f662c70\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c430a06c5f662c70\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard\n",
    "%tensorboard --logdir logs/flights_ontime/SDNN_HB/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 8\n",
      "- Learning Rate: 0.006415517608465564\n",
      "- Dropout Rate: 0.024849650762982137\n",
      "- L2 Regularization: 0.0007243411260176605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "SDNN_model = models.load_model('models/flights_ontime/SDNN_model')\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- L2 Regularization: {best_hps.get('l2_regularization')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 13)                1261      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 112       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1382 (5.40 KB)\n",
      "Trainable params: 1382 (5.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SDNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 117.43\n",
      "- Validation MSE: 33070.08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inverse transform the predicted values and get validation MAE, MSE\n",
    "y_pred = SDNN_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "SDNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "SDNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {SDNN_val_mae:.2f}\n",
    "- Validation MSE: {SDNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECURRENT NEURAL NETWORK (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lag variables from X train, val, and test sets\n",
    "The lag variables are redundant with the recurrent loops of an RNN that feed historical information into each neuron. I dropped the lag variables to reduce the redundancy and dimensionality in the RNN datasets. However, the lag variables may have value in an RNN despite introducing redundancy and multicolinearity. Time permitting, I'll retain the lag variables and train the RNN's a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_X_train_full = X_train_full.drop(lag_cols, axis=1)\n",
    "rnn_X_train = X_train.drop(lag_cols, axis=1)\n",
    "rnn_X_val = X_val.drop(lag_cols, axis=1)\n",
    "rnn_X_test = X_test.drop(lag_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN column transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_numeric_cols = [col for col in numeric_cols if col not in lag_cols]\n",
    "\n",
    "# Fit transformers to the training data\n",
    "rnn_f_scaler = StandardScaler()\n",
    "rnn_f_scaler.fit(rnn_X_train[rnn_numeric_cols])\n",
    "\n",
    "# Create a function to preprocess TensorFlow datasets\n",
    "def rnn_preprocess(features, target):\n",
    "    scaled_features = rnn_f_scaler.transform(features[rnn_numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1)) # Scaling the target can speed up training, improve convergence, and reduce the impact of outliers for RNNs\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Transform the data\n",
    "X_train_rnn, y_train_rnn = rnn_preprocess(X_train, y_train)\n",
    "X_val_rnn, y_val_rnn = rnn_preprocess(X_val, y_val)\n",
    "X_test_rnn, y_test_rnn = rnn_preprocess(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create timeseries datasets\n",
    "\n",
    "The timeseries datasets below use a sequence length of 7 and a time step of 1. Each recurrent neuron will process the sequences in 7 recurrent steps, updating its hidden state based on the current input and the previous hidden state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "seq_length = 7\n",
    "batch_size = 32\n",
    "\n",
    "train_rnn = timeseries_dataset_from_array(\n",
    "    data = X_train_rnn, \n",
    "    targets = y_train_rnn,\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "val_rnn = timeseries_dataset_from_array(\n",
    "    data = X_val_rnn, \n",
    "    targets = y_val_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_rnn = timeseries_dataset_from_array(\n",
    "    data = X_test_rnn, \n",
    "    targets = y_test_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE RECURRENT NEURON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron RNN hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build one-neuron RNN hypermodel\n",
    "def OneRNN_model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units = 1, \n",
    "                  input_shape = (None, X_train_rnn.shape[1]), \n",
    "                  kernel_regularizer=L2(kernel_reg),\n",
    "                  recurrent_regularizer=L2(recurr_reg),\n",
    "                  )\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 05s]\n",
      "val_loss: 1.3041276931762695\n",
      "\n",
      "Best val_loss So Far: 1.1027542352676392\n",
      "Total elapsed time: 00h 05m 33s\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Hyperband tuner\n",
    "OneRNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = OneRNN_model_builder,\n",
    "    objective='val_loss',\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory='logs/flights_ontime/OneRNN',\n",
    "    project_name='hyperband_tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneRNN_tuner_HB.search(train_rnn, \n",
    "             validation_data=val_rnn, \n",
    "             epochs=50, \n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best one-neuron RNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "best_hps = OneRNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneRNN_model = OneRNN_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/OneRNN/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/OneRNN/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = OneRNN_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneRNN_model.save('models/flights_ontime/OneRNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 41285), started 0:00:05 ago. (Use '!kill 41285' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ea377e98d930e2ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ea377e98d930e2ca\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneRNN/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evaluate the best one-neuron RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 248.49\n",
      "- Validation MSE: 109553.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OneRNN_model = models.load_model('models/flights_ontime/OneRNN_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneRNN_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "OneRNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneRNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneRNN_val_mae:.2f}\n",
    "- Validation MSE: {OneRNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build shallow RNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    recurrent_dropout_rate = hp.Float('recurrent_dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    model.add(SimpleRNN(units=n_neurons,\n",
    "                        activation='tanh', \n",
    "                        return_sequences=False,\n",
    "                        kernel_regularizer=L2(kernel_reg),\n",
    "                        recurrent_regularizer=L2(recurr_reg),\n",
    "                        dropout = dropout_rate,\n",
    "                        recurrent_dropout = recurrent_dropout_rate))\n",
    "    \n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using a random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN_shallow_tuner_RS = kt.RandomSearch(\n",
    "#     build_model,\n",
    "#     objective='val_loss',\n",
    "#     max_trials=100,\n",
    "#     overwrite=True\n",
    "# )\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# RNN_shallow_tuner_RS.search(train_rnn, epochs=500, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 07s]\n",
      "val_loss: 1.3063130378723145\n",
      "\n",
      "Best val_loss So Far: 1.1599246263504028\n",
      "Total elapsed time: 00h 13m 04s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_BO = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    num_initial_points=2,\n",
    "    overwrite=True\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_BO.search(train_rnn, epochs=50, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Hyperband tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 689 Complete [00h 00m 10s]\n",
      "val_loss: 1.3770010471343994\n",
      "\n",
      "Best val_loss So Far: 1.124523639678955\n",
      "Total elapsed time: 01h 09m 43s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_HB = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=200,\n",
    "    factor=2,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_HB.search(train_rnn, \n",
    "                            epochs=200, \n",
    "                            validation_data=val_rnn, \n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save the best shallow RNN model\n",
    "The Hyperband tuner produced the best model based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "43/43 [==============================] - 1s 5ms/step - loss: 1.2611 - mean_absolute_error: 0.8335 - val_loss: 1.5629 - val_mean_absolute_error: 0.8765\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1531 - mean_absolute_error: 0.8097 - val_loss: 1.4719 - val_mean_absolute_error: 0.8568\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1014 - mean_absolute_error: 0.7794 - val_loss: 1.4003 - val_mean_absolute_error: 0.8181\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0665 - mean_absolute_error: 0.7649 - val_loss: 1.3524 - val_mean_absolute_error: 0.8220\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0247 - mean_absolute_error: 0.7550 - val_loss: 1.3243 - val_mean_absolute_error: 0.8314\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0218 - mean_absolute_error: 0.7637 - val_loss: 1.3088 - val_mean_absolute_error: 0.8355\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0215 - mean_absolute_error: 0.7605 - val_loss: 1.2987 - val_mean_absolute_error: 0.8373\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0127 - mean_absolute_error: 0.7630 - val_loss: 1.2929 - val_mean_absolute_error: 0.8397\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9994 - mean_absolute_error: 0.7565 - val_loss: 1.2896 - val_mean_absolute_error: 0.8415\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0058 - mean_absolute_error: 0.7612 - val_loss: 1.2875 - val_mean_absolute_error: 0.8426\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0096 - mean_absolute_error: 0.7643 - val_loss: 1.2851 - val_mean_absolute_error: 0.8439\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9996 - mean_absolute_error: 0.7605 - val_loss: 1.2851 - val_mean_absolute_error: 0.8448\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0036 - mean_absolute_error: 0.7623 - val_loss: 1.2835 - val_mean_absolute_error: 0.8458\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9992 - mean_absolute_error: 0.7610 - val_loss: 1.2832 - val_mean_absolute_error: 0.8448\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9987 - mean_absolute_error: 0.7568 - val_loss: 1.2834 - val_mean_absolute_error: 0.8448\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0008 - mean_absolute_error: 0.7582 - val_loss: 1.2818 - val_mean_absolute_error: 0.8469\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9992 - mean_absolute_error: 0.7602 - val_loss: 1.2823 - val_mean_absolute_error: 0.8453\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9966 - mean_absolute_error: 0.7559 - val_loss: 1.2831 - val_mean_absolute_error: 0.8440\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9918 - mean_absolute_error: 0.7562 - val_loss: 1.2818 - val_mean_absolute_error: 0.8455\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0054 - mean_absolute_error: 0.7609 - val_loss: 1.2826 - val_mean_absolute_error: 0.8441\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9993 - mean_absolute_error: 0.7600 - val_loss: 1.2807 - val_mean_absolute_error: 0.8465\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9993 - mean_absolute_error: 0.7570 - val_loss: 1.2812 - val_mean_absolute_error: 0.8455\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9953 - mean_absolute_error: 0.7563 - val_loss: 1.2815 - val_mean_absolute_error: 0.8437\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9967 - mean_absolute_error: 0.7550 - val_loss: 1.2804 - val_mean_absolute_error: 0.8448\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9978 - mean_absolute_error: 0.7573 - val_loss: 1.2789 - val_mean_absolute_error: 0.8463\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0014 - mean_absolute_error: 0.7584 - val_loss: 1.2788 - val_mean_absolute_error: 0.8465\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9985 - mean_absolute_error: 0.7609 - val_loss: 1.2784 - val_mean_absolute_error: 0.8472\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9907 - mean_absolute_error: 0.7559 - val_loss: 1.2802 - val_mean_absolute_error: 0.8446\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9992 - mean_absolute_error: 0.7592 - val_loss: 1.2796 - val_mean_absolute_error: 0.8453\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9928 - mean_absolute_error: 0.7558 - val_loss: 1.2798 - val_mean_absolute_error: 0.8446\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7546 - val_loss: 1.2796 - val_mean_absolute_error: 0.8463\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9998 - mean_absolute_error: 0.7634 - val_loss: 1.2798 - val_mean_absolute_error: 0.8459\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0002 - mean_absolute_error: 0.7612 - val_loss: 1.2801 - val_mean_absolute_error: 0.8448\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9915 - mean_absolute_error: 0.7573 - val_loss: 1.2795 - val_mean_absolute_error: 0.8443\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9972 - mean_absolute_error: 0.7575 - val_loss: 1.2786 - val_mean_absolute_error: 0.8441\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9884 - mean_absolute_error: 0.7530 - val_loss: 1.2775 - val_mean_absolute_error: 0.8439\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7583 - val_loss: 1.2763 - val_mean_absolute_error: 0.8446\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9915 - mean_absolute_error: 0.7585 - val_loss: 1.2745 - val_mean_absolute_error: 0.8465\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9945 - mean_absolute_error: 0.7577 - val_loss: 1.2761 - val_mean_absolute_error: 0.8425\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9843 - mean_absolute_error: 0.7523 - val_loss: 1.2757 - val_mean_absolute_error: 0.8438\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7557 - val_loss: 1.2744 - val_mean_absolute_error: 0.8436\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9917 - mean_absolute_error: 0.7588 - val_loss: 1.2736 - val_mean_absolute_error: 0.8424\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9893 - mean_absolute_error: 0.7552 - val_loss: 1.2735 - val_mean_absolute_error: 0.8426\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9875 - mean_absolute_error: 0.7549 - val_loss: 1.2738 - val_mean_absolute_error: 0.8429\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9901 - mean_absolute_error: 0.7561 - val_loss: 1.2744 - val_mean_absolute_error: 0.8443\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9911 - mean_absolute_error: 0.7573 - val_loss: 1.2757 - val_mean_absolute_error: 0.8462\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9986 - mean_absolute_error: 0.7607 - val_loss: 1.2756 - val_mean_absolute_error: 0.8458\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9916 - mean_absolute_error: 0.7573 - val_loss: 1.2757 - val_mean_absolute_error: 0.8461\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9855 - mean_absolute_error: 0.7557 - val_loss: 1.2748 - val_mean_absolute_error: 0.8439\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9904 - mean_absolute_error: 0.7562 - val_loss: 1.2751 - val_mean_absolute_error: 0.8450\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9851 - mean_absolute_error: 0.7530 - val_loss: 1.2765 - val_mean_absolute_error: 0.8440\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9880 - mean_absolute_error: 0.7552 - val_loss: 1.2774 - val_mean_absolute_error: 0.8443\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9902 - mean_absolute_error: 0.7554 - val_loss: 1.2766 - val_mean_absolute_error: 0.8430\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9889 - mean_absolute_error: 0.7584 - val_loss: 1.2767 - val_mean_absolute_error: 0.8453\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9889 - mean_absolute_error: 0.7533 - val_loss: 1.2780 - val_mean_absolute_error: 0.8449\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9956 - mean_absolute_error: 0.7572 - val_loss: 1.2762 - val_mean_absolute_error: 0.8398\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9867 - mean_absolute_error: 0.7553 - val_loss: 1.2745 - val_mean_absolute_error: 0.8442\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9889 - mean_absolute_error: 0.7560 - val_loss: 1.2741 - val_mean_absolute_error: 0.8423\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9876 - mean_absolute_error: 0.7537 - val_loss: 1.2726 - val_mean_absolute_error: 0.8407\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9852 - mean_absolute_error: 0.7560 - val_loss: 1.2728 - val_mean_absolute_error: 0.8439\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9898 - mean_absolute_error: 0.7573 - val_loss: 1.2727 - val_mean_absolute_error: 0.8440\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9872 - mean_absolute_error: 0.7579 - val_loss: 1.2743 - val_mean_absolute_error: 0.8432\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9900 - mean_absolute_error: 0.7579 - val_loss: 1.2731 - val_mean_absolute_error: 0.8425\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9869 - mean_absolute_error: 0.7555 - val_loss: 1.2729 - val_mean_absolute_error: 0.8432\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9804 - mean_absolute_error: 0.7548 - val_loss: 1.2738 - val_mean_absolute_error: 0.8427\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9851 - mean_absolute_error: 0.7525 - val_loss: 1.2745 - val_mean_absolute_error: 0.8430\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7557 - val_loss: 1.2733 - val_mean_absolute_error: 0.8422\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9863 - mean_absolute_error: 0.7544 - val_loss: 1.2746 - val_mean_absolute_error: 0.8434\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9880 - mean_absolute_error: 0.7588 - val_loss: 1.2753 - val_mean_absolute_error: 0.8441\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9864 - mean_absolute_error: 0.7572 - val_loss: 1.2748 - val_mean_absolute_error: 0.8430\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9844 - mean_absolute_error: 0.7561 - val_loss: 1.2738 - val_mean_absolute_error: 0.8409\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9751 - mean_absolute_error: 0.7480 - val_loss: 1.2742 - val_mean_absolute_error: 0.8421\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9823 - mean_absolute_error: 0.7544 - val_loss: 1.2760 - val_mean_absolute_error: 0.8427\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9819 - mean_absolute_error: 0.7548 - val_loss: 1.2779 - val_mean_absolute_error: 0.8401\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9907 - mean_absolute_error: 0.7567 - val_loss: 1.2756 - val_mean_absolute_error: 0.8434\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9775 - mean_absolute_error: 0.7508 - val_loss: 1.2750 - val_mean_absolute_error: 0.8396\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9852 - mean_absolute_error: 0.7538 - val_loss: 1.2704 - val_mean_absolute_error: 0.8417\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9876 - mean_absolute_error: 0.7560 - val_loss: 1.2702 - val_mean_absolute_error: 0.8384\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9846 - mean_absolute_error: 0.7531 - val_loss: 1.2704 - val_mean_absolute_error: 0.8363\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9854 - mean_absolute_error: 0.7532 - val_loss: 1.2706 - val_mean_absolute_error: 0.8401\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9889 - mean_absolute_error: 0.7601 - val_loss: 1.2689 - val_mean_absolute_error: 0.8416\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9888 - mean_absolute_error: 0.7578 - val_loss: 1.2694 - val_mean_absolute_error: 0.8406\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9750 - mean_absolute_error: 0.7519 - val_loss: 1.2689 - val_mean_absolute_error: 0.8409\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9898 - mean_absolute_error: 0.7550 - val_loss: 1.2691 - val_mean_absolute_error: 0.8396\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9863 - mean_absolute_error: 0.7570 - val_loss: 1.2689 - val_mean_absolute_error: 0.8417\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9835 - mean_absolute_error: 0.7533 - val_loss: 1.2691 - val_mean_absolute_error: 0.8382\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9853 - mean_absolute_error: 0.7535 - val_loss: 1.2673 - val_mean_absolute_error: 0.8410\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9812 - mean_absolute_error: 0.7541 - val_loss: 1.2684 - val_mean_absolute_error: 0.8405\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9836 - mean_absolute_error: 0.7526 - val_loss: 1.2695 - val_mean_absolute_error: 0.8398\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7542 - val_loss: 1.2706 - val_mean_absolute_error: 0.8392\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9753 - mean_absolute_error: 0.7511 - val_loss: 1.2712 - val_mean_absolute_error: 0.8404\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9810 - mean_absolute_error: 0.7515 - val_loss: 1.2703 - val_mean_absolute_error: 0.8358\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9788 - mean_absolute_error: 0.7552 - val_loss: 1.2685 - val_mean_absolute_error: 0.8386\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9816 - mean_absolute_error: 0.7524 - val_loss: 1.2690 - val_mean_absolute_error: 0.8377\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9809 - mean_absolute_error: 0.7561 - val_loss: 1.2687 - val_mean_absolute_error: 0.8389\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9787 - mean_absolute_error: 0.7542 - val_loss: 1.2696 - val_mean_absolute_error: 0.8364\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9708 - mean_absolute_error: 0.7473 - val_loss: 1.2704 - val_mean_absolute_error: 0.8344\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9808 - mean_absolute_error: 0.7509 - val_loss: 1.2669 - val_mean_absolute_error: 0.8349\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9874 - mean_absolute_error: 0.7557 - val_loss: 1.2671 - val_mean_absolute_error: 0.8368\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9809 - mean_absolute_error: 0.7546 - val_loss: 1.2656 - val_mean_absolute_error: 0.8372\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9815 - mean_absolute_error: 0.7523 - val_loss: 1.2668 - val_mean_absolute_error: 0.8368\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9914 - mean_absolute_error: 0.7590 - val_loss: 1.2675 - val_mean_absolute_error: 0.8369\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9810 - mean_absolute_error: 0.7503 - val_loss: 1.2655 - val_mean_absolute_error: 0.8379\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9752 - mean_absolute_error: 0.7516 - val_loss: 1.2650 - val_mean_absolute_error: 0.8379\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9770 - mean_absolute_error: 0.7497 - val_loss: 1.2674 - val_mean_absolute_error: 0.8397\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9868 - mean_absolute_error: 0.7538 - val_loss: 1.2678 - val_mean_absolute_error: 0.8346\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9736 - mean_absolute_error: 0.7497 - val_loss: 1.2691 - val_mean_absolute_error: 0.8388\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9801 - mean_absolute_error: 0.7523 - val_loss: 1.2684 - val_mean_absolute_error: 0.8379\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9814 - mean_absolute_error: 0.7506 - val_loss: 1.2686 - val_mean_absolute_error: 0.8347\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9732 - mean_absolute_error: 0.7490 - val_loss: 1.2647 - val_mean_absolute_error: 0.8355\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9789 - mean_absolute_error: 0.7547 - val_loss: 1.2653 - val_mean_absolute_error: 0.8342\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9765 - mean_absolute_error: 0.7516 - val_loss: 1.2652 - val_mean_absolute_error: 0.8362\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9801 - mean_absolute_error: 0.7511 - val_loss: 1.2664 - val_mean_absolute_error: 0.8327\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9875 - mean_absolute_error: 0.7552 - val_loss: 1.2663 - val_mean_absolute_error: 0.8352\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9788 - mean_absolute_error: 0.7542 - val_loss: 1.2666 - val_mean_absolute_error: 0.8340\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9829 - mean_absolute_error: 0.7546 - val_loss: 1.2657 - val_mean_absolute_error: 0.8335\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9846 - mean_absolute_error: 0.7560 - val_loss: 1.2649 - val_mean_absolute_error: 0.8330\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9804 - mean_absolute_error: 0.7516 - val_loss: 1.2659 - val_mean_absolute_error: 0.8346\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9744 - mean_absolute_error: 0.7533 - val_loss: 1.2682 - val_mean_absolute_error: 0.8373\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9815 - mean_absolute_error: 0.7557 - val_loss: 1.2687 - val_mean_absolute_error: 0.8359\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9821 - mean_absolute_error: 0.7515 - val_loss: 1.2689 - val_mean_absolute_error: 0.8344\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9781 - mean_absolute_error: 0.7563 - val_loss: 1.2681 - val_mean_absolute_error: 0.8382\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9852 - mean_absolute_error: 0.7555 - val_loss: 1.2701 - val_mean_absolute_error: 0.8383\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9709 - mean_absolute_error: 0.7479 - val_loss: 1.2709 - val_mean_absolute_error: 0.8367\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9892 - mean_absolute_error: 0.7582 - val_loss: 1.2698 - val_mean_absolute_error: 0.8367\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9788 - mean_absolute_error: 0.7536 - val_loss: 1.2654 - val_mean_absolute_error: 0.8351\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9732 - mean_absolute_error: 0.7505 - val_loss: 1.2650 - val_mean_absolute_error: 0.8364\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9782 - mean_absolute_error: 0.7503 - val_loss: 1.2681 - val_mean_absolute_error: 0.8351\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9709 - mean_absolute_error: 0.7515 - val_loss: 1.2674 - val_mean_absolute_error: 0.8333\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9803 - mean_absolute_error: 0.7530 - val_loss: 1.2652 - val_mean_absolute_error: 0.8328\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9705 - mean_absolute_error: 0.7521 - val_loss: 1.2636 - val_mean_absolute_error: 0.8370\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9808 - mean_absolute_error: 0.7558 - val_loss: 1.2654 - val_mean_absolute_error: 0.8330\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9828 - mean_absolute_error: 0.7517 - val_loss: 1.2681 - val_mean_absolute_error: 0.8364\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9811 - mean_absolute_error: 0.7548 - val_loss: 1.2694 - val_mean_absolute_error: 0.8355\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9907 - mean_absolute_error: 0.7565 - val_loss: 1.2667 - val_mean_absolute_error: 0.8357\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9823 - mean_absolute_error: 0.7528 - val_loss: 1.2669 - val_mean_absolute_error: 0.8374\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9780 - mean_absolute_error: 0.7513 - val_loss: 1.2673 - val_mean_absolute_error: 0.8341\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9783 - mean_absolute_error: 0.7525 - val_loss: 1.2676 - val_mean_absolute_error: 0.8350\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9871 - mean_absolute_error: 0.7519 - val_loss: 1.2666 - val_mean_absolute_error: 0.8367\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9804 - mean_absolute_error: 0.7550 - val_loss: 1.2666 - val_mean_absolute_error: 0.8361\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9722 - mean_absolute_error: 0.7523 - val_loss: 1.2663 - val_mean_absolute_error: 0.8338\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9779 - mean_absolute_error: 0.7497 - val_loss: 1.2661 - val_mean_absolute_error: 0.8317\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9834 - mean_absolute_error: 0.7514 - val_loss: 1.2658 - val_mean_absolute_error: 0.8351\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9754 - mean_absolute_error: 0.7489 - val_loss: 1.2670 - val_mean_absolute_error: 0.8343\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9811 - mean_absolute_error: 0.7588 - val_loss: 1.2678 - val_mean_absolute_error: 0.8355\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9759 - mean_absolute_error: 0.7531 - val_loss: 1.2686 - val_mean_absolute_error: 0.8337\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9804 - mean_absolute_error: 0.7517 - val_loss: 1.2712 - val_mean_absolute_error: 0.8340\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9699 - mean_absolute_error: 0.7507 - val_loss: 1.2712 - val_mean_absolute_error: 0.8349\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9792 - mean_absolute_error: 0.7550 - val_loss: 1.2672 - val_mean_absolute_error: 0.8333\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9777 - mean_absolute_error: 0.7529 - val_loss: 1.2676 - val_mean_absolute_error: 0.8341\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9794 - mean_absolute_error: 0.7529 - val_loss: 1.2671 - val_mean_absolute_error: 0.8350\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9829 - mean_absolute_error: 0.7528 - val_loss: 1.2664 - val_mean_absolute_error: 0.8318\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9822 - mean_absolute_error: 0.7521 - val_loss: 1.2652 - val_mean_absolute_error: 0.8370\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9795 - mean_absolute_error: 0.7558 - val_loss: 1.2665 - val_mean_absolute_error: 0.8336\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9762 - mean_absolute_error: 0.7521 - val_loss: 1.2662 - val_mean_absolute_error: 0.8352\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9852 - mean_absolute_error: 0.7539 - val_loss: 1.2671 - val_mean_absolute_error: 0.8353\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9833 - mean_absolute_error: 0.7539 - val_loss: 1.2686 - val_mean_absolute_error: 0.8354\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9799 - mean_absolute_error: 0.7530 - val_loss: 1.2673 - val_mean_absolute_error: 0.8351\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9794 - mean_absolute_error: 0.7514 - val_loss: 1.2661 - val_mean_absolute_error: 0.8358\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9757 - mean_absolute_error: 0.7531 - val_loss: 1.2667 - val_mean_absolute_error: 0.8321\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9809 - mean_absolute_error: 0.7539 - val_loss: 1.2667 - val_mean_absolute_error: 0.8317\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9784 - mean_absolute_error: 0.7539 - val_loss: 1.2678 - val_mean_absolute_error: 0.8319\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9775 - mean_absolute_error: 0.7550 - val_loss: 1.2645 - val_mean_absolute_error: 0.8307\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9833 - mean_absolute_error: 0.7573 - val_loss: 1.2641 - val_mean_absolute_error: 0.8337\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9793 - mean_absolute_error: 0.7524 - val_loss: 1.2647 - val_mean_absolute_error: 0.8314\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9729 - mean_absolute_error: 0.7527 - val_loss: 1.2639 - val_mean_absolute_error: 0.8319\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9835 - mean_absolute_error: 0.7592 - val_loss: 1.2652 - val_mean_absolute_error: 0.8320\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9802 - mean_absolute_error: 0.7535 - val_loss: 1.2655 - val_mean_absolute_error: 0.8315\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9791 - mean_absolute_error: 0.7557 - val_loss: 1.2686 - val_mean_absolute_error: 0.8353\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9840 - mean_absolute_error: 0.7517 - val_loss: 1.2707 - val_mean_absolute_error: 0.8347\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9803 - mean_absolute_error: 0.7536 - val_loss: 1.2718 - val_mean_absolute_error: 0.8344\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9738 - mean_absolute_error: 0.7497 - val_loss: 1.2715 - val_mean_absolute_error: 0.8352\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9851 - mean_absolute_error: 0.7557 - val_loss: 1.2691 - val_mean_absolute_error: 0.8363\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9745 - mean_absolute_error: 0.7497 - val_loss: 1.2704 - val_mean_absolute_error: 0.8335\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9732 - mean_absolute_error: 0.7490 - val_loss: 1.2700 - val_mean_absolute_error: 0.8340\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9747 - mean_absolute_error: 0.7502 - val_loss: 1.2690 - val_mean_absolute_error: 0.8352\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9778 - mean_absolute_error: 0.7510 - val_loss: 1.2670 - val_mean_absolute_error: 0.8345\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9804 - mean_absolute_error: 0.7546 - val_loss: 1.2684 - val_mean_absolute_error: 0.8334\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9767 - mean_absolute_error: 0.7550 - val_loss: 1.2696 - val_mean_absolute_error: 0.8350\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9858 - mean_absolute_error: 0.7556 - val_loss: 1.2694 - val_mean_absolute_error: 0.8349\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9763 - mean_absolute_error: 0.7513 - val_loss: 1.2689 - val_mean_absolute_error: 0.8335\n",
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = RNN_shallow_tuner_HB.get_best_hyperparameters(num_trials=1)[0]\n",
    "RNN_shallow_model = RNN_shallow_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# TensorBoard setup\n",
    "!rm -rf ./logs/flights_ontime/RNN_shallow/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/RNN_shallow/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = RNN_shallow_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback])\n",
    "\n",
    "# Save the best trained model\n",
    "RNN_shallow_model.save('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6013 (pid 49139), started 0:02:24 ago. (Use '!kill 49139' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-19c2c908334d8da9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-19c2c908334d8da9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/RNN_shallow/tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best shallow RNN model (from Hyperband tuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "RNN_shallow_model = models.load_model('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best shallow RNN model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Neurons: 1\n",
      "- Learning Rate: 0.002332058207624143\n",
      "- Dropout Rate: 0.2471209924895985\n",
      "- Recurrent Dropout Rate: 0.4440972042279873\n",
      "- Kernel Regularization: 0.00014973417105600966\n",
      "- Recurrent Regularization: 0.0003706212687198221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Recurrent Dropout Rate: {best_hps.get('recurrent_dropout_rate')}\n",
    "- Kernel Regularization: {best_hps.get('kernel_reg')}\n",
    "- Recurrent Regularization: {best_hps.get('recurr_reg')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 1)                 77        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79 (316.00 Byte)\n",
      "Trainable params: 79 (316.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best shallow RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 241.78\n",
      "- Validation MSE: 104769.82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = RNN_shallow_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "shallow_rnn_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {shallow_rnn_val_mae:.2f}\n",
    "- Validation MSE: {shallow_rnn_val_mse:.2f}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TYPE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the Elastic Net metrics\n",
    "EN_data = pd.read_csv(\"model_output/elastic_net_results.csv\")\n",
    "LR_mae = EN_data.loc[EN_data['TARGET'] == 'flights_ontime', 'MAE'].values[0]\n",
    "LR_mse = EN_data.loc[EN_data['TARGET'] == 'flights_ontime', 'MSE'].values[0]\n",
    "\n",
    "models = ['Linear Reg', 'One Neuron', 'Shallow NN', 'One RN', 'Shallow RNN']\n",
    "mae = [LR_mae, OneNeuron_val_mae, SDNN_val_mae,  OneRNN_val_mae, shallow_rnn_val_mae]\n",
    "mse = [LR_mse, OneNeuron_val_mse, SDNN_val_mse, OneRNN_val_mse, shallow_rnn_val_mse]\n",
    "\n",
    "# Sort by MAE\n",
    "sorted_indices_mae = np.argsort(mae)\n",
    "sorted_models_mae = [models[i] for i in sorted_indices_mae]\n",
    "sorted_mae = [mae[i] for i in sorted_indices_mae]\n",
    "\n",
    "# Sort by MSE\n",
    "sorted_indices_mse = np.argsort(mse)\n",
    "sorted_models_mse = [models[i] for i in sorted_indices_mse]\n",
    "sorted_mse = [mse[i] for i in sorted_indices_mse]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "bar_width = 0.35\n",
    "\n",
    "fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "\n",
    "# MAE\n",
    "bars_mae = axes[0].bar(x, sorted_mae, bar_width, label='MAE')\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('MAE Scores')\n",
    "axes[0].set_title('MAE Scores by model')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(sorted_models_mae)\n",
    "axes[0].legend()\n",
    "\n",
    "# Add values above MAE bars\n",
    "for bar, value in zip(bars_mae, sorted_mae):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width() / 2, height + 0.01, f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "# MSE\n",
    "bar_mse = axes[1].bar(x, sorted_mse, bar_width, label='MSE')\n",
    "axes[1].set_xlabel('Models')\n",
    "axes[1].set_ylabel('MSE Scores')\n",
    "axes[1].set_title('MSE Scores by model')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(sorted_models_mse)\n",
    "axes[1].legend()\n",
    "\n",
    "# Add values above MSE bars\n",
    "for bar, value in zip(bar_mse, sorted_mse):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width() / 2, height + 0.01, f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain the shuffle=True/False implications for prediction vs time series forecasting\n",
    "2. Switch to hourly data and split data into .9 /.05 /.05 to enable a better train/val/test split for time series forecasting?\n",
    "3. Add recent months to the flight and weather data (together)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-rTmYhf-l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
