{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "\n",
    "from keras import layers, models, Sequential, regularizers\n",
    "from keras.layers import SimpleRNN, Dense, Dropout, Embedding, LSTM, GRU\n",
    "from keras.optimizers.legacy import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data & column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA_PATH = \"data.v3/daily\" \n",
    "\n",
    "df = pd.read_parquet(os.path.join(DAILY_DATA_PATH, \"daily_flights_and_weather_merged.parquet\"))\n",
    "\n",
    "# Flights column groups\n",
    "flights_terminal_cols = ['flights_arr_A', 'flights_arr_B', 'flights_arr_C', 'flights_arr_D', 'flights_arr_E',\n",
    "                         'flights_dep_A', 'flights_dep_B', 'flights_dep_C', 'flights_dep_D', 'flights_dep_E']\n",
    "\n",
    "flights_non_terminal_cols = ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime',\n",
    "                             'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel',\n",
    "                             'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel']\n",
    "\n",
    "flights_percentage_cols = ['flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct',\n",
    "                            'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct',\n",
    "                            'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
    "\n",
    "# Date column groups\n",
    "date_cols = ['date', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day']\n",
    "\n",
    "# Weather column groups\n",
    "weather_cols = ['wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction']\n",
    "\n",
    "# Lag column groups\n",
    "lag_cols =  ['flights_total_lag_1', 'flights_total_lag_2', 'flights_total_lag_3', 'flights_total_lag_4', 'flights_total_lag_5', 'flights_total_lag_6', 'flights_total_lag_7', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split - \"flights_ontime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full shape: (1516, 47)\n",
      "y_train_full shape: (1516,)\n",
      "X_train shape: (1364, 47)\n",
      "y_train shape: (1364,)\n",
      "X_Test shape: (169, 47)\n",
      "y_Test shape: (169,)\n"
     ]
    }
   ],
   "source": [
    "# Select features and targets\n",
    "train_features = ['random'] + date_cols + weather_cols + lag_cols\n",
    "targets = flights_non_terminal_cols + flights_percentage_cols\n",
    "\n",
    "# Create X and y\n",
    "X = df[train_features].drop('date', axis=1)\n",
    "y = df[targets]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y['flights_ontime'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Split data into X_train_rull and y_train_full into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes\n",
    "print(\"X_train_full shape:\", X_train_full.shape)\n",
    "print(\"y_train_full shape:\", y_train_full.shape)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_Test shape:\", X_test.shape)\n",
    "print(\"y_Test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS FOR DENSE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['random', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day', 'wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction', 'flights_total_lag_1', 'flights_total_lag_2', 'flights_total_lag_3', 'flights_total_lag_4', 'flights_total_lag_5', 'flights_total_lag_6', 'flights_total_lag_7', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7']\n",
      "Target columns: ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime', 'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel', 'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel', 'flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct', 'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct', 'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
      "\n",
      "Unique data types in X\n",
      "float64    23\n",
      "object     11\n",
      "int64       7\n",
      "float32     4\n",
      "int32       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns to one-hot-encode: ['covid', 'month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "print(f\"Target columns: {y.columns.tolist()}\", end=\"\\n\\n\")\n",
    "print(\"Unique data types in X\", X.dtypes.value_counts(), sep = '\\n')\n",
    "\n",
    "# Identify categorical and numeric columns in X\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include = ['float64', 'float32', 'int32', 'int64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns to one-hot-encode: {categorical_cols}\")\n",
    "\n",
    "# Fit transformers to the training data\n",
    "f_scaler = StandardScaler()\n",
    "f_scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # Some observed holidays may not be in the training data\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "t_scaler = StandardScaler()\n",
    "t_scaler.fit(y_train.values.reshape(-1, 1)) # reshape y_train to be 2D\n",
    "\n",
    "# Define preprocessor\n",
    "def preprocess(features, target, set_global_scaler = False):\n",
    "    global global_targer_scaler\n",
    "\n",
    "    scaled_features = f_scaler.transform(features[numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1))\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "\n",
    "    if set_global_scaler:\n",
    "        global_targer_scaler = t_scaler\n",
    "\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_d, y_train_d = preprocess(X_train, y_train, set_global_scaler=True)\n",
    "X_val_d, y_val_d = preprocess(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-NEURON \"LINEAR MODEL\"\n",
    "\n",
    "The goal of this section is to simulate linear regression using a neural newtork with one neuron and no activation function. I'll use L1 and L2 regularization to simulate elastic net regression and compare results to those found in 3.daily_linear_regression.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow datasets\n",
    "train_ds_flights_ontime_d = Dataset.from_tensor_slices((X_train_d, y_train_d)).shuffle(len(X_train_d))\n",
    "val_ds_flights_ontime_d = Dataset.from_tensor_slices((X_val_d, y_val_d)).shuffle(len(X_val_d))\n",
    "\n",
    "# Batch and prefetch\n",
    "batch_size = 32\n",
    "train_ds_flights_ontime_d = train_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n",
    "val_ds_flights_ontime_d = val_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create R-squared metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    y_true_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_true], tf.float32)\n",
    "    y_pred_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_pred], tf.float32)\n",
    "    SS_res =  K.sum(K.square(y_true_inv - y_pred_inv)) \n",
    "    SS_tot = K.sum(K.square(y_true_inv - K.mean(y_true_inv))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    l1_regularization = hp.Float('l1_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(units = 1, \n",
    "            input_dim=X_train_d.shape[1], \n",
    "            kernel_regularizer=L1L2(l1_regularization, l2_regularization))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one-neuron hyperparameters using Keras random search tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 04s]\n",
      "val_loss: 0.4642547070980072\n",
      "\n",
      "Best val_loss So Far: 0.4110903888940811\n",
      "Total elapsed time: 00h 10m 56s\n"
     ]
    }
   ],
   "source": [
    "# Callbacks & Tensorboard Setup\n",
    "early_stopping_1n_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Create a Keras Tuner\n",
    "OneNeuron_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory='logs/flights_ontime/dense_lr/',\n",
    "    project_name='tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneNeuron_tuner_RS.search(train_ds_flights_ontime_d, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             callbacks=[early_stopping_1n_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best 3 one-model fits: hyperparameters and validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in logs/flights_ontime/dense_lr/tuner\n",
      "Showing 3 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 012 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.006842507100027634\n",
      "l1_regularization: 5.026554730743739e-05\n",
      "l2_regularization: 0.00012316317658612945\n",
      "Score: 0.4110903888940811\n",
      "\n",
      "Trial 024 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.008530202096475512\n",
      "l1_regularization: 0.00012170421860683753\n",
      "l2_regularization: 1.1011211773991691e-05\n",
      "Score: 0.41599664092063904\n",
      "\n",
      "Trial 046 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.00359824300326137\n",
      "l1_regularization: 0.00025769328883230635\n",
      "l2_regularization: 0.0004753203574656876\n",
      "Score: 0.4249129742383957\n"
     ]
    }
   ],
   "source": [
    "OneNeuron_tuner_RS.results_summary(num_trials=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save best one-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Tensorboard setup\n",
    "!rm -rf ./logs/flights_ontime/OneNeuron/tensorboard/ \n",
    "log_dir = \"logs/flights_ontime/OneNeuron/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_best = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneNeuron_LR_model = OneNeuron_tuner_RS.hypermodel.build(best_hps)\n",
    "history = OneNeuron_LR_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneNeuron_LR_model.save('models/flights_ontime/OneNeuron_LR_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TensorBoard for best 1-neuron model\n",
    "The TensorBoard dashboard shows plots generated from training logs that provide insight into the training of a model. \n",
    "\n",
    "The time series tab shows several plots within expandable windows for our one-neuronal model, \"dense_#\" and for the loss and training metrics by epoch.  Under dense_#, TesnorBoard shows histograms of the bias values \"bias_0\" and weight values, \"kernel_0\" by epoch. The epoch number is on the y-axis with the first epochs at the top and the most recent epoch at the bottom. These plots show how the bias and weight distributions change with training. For the one-neuron model, the weights appear to stabilize well before the training ended, at around 50 to 60 epochs, while the bias terms continued to drift downwards with training.\n",
    "\n",
    "The other plots under Time Series show how the loss and metrics change with training epoch or iteration (batch number). Based on these plots, the one-neuron model appears to have high bias and high variance. High bias is indicated by the large difference in loss and performance metrics between the train and validation datasets. High variance is indicated by the large variation in the validation loss, mae, and r-squared metrics that persists through training, even after these metrics stabilize on the training set at around epoch 40. Taken together, the one-neuron model appears to lack flexibility and would also benefit from having more data to train the weights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 3470), started 10:23:51 ago. (Use '!kill 3470' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-213b8de153dc2086\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-213b8de153dc2086\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneNeuron/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evalute the best 1-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 580us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 122.72\n",
      "- Validation MSE: 32874.14\n",
      "- Validation R^2: 0.679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "OneNeuron_LR_model = models.load_model('models/flights_ontime/OneNeuron_LR_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneNeuron_LR_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "OneNeuron_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneNeuron_val_mae:.2f}\n",
    "- Validation MSE: {OneNeuron_val_mse:.2f}\n",
    "- Validation R^2: {OneNeuron_val_r2:.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW DENSE NEURAL NETWORK (SDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SDNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=1, max_value=2, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.02, max_value=0.03, default=0.0)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=n_neurons, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=L2(l2_regularization)))\n",
    "    \n",
    "    for layer in range(n_hidden-1):\n",
    "        model.add(Dense(units=n_neurons, \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=L2(l2_regularization)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    if n_hidden > 0:\n",
    "        model.add(Dense(units=n_neurons, \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=L2(l2_regularization)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 02s]\n",
      "val_loss: 0.4439461827278137\n",
      "\n",
      "Best val_loss So Far: 0.38801226019859314\n",
      "Total elapsed time: 00h 08m 06s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_BO = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_BO = kt.BayesianOptimization(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    num_initial_points=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"bayesian_optimization_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_BO.search(train_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             callbacks=[early_stopping_BO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 04s]\n",
      "val_loss: 0.4617564529180527\n",
      "\n",
      "Best val_loss So Far: 0.3983249217271805\n",
      "Total elapsed time: 00h 09m 17s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"random_search_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_RS.search(train_ds_flights_ontime_d,\n",
    "                epochs=500, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for best SDNN model using hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 05s]\n",
      "val_loss: 0.7675652503967285\n",
      "\n",
      "Best val_loss So Far: 0.3679744005203247\n",
      "Total elapsed time: 00h 16m 34s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_HB = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"hyperband_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_HB.search(train_ds_flights_ontime_d,\n",
    "                epochs=600, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_HB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best SDNN model (from hyperband search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters from Hyperband tuner\n",
    "best_hps = SDNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Initialize Early Stopping\n",
    "early_stopping_SDNN_best = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/SDNN_HB/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/SDNN_HB/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "SDNN_model = SDNN_tuner_HB.hypermodel.build(best_hps)\n",
    "history = SDNN_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_SDNN_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "SDNN_model.save('models/flights_ontime/SDNN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 27548), started 10:59:53 ago. (Use '!kill 27548' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4a938b36ff60f93d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4a938b36ff60f93d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard\n",
    "%tensorboard --logdir logs/flights_ontime/SDNN_HB/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 8\n",
      "- Learning Rate: 0.006415517608465564\n",
      "- Dropout Rate: 0.024849650762982137\n",
      "- L2 Regularization: 0.0007243411260176605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "SDNN_model = models.load_model('models/flights_ontime/SDNN_model')\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- L2 Regularization: {best_hps.get('l2_regularization')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 720       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801 (3.13 KB)\n",
      "Trainable params: 801 (3.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SDNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 634us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 125.45\n",
      "- Validation MSE: 33286.20\n",
      "- Validation R^2: 0.675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inverse transform the predicted values and get validation MAE, MSE\n",
    "y_pred = SDNN_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "SDNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "SDNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "SDNN_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {SDNN_val_mae:.2f}\n",
    "- Validation MSE: {SDNN_val_mse:.2f}\n",
    "- Validation R^2: {SDNN_val_r2:.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECURRENT NEURAL NETWORK (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lag variables from X train, val, and test sets\n",
    "The lag variables are redundant with the recurrent loops of an RNN that feed historical information into each neuron. I dropped the lag variables to reduce the redundancy and dimensionality in the RNN datasets. However, the lag variables may have value in an RNN despite introducing redundancy and multicolinearity. Time permitting, I'll retain the lag variables and train the RNN's a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_X_train_full = X_train_full.drop(lag_cols, axis=1)\n",
    "rnn_X_train = X_train.drop(lag_cols, axis=1)\n",
    "rnn_X_val = X_val.drop(lag_cols, axis=1)\n",
    "rnn_X_test = X_test.drop(lag_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN column transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_numeric_cols = [col for col in numeric_cols if col not in lag_cols]\n",
    "\n",
    "# Fit transformers to the training data\n",
    "rnn_f_scaler = StandardScaler()\n",
    "rnn_f_scaler.fit(rnn_X_train[rnn_numeric_cols])\n",
    "\n",
    "# Create a function to preprocess TensorFlow datasets\n",
    "def rnn_preprocess(features, target):\n",
    "    scaled_features = rnn_f_scaler.transform(features[rnn_numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1)) # Scaling the target can speed up training, improve convergence, and reduce the impact of outliers for RNNs\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Transform the data\n",
    "X_train_rnn, y_train_rnn = rnn_preprocess(X_train, y_train)\n",
    "X_val_rnn, y_val_rnn = rnn_preprocess(X_val, y_val)\n",
    "X_test_rnn, y_test_rnn = rnn_preprocess(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create timeseries datasets\n",
    "\n",
    "The timeseries datasets below use a sequence length of 7 and a time step of 1. Each recurrent neuron will process the sequences in 7 recurrent steps, updating its hidden state based on the current input and the previous hidden state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "seq_length = 7\n",
    "batch_size = 32\n",
    "\n",
    "train_rnn = timeseries_dataset_from_array(\n",
    "    data = X_train_rnn, \n",
    "    targets = y_train_rnn,\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "val_rnn = timeseries_dataset_from_array(\n",
    "    data = X_val_rnn, \n",
    "    targets = y_val_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_rnn = timeseries_dataset_from_array(\n",
    "    data = X_test_rnn, \n",
    "    targets = y_test_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a 1-neuron RNN hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build one-neuron RNN hypermodel\n",
    "def OneRNN_model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units = 1, \n",
    "                  input_shape = (None, X_train_rnn.shape[1]), \n",
    "                  kernel_regularizer=L2(kernel_reg),\n",
    "                  recurrent_regularizer=L2(recurr_reg),\n",
    "                  )\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 21s]\n",
      "val_loss: 1.2453628778457642\n",
      "\n",
      "Best val_loss So Far: 1.1035436391830444\n",
      "Total elapsed time: 00h 49m 19s\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Hyperband tuner\n",
    "OneRNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = OneRNN_model_builder,\n",
    "    objective='val_loss',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    directory='logs/flights_ontime/OneRNN',\n",
    "    project_name='hyperband_tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneRNN_tuner_HB.search(train_rnn, \n",
    "             validation_data=val_rnn, \n",
    "             epochs=100, \n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best one-neuron RNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "best_hps = OneRNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneRNN_model = OneRNN_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/OneRNN/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/OneRNN/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = OneRNN_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneRNN_model.save('models/flights_ontime/OneRNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 41285), started 0:00:05 ago. (Use '!kill 41285' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ea377e98d930e2ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ea377e98d930e2ca\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneRNN/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evaluate the best one-neuron RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 840us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 252.07\n",
      "- Validation MSE: 107981.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OneRNN_model = models.load_model('models/flights_ontime/OneRNN_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneRNN_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "OneRNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneRNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneRNN_val_mae:.2f}\n",
    "- Validation MSE: {OneRNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a shallow RNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=1, max_value=2, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    recurrent_dropout_rate = hp.Float('recurrent_dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer with dropout\n",
    "    model.add(Dropout(dropout_rate, \n",
    "                      input_shape=(None, X_train_rnn.shape[1])))\n",
    "\n",
    "    # First n-1 Hidden layers\n",
    "    for _ in range(n_hidden-1):\n",
    "        model.add(SimpleRNN(units=n_neurons, \n",
    "                            activation='relu', \n",
    "                            return_sequences=True,\n",
    "                            kernel_regularizer=L2(kernel_reg),\n",
    "                            recurrent_regularizer=L2(recurr_reg),\n",
    "                            dropout = dropout_rate,\n",
    "                            recurrent_dropout = recurrent_dropout_rate))\n",
    "\n",
    "    # Last hidden layer\n",
    "    if n_hidden > 0:\n",
    "        model.add(SimpleRNN(units=n_neurons, \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=L2(kernel_reg),\n",
    "                            recurrent_regularizer=L2(recurr_reg),\n",
    "                            dropout = dropout_rate,\n",
    "                            recurrent_dropout = recurrent_dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using a random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 15s]\n",
      "val_loss: 1.264518141746521\n",
      "\n",
      "Best val_loss So Far: 1.124204158782959\n",
      "Total elapsed time: 00h 10m 11s\n",
      "\n",
      "Search: Running Trial #26\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |1                 |n_hidden\n",
      "13                |26                |n_neurons\n",
      "0.00030422        |0.0055101         |learning_rate\n",
      "0.32277           |0.21213           |dropout_rate\n",
      "0.43681           |0.47244           |recurrent_dropout_rate\n",
      "0.00017468        |0.006274          |kernel_reg\n",
      "0.03678           |0.01079           |recurr_reg\n",
      "\n",
      "Epoch 1/500\n",
      "43/43 [==============================] - 1s 5ms/step - loss: 23.9736 - mean_absolute_error: 3.4789 - val_loss: 5.0717 - val_mean_absolute_error: 1.7508\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14.4724 - mean_absolute_error: 2.6433 - val_loss: 3.7997 - val_mean_absolute_error: 1.4154\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 10.0611 - mean_absolute_error: 2.2159 - val_loss: 3.3012 - val_mean_absolute_error: 1.2457\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 7.4112 - mean_absolute_error: 1.9309 - val_loss: 3.0874 - val_mean_absolute_error: 1.1624\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 6.2317 - mean_absolute_error: 1.7917 - val_loss: 2.9503 - val_mean_absolute_error: 1.1073\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.9081 - mean_absolute_error: 1.5558 - val_loss: 2.8335 - val_mean_absolute_error: 1.0714\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3530 - mean_absolute_error: 1.4997 - val_loss: 2.7405 - val_mean_absolute_error: 1.0453\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3267 - mean_absolute_error: 1.4833 - val_loss: 2.7089 - val_mean_absolute_error: 1.0280\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.8107 - mean_absolute_error: 1.3574 - val_loss: 2.6490 - val_mean_absolute_error: 1.0106\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 3.3602 - mean_absolute_error: 1.3215 - val_loss: 2.6128 - val_mean_absolute_error: 0.9944\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.1781 - mean_absolute_error: 1.2638 - val_loss: 2.5835 - val_mean_absolute_error: 0.9791\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9005 - mean_absolute_error: 1.2213 - val_loss: 2.5635 - val_mean_absolute_error: 0.9660\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.0156 - mean_absolute_error: 1.2109 - val_loss: 2.5116 - val_mean_absolute_error: 0.9554\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9074 - mean_absolute_error: 1.1719 - val_loss: 2.4666 - val_mean_absolute_error: 0.9443\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5431 - mean_absolute_error: 1.1325 - val_loss: 2.4584 - val_mean_absolute_error: 0.9397\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7084 - mean_absolute_error: 1.1457 - val_loss: 2.4308 - val_mean_absolute_error: 0.9354\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3295 - mean_absolute_error: 1.0736 - val_loss: 2.4289 - val_mean_absolute_error: 0.9328\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4867 - mean_absolute_error: 1.0968 - val_loss: 2.3907 - val_mean_absolute_error: 0.9292\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2197 - mean_absolute_error: 1.0403 - val_loss: 2.3882 - val_mean_absolute_error: 0.9256\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2441 - mean_absolute_error: 1.0208 - val_loss: 2.3810 - val_mean_absolute_error: 0.9229\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2777 - mean_absolute_error: 1.0340 - val_loss: 2.3497 - val_mean_absolute_error: 0.9194\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1225 - mean_absolute_error: 1.0031 - val_loss: 2.3459 - val_mean_absolute_error: 0.9174\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0509 - mean_absolute_error: 0.9860 - val_loss: 2.3447 - val_mean_absolute_error: 0.9159\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1264 - mean_absolute_error: 0.9712 - val_loss: 2.3254 - val_mean_absolute_error: 0.9154\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0405 - mean_absolute_error: 0.9633 - val_loss: 2.3194 - val_mean_absolute_error: 0.9145\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9489 - mean_absolute_error: 0.9468 - val_loss: 2.3067 - val_mean_absolute_error: 0.9125\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0341 - mean_absolute_error: 0.9544 - val_loss: 2.2887 - val_mean_absolute_error: 0.9103\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9666 - mean_absolute_error: 0.9293 - val_loss: 2.2627 - val_mean_absolute_error: 0.9073\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8668 - mean_absolute_error: 0.9219 - val_loss: 2.2590 - val_mean_absolute_error: 0.9057\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7993 - mean_absolute_error: 0.9042 - val_loss: 2.2507 - val_mean_absolute_error: 0.9046\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8423 - mean_absolute_error: 0.9018 - val_loss: 2.2453 - val_mean_absolute_error: 0.9041\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8046 - mean_absolute_error: 0.9005 - val_loss: 2.2348 - val_mean_absolute_error: 0.9030\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8740 - mean_absolute_error: 0.9107 - val_loss: 2.2089 - val_mean_absolute_error: 0.9003\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8210 - mean_absolute_error: 0.9112 - val_loss: 2.1976 - val_mean_absolute_error: 0.8987\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7867 - mean_absolute_error: 0.8874 - val_loss: 2.1895 - val_mean_absolute_error: 0.8984\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7248 - mean_absolute_error: 0.8639 - val_loss: 2.1714 - val_mean_absolute_error: 0.8973\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7682 - mean_absolute_error: 0.8911 - val_loss: 2.1600 - val_mean_absolute_error: 0.8960\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6994 - mean_absolute_error: 0.8700 - val_loss: 2.1487 - val_mean_absolute_error: 0.8957\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6544 - mean_absolute_error: 0.8563 - val_loss: 2.1398 - val_mean_absolute_error: 0.8947\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6671 - mean_absolute_error: 0.8621 - val_loss: 2.1301 - val_mean_absolute_error: 0.8927\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7000 - mean_absolute_error: 0.8653 - val_loss: 2.1212 - val_mean_absolute_error: 0.8911\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6268 - mean_absolute_error: 0.8496 - val_loss: 2.1146 - val_mean_absolute_error: 0.8895\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7034 - mean_absolute_error: 0.8517 - val_loss: 2.0866 - val_mean_absolute_error: 0.8873\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6061 - mean_absolute_error: 0.8471 - val_loss: 2.0841 - val_mean_absolute_error: 0.8865\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5636 - mean_absolute_error: 0.8335 - val_loss: 2.0798 - val_mean_absolute_error: 0.8857\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6267 - mean_absolute_error: 0.8450 - val_loss: 2.0733 - val_mean_absolute_error: 0.8848\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5709 - mean_absolute_error: 0.8269 - val_loss: 2.0602 - val_mean_absolute_error: 0.8839\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5516 - mean_absolute_error: 0.8195 - val_loss: 2.0471 - val_mean_absolute_error: 0.8831\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5353 - mean_absolute_error: 0.8183 - val_loss: 2.0362 - val_mean_absolute_error: 0.8821\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6000 - mean_absolute_error: 0.8185 - val_loss: 2.0152 - val_mean_absolute_error: 0.8801\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5312 - mean_absolute_error: 0.8216 - val_loss: 2.0079 - val_mean_absolute_error: 0.8794\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5829 - mean_absolute_error: 0.8311 - val_loss: 1.9987 - val_mean_absolute_error: 0.8782\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4742 - mean_absolute_error: 0.7980 - val_loss: 1.9940 - val_mean_absolute_error: 0.8778\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5477 - mean_absolute_error: 0.8248 - val_loss: 1.9909 - val_mean_absolute_error: 0.8761\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5039 - mean_absolute_error: 0.8046 - val_loss: 1.9855 - val_mean_absolute_error: 0.8756\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4895 - mean_absolute_error: 0.8087 - val_loss: 1.9826 - val_mean_absolute_error: 0.8750\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5167 - mean_absolute_error: 0.8194 - val_loss: 1.9774 - val_mean_absolute_error: 0.8746\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4949 - mean_absolute_error: 0.8058 - val_loss: 1.9694 - val_mean_absolute_error: 0.8743\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5130 - mean_absolute_error: 0.8178 - val_loss: 1.9693 - val_mean_absolute_error: 0.8740\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5503 - mean_absolute_error: 0.8112 - val_loss: 1.9426 - val_mean_absolute_error: 0.8724\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4768 - mean_absolute_error: 0.8075 - val_loss: 1.9366 - val_mean_absolute_error: 0.8713\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4812 - mean_absolute_error: 0.7979 - val_loss: 1.9356 - val_mean_absolute_error: 0.8709\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4937 - mean_absolute_error: 0.7993 - val_loss: 1.9271 - val_mean_absolute_error: 0.8698\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5001 - mean_absolute_error: 0.8151 - val_loss: 1.9187 - val_mean_absolute_error: 0.8689\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4172 - mean_absolute_error: 0.7882 - val_loss: 1.9112 - val_mean_absolute_error: 0.8683\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4511 - mean_absolute_error: 0.7913 - val_loss: 1.9067 - val_mean_absolute_error: 0.8682\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4918 - mean_absolute_error: 0.8159 - val_loss: 1.8992 - val_mean_absolute_error: 0.8678\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4588 - mean_absolute_error: 0.7920 - val_loss: 1.8788 - val_mean_absolute_error: 0.8663\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4541 - mean_absolute_error: 0.8056 - val_loss: 1.8776 - val_mean_absolute_error: 0.8660\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4304 - mean_absolute_error: 0.7920 - val_loss: 1.8743 - val_mean_absolute_error: 0.8655\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4189 - mean_absolute_error: 0.7895 - val_loss: 1.8701 - val_mean_absolute_error: 0.8651\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4331 - mean_absolute_error: 0.7855 - val_loss: 1.8502 - val_mean_absolute_error: 0.8643\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3735 - mean_absolute_error: 0.7680 - val_loss: 1.8472 - val_mean_absolute_error: 0.8639\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4076 - mean_absolute_error: 0.7912 - val_loss: 1.8442 - val_mean_absolute_error: 0.8636\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4083 - mean_absolute_error: 0.7830 - val_loss: 1.8416 - val_mean_absolute_error: 0.8638\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3836 - mean_absolute_error: 0.7686 - val_loss: 1.8358 - val_mean_absolute_error: 0.8637\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4060 - mean_absolute_error: 0.7873 - val_loss: 1.8318 - val_mean_absolute_error: 0.8633\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3745 - mean_absolute_error: 0.7836 - val_loss: 1.8239 - val_mean_absolute_error: 0.8628\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4426 - mean_absolute_error: 0.7986 - val_loss: 1.7989 - val_mean_absolute_error: 0.8607\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4210 - mean_absolute_error: 0.7939 - val_loss: 1.7898 - val_mean_absolute_error: 0.8596\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3899 - mean_absolute_error: 0.7771 - val_loss: 1.7824 - val_mean_absolute_error: 0.8591\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3663 - mean_absolute_error: 0.7779 - val_loss: 1.7789 - val_mean_absolute_error: 0.8584\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3860 - mean_absolute_error: 0.7773 - val_loss: 1.7722 - val_mean_absolute_error: 0.8581\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3950 - mean_absolute_error: 0.7866 - val_loss: 1.7546 - val_mean_absolute_error: 0.8566\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3490 - mean_absolute_error: 0.7732 - val_loss: 1.7526 - val_mean_absolute_error: 0.8564\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3243 - mean_absolute_error: 0.7676 - val_loss: 1.7486 - val_mean_absolute_error: 0.8558\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3517 - mean_absolute_error: 0.7779 - val_loss: 1.7453 - val_mean_absolute_error: 0.8550\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3238 - mean_absolute_error: 0.7646 - val_loss: 1.7446 - val_mean_absolute_error: 0.8549\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3432 - mean_absolute_error: 0.7740 - val_loss: 1.7416 - val_mean_absolute_error: 0.8550\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3355 - mean_absolute_error: 0.7764 - val_loss: 1.7379 - val_mean_absolute_error: 0.8550\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3341 - mean_absolute_error: 0.7731 - val_loss: 1.7350 - val_mean_absolute_error: 0.8548\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3329 - mean_absolute_error: 0.7754 - val_loss: 1.7304 - val_mean_absolute_error: 0.8541\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3138 - mean_absolute_error: 0.7702 - val_loss: 1.7252 - val_mean_absolute_error: 0.8534\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3429 - mean_absolute_error: 0.7726 - val_loss: 1.7053 - val_mean_absolute_error: 0.8523\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3093 - mean_absolute_error: 0.7694 - val_loss: 1.6992 - val_mean_absolute_error: 0.8523\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2986 - mean_absolute_error: 0.7705 - val_loss: 1.6948 - val_mean_absolute_error: 0.8523\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3242 - mean_absolute_error: 0.7670 - val_loss: 1.6762 - val_mean_absolute_error: 0.8510\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3420 - mean_absolute_error: 0.7816 - val_loss: 1.6747 - val_mean_absolute_error: 0.8507\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3058 - mean_absolute_error: 0.7717 - val_loss: 1.6718 - val_mean_absolute_error: 0.8505\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2822 - mean_absolute_error: 0.7643 - val_loss: 1.6676 - val_mean_absolute_error: 0.8508\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3065 - mean_absolute_error: 0.7718 - val_loss: 1.6638 - val_mean_absolute_error: 0.8510\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3101 - mean_absolute_error: 0.7751 - val_loss: 1.6457 - val_mean_absolute_error: 0.8499\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2878 - mean_absolute_error: 0.7657 - val_loss: 1.6418 - val_mean_absolute_error: 0.8493\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2806 - mean_absolute_error: 0.7665 - val_loss: 1.6383 - val_mean_absolute_error: 0.8490\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3142 - mean_absolute_error: 0.7764 - val_loss: 1.6189 - val_mean_absolute_error: 0.8481\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2601 - mean_absolute_error: 0.7593 - val_loss: 1.6052 - val_mean_absolute_error: 0.8466\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2682 - mean_absolute_error: 0.7658 - val_loss: 1.6036 - val_mean_absolute_error: 0.8462\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2552 - mean_absolute_error: 0.7584 - val_loss: 1.6019 - val_mean_absolute_error: 0.8465\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2804 - mean_absolute_error: 0.7732 - val_loss: 1.5973 - val_mean_absolute_error: 0.8462\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2818 - mean_absolute_error: 0.7773 - val_loss: 1.5983 - val_mean_absolute_error: 0.8458\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2510 - mean_absolute_error: 0.7634 - val_loss: 1.5962 - val_mean_absolute_error: 0.8458\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2573 - mean_absolute_error: 0.7699 - val_loss: 1.5946 - val_mean_absolute_error: 0.8458\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2676 - mean_absolute_error: 0.7712 - val_loss: 1.5944 - val_mean_absolute_error: 0.8453\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2393 - mean_absolute_error: 0.7553 - val_loss: 1.5900 - val_mean_absolute_error: 0.8451\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2269 - mean_absolute_error: 0.7590 - val_loss: 1.5870 - val_mean_absolute_error: 0.8454\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2386 - mean_absolute_error: 0.7640 - val_loss: 1.5837 - val_mean_absolute_error: 0.8452\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2495 - mean_absolute_error: 0.7636 - val_loss: 1.5824 - val_mean_absolute_error: 0.8452\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2427 - mean_absolute_error: 0.7660 - val_loss: 1.5783 - val_mean_absolute_error: 0.8450\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2319 - mean_absolute_error: 0.7634 - val_loss: 1.5601 - val_mean_absolute_error: 0.8433\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2361 - mean_absolute_error: 0.7630 - val_loss: 1.5574 - val_mean_absolute_error: 0.8434\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2363 - mean_absolute_error: 0.7651 - val_loss: 1.5455 - val_mean_absolute_error: 0.8423\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2295 - mean_absolute_error: 0.7611 - val_loss: 1.5303 - val_mean_absolute_error: 0.8414\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2168 - mean_absolute_error: 0.7589 - val_loss: 1.5297 - val_mean_absolute_error: 0.8415\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2436 - mean_absolute_error: 0.7659 - val_loss: 1.5193 - val_mean_absolute_error: 0.8403\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2326 - mean_absolute_error: 0.7617 - val_loss: 1.5171 - val_mean_absolute_error: 0.8404\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2133 - mean_absolute_error: 0.7675 - val_loss: 1.5140 - val_mean_absolute_error: 0.8407\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2113 - mean_absolute_error: 0.7617 - val_loss: 1.5092 - val_mean_absolute_error: 0.8403\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2060 - mean_absolute_error: 0.7598 - val_loss: 1.5087 - val_mean_absolute_error: 0.8406\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2075 - mean_absolute_error: 0.7639 - val_loss: 1.5091 - val_mean_absolute_error: 0.8409\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1946 - mean_absolute_error: 0.7569 - val_loss: 1.5056 - val_mean_absolute_error: 0.8409\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2001 - mean_absolute_error: 0.7659 - val_loss: 1.5052 - val_mean_absolute_error: 0.8409\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1951 - mean_absolute_error: 0.7614 - val_loss: 1.4952 - val_mean_absolute_error: 0.8409\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1998 - mean_absolute_error: 0.7623 - val_loss: 1.4944 - val_mean_absolute_error: 0.8414\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1884 - mean_absolute_error: 0.7581 - val_loss: 1.4934 - val_mean_absolute_error: 0.8417\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1950 - mean_absolute_error: 0.7605 - val_loss: 1.4891 - val_mean_absolute_error: 0.8418\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1767 - mean_absolute_error: 0.7564 - val_loss: 1.4871 - val_mean_absolute_error: 0.8422\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1787 - mean_absolute_error: 0.7615 - val_loss: 1.4876 - val_mean_absolute_error: 0.8428\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1905 - mean_absolute_error: 0.7634 - val_loss: 1.4848 - val_mean_absolute_error: 0.8431\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1775 - mean_absolute_error: 0.7660 - val_loss: 1.4836 - val_mean_absolute_error: 0.8433\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1624 - mean_absolute_error: 0.7570 - val_loss: 1.4790 - val_mean_absolute_error: 0.8436\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1668 - mean_absolute_error: 0.7600 - val_loss: 1.4785 - val_mean_absolute_error: 0.8442\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1639 - mean_absolute_error: 0.7569 - val_loss: 1.4788 - val_mean_absolute_error: 0.8444\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1695 - mean_absolute_error: 0.7629 - val_loss: 1.4767 - val_mean_absolute_error: 0.8442\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1540 - mean_absolute_error: 0.7583 - val_loss: 1.4766 - val_mean_absolute_error: 0.8442\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1592 - mean_absolute_error: 0.7572 - val_loss: 1.4726 - val_mean_absolute_error: 0.8444\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1734 - mean_absolute_error: 0.7626 - val_loss: 1.4577 - val_mean_absolute_error: 0.8433\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1582 - mean_absolute_error: 0.7627 - val_loss: 1.4501 - val_mean_absolute_error: 0.8426\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1553 - mean_absolute_error: 0.7595 - val_loss: 1.4507 - val_mean_absolute_error: 0.8425\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1436 - mean_absolute_error: 0.7596 - val_loss: 1.4479 - val_mean_absolute_error: 0.8428\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1411 - mean_absolute_error: 0.7548 - val_loss: 1.4383 - val_mean_absolute_error: 0.8425\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1398 - mean_absolute_error: 0.7557 - val_loss: 1.4359 - val_mean_absolute_error: 0.8426\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1364 - mean_absolute_error: 0.7591 - val_loss: 1.4330 - val_mean_absolute_error: 0.8425\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1469 - mean_absolute_error: 0.7661 - val_loss: 1.4337 - val_mean_absolute_error: 0.8430\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1270 - mean_absolute_error: 0.7571 - val_loss: 1.4353 - val_mean_absolute_error: 0.8432\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1347 - mean_absolute_error: 0.7561 - val_loss: 1.4345 - val_mean_absolute_error: 0.8437\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1419 - mean_absolute_error: 0.7632 - val_loss: 1.4387 - val_mean_absolute_error: 0.8445\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1173 - mean_absolute_error: 0.7551 - val_loss: 1.4388 - val_mean_absolute_error: 0.8451\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1341 - mean_absolute_error: 0.7611 - val_loss: 1.4376 - val_mean_absolute_error: 0.8453\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1217 - mean_absolute_error: 0.7559 - val_loss: 1.4386 - val_mean_absolute_error: 0.8460\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1054 - mean_absolute_error: 0.7516 - val_loss: 1.4393 - val_mean_absolute_error: 0.8463\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1305 - mean_absolute_error: 0.7594 - val_loss: 1.4219 - val_mean_absolute_error: 0.8446\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1160 - mean_absolute_error: 0.7575 - val_loss: 1.4191 - val_mean_absolute_error: 0.8448\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1029 - mean_absolute_error: 0.7577 - val_loss: 1.4167 - val_mean_absolute_error: 0.8446\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1178 - mean_absolute_error: 0.7596 - val_loss: 1.4180 - val_mean_absolute_error: 0.8447\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1209 - mean_absolute_error: 0.7617 - val_loss: 1.4060 - val_mean_absolute_error: 0.8438\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1096 - mean_absolute_error: 0.7589 - val_loss: 1.4034 - val_mean_absolute_error: 0.8438\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1045 - mean_absolute_error: 0.7605 - val_loss: 1.4026 - val_mean_absolute_error: 0.8441\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0944 - mean_absolute_error: 0.7525 - val_loss: 1.4018 - val_mean_absolute_error: 0.8443\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0921 - mean_absolute_error: 0.7508 - val_loss: 1.4007 - val_mean_absolute_error: 0.8444\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0991 - mean_absolute_error: 0.7569 - val_loss: 1.4022 - val_mean_absolute_error: 0.8449\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1065 - mean_absolute_error: 0.7595 - val_loss: 1.4047 - val_mean_absolute_error: 0.8456\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1046 - mean_absolute_error: 0.7592 - val_loss: 1.3913 - val_mean_absolute_error: 0.8446\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0986 - mean_absolute_error: 0.7611 - val_loss: 1.3915 - val_mean_absolute_error: 0.8448\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0975 - mean_absolute_error: 0.7625 - val_loss: 1.3803 - val_mean_absolute_error: 0.8441\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0921 - mean_absolute_error: 0.7560 - val_loss: 1.3807 - val_mean_absolute_error: 0.8447\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0946 - mean_absolute_error: 0.7612 - val_loss: 1.3784 - val_mean_absolute_error: 0.8445\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0876 - mean_absolute_error: 0.7587 - val_loss: 1.3780 - val_mean_absolute_error: 0.8446\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0984 - mean_absolute_error: 0.7595 - val_loss: 1.3681 - val_mean_absolute_error: 0.8439\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0777 - mean_absolute_error: 0.7573 - val_loss: 1.3661 - val_mean_absolute_error: 0.8438\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0880 - mean_absolute_error: 0.7613 - val_loss: 1.3646 - val_mean_absolute_error: 0.8439\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0839 - mean_absolute_error: 0.7620 - val_loss: 1.3623 - val_mean_absolute_error: 0.8437\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0776 - mean_absolute_error: 0.7585 - val_loss: 1.3626 - val_mean_absolute_error: 0.8439\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0720 - mean_absolute_error: 0.7561 - val_loss: 1.3613 - val_mean_absolute_error: 0.8439\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0665 - mean_absolute_error: 0.7571 - val_loss: 1.3644 - val_mean_absolute_error: 0.8445\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0662 - mean_absolute_error: 0.7521 - val_loss: 1.3651 - val_mean_absolute_error: 0.8446\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0604 - mean_absolute_error: 0.7555 - val_loss: 1.3661 - val_mean_absolute_error: 0.8450\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0682 - mean_absolute_error: 0.7597 - val_loss: 1.3640 - val_mean_absolute_error: 0.8450\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0628 - mean_absolute_error: 0.7549 - val_loss: 1.3540 - val_mean_absolute_error: 0.8442\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0731 - mean_absolute_error: 0.7604 - val_loss: 1.3438 - val_mean_absolute_error: 0.8437\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0626 - mean_absolute_error: 0.7553 - val_loss: 1.3443 - val_mean_absolute_error: 0.8441\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0556 - mean_absolute_error: 0.7575 - val_loss: 1.3359 - val_mean_absolute_error: 0.8433\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0645 - mean_absolute_error: 0.7618 - val_loss: 1.3365 - val_mean_absolute_error: 0.8435\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0526 - mean_absolute_error: 0.7555 - val_loss: 1.3356 - val_mean_absolute_error: 0.8434\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0575 - mean_absolute_error: 0.7569 - val_loss: 1.3300 - val_mean_absolute_error: 0.8429\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0468 - mean_absolute_error: 0.7546 - val_loss: 1.3294 - val_mean_absolute_error: 0.8431\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0548 - mean_absolute_error: 0.7575 - val_loss: 1.3328 - val_mean_absolute_error: 0.8441\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0551 - mean_absolute_error: 0.7565 - val_loss: 1.3310 - val_mean_absolute_error: 0.8442\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0562 - mean_absolute_error: 0.7607 - val_loss: 1.3320 - val_mean_absolute_error: 0.8446\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0505 - mean_absolute_error: 0.7548 - val_loss: 1.3323 - val_mean_absolute_error: 0.8450\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0538 - mean_absolute_error: 0.7590 - val_loss: 1.3266 - val_mean_absolute_error: 0.8448\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0397 - mean_absolute_error: 0.7537 - val_loss: 1.3274 - val_mean_absolute_error: 0.8449\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0413 - mean_absolute_error: 0.7531 - val_loss: 1.3265 - val_mean_absolute_error: 0.8449\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0469 - mean_absolute_error: 0.7603 - val_loss: 1.3199 - val_mean_absolute_error: 0.8444\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0388 - mean_absolute_error: 0.7561 - val_loss: 1.3224 - val_mean_absolute_error: 0.8443\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.7595 - val_loss: 1.3213 - val_mean_absolute_error: 0.8443\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0397 - mean_absolute_error: 0.7566 - val_loss: 1.3231 - val_mean_absolute_error: 0.8446\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0413 - mean_absolute_error: 0.7592 - val_loss: 1.3244 - val_mean_absolute_error: 0.8449\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0336 - mean_absolute_error: 0.7533 - val_loss: 1.3238 - val_mean_absolute_error: 0.8453\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0372 - mean_absolute_error: 0.7542 - val_loss: 1.3216 - val_mean_absolute_error: 0.8449\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0362 - mean_absolute_error: 0.7556 - val_loss: 1.3213 - val_mean_absolute_error: 0.8449\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0286 - mean_absolute_error: 0.7547 - val_loss: 1.3207 - val_mean_absolute_error: 0.8449\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0221 - mean_absolute_error: 0.7520 - val_loss: 1.3221 - val_mean_absolute_error: 0.8452\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.0382 - mean_absolute_error: 0.7593 - val_loss: 1.3219 - val_mean_absolute_error: 0.8452\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0184 - mean_absolute_error: 0.7502 - val_loss: 1.3246 - val_mean_absolute_error: 0.8456\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0240 - mean_absolute_error: 0.7533 - val_loss: 1.3268 - val_mean_absolute_error: 0.8460\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0344 - mean_absolute_error: 0.7593 - val_loss: 1.3278 - val_mean_absolute_error: 0.8461\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0239 - mean_absolute_error: 0.7509 - val_loss: 1.3278 - val_mean_absolute_error: 0.8458\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0278 - mean_absolute_error: 0.7592 - val_loss: 1.3286 - val_mean_absolute_error: 0.8461\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0292 - mean_absolute_error: 0.7571 - val_loss: 1.3317 - val_mean_absolute_error: 0.8465\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0272 - mean_absolute_error: 0.7557 - val_loss: 1.3338 - val_mean_absolute_error: 0.8469\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0279 - mean_absolute_error: 0.7587 - val_loss: 1.3362 - val_mean_absolute_error: 0.8477\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0263 - mean_absolute_error: 0.7576 - val_loss: 1.3265 - val_mean_absolute_error: 0.8469\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0238 - mean_absolute_error: 0.7559 - val_loss: 1.3316 - val_mean_absolute_error: 0.8473\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0278 - mean_absolute_error: 0.7553 - val_loss: 1.3225 - val_mean_absolute_error: 0.8465\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0221 - mean_absolute_error: 0.7570 - val_loss: 1.3203 - val_mean_absolute_error: 0.8463\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0201 - mean_absolute_error: 0.7586 - val_loss: 1.3235 - val_mean_absolute_error: 0.8469\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0180 - mean_absolute_error: 0.7590 - val_loss: 1.3133 - val_mean_absolute_error: 0.8455\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0191 - mean_absolute_error: 0.7561 - val_loss: 1.3020 - val_mean_absolute_error: 0.8442\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0226 - mean_absolute_error: 0.7637 - val_loss: 1.3029 - val_mean_absolute_error: 0.8442\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0192 - mean_absolute_error: 0.7529 - val_loss: 1.3064 - val_mean_absolute_error: 0.8446\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0107 - mean_absolute_error: 0.7532 - val_loss: 1.3068 - val_mean_absolute_error: 0.8445\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0007 - mean_absolute_error: 0.7522 - val_loss: 1.3073 - val_mean_absolute_error: 0.8446\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0189 - mean_absolute_error: 0.7571 - val_loss: 1.3083 - val_mean_absolute_error: 0.8447\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0132 - mean_absolute_error: 0.7548 - val_loss: 1.3088 - val_mean_absolute_error: 0.8446\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0139 - mean_absolute_error: 0.7573 - val_loss: 1.3120 - val_mean_absolute_error: 0.8447\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0118 - mean_absolute_error: 0.7552 - val_loss: 1.3159 - val_mean_absolute_error: 0.8451\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0048 - mean_absolute_error: 0.7553 - val_loss: 1.3237 - val_mean_absolute_error: 0.8463\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0096 - mean_absolute_error: 0.7521 - val_loss: 1.3288 - val_mean_absolute_error: 0.8471\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0109 - mean_absolute_error: 0.7574 - val_loss: 1.3248 - val_mean_absolute_error: 0.8467\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0143 - mean_absolute_error: 0.7553 - val_loss: 1.3288 - val_mean_absolute_error: 0.8473\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0023 - mean_absolute_error: 0.7523 - val_loss: 1.3385 - val_mean_absolute_error: 0.8487\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0019 - mean_absolute_error: 0.7525 - val_loss: 1.3410 - val_mean_absolute_error: 0.8490\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0022 - mean_absolute_error: 0.7534 - val_loss: 1.3385 - val_mean_absolute_error: 0.8488\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0026 - mean_absolute_error: 0.7536 - val_loss: 1.3377 - val_mean_absolute_error: 0.8488\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0078 - mean_absolute_error: 0.7564 - val_loss: 1.3407 - val_mean_absolute_error: 0.8494\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0040 - mean_absolute_error: 0.7546 - val_loss: 1.3417 - val_mean_absolute_error: 0.8494\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0084 - mean_absolute_error: 0.7551 - val_loss: 1.3401 - val_mean_absolute_error: 0.8494\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0119 - mean_absolute_error: 0.7591 - val_loss: 1.3441 - val_mean_absolute_error: 0.8497\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0081 - mean_absolute_error: 0.7552 - val_loss: 1.3429 - val_mean_absolute_error: 0.8498\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0055 - mean_absolute_error: 0.7542 - val_loss: 1.3384 - val_mean_absolute_error: 0.8498\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9962 - mean_absolute_error: 0.7519 - val_loss: 1.3388 - val_mean_absolute_error: 0.8498\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9965 - mean_absolute_error: 0.7546 - val_loss: 1.3342 - val_mean_absolute_error: 0.8491\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0067 - mean_absolute_error: 0.7576 - val_loss: 1.3337 - val_mean_absolute_error: 0.8492\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9985 - mean_absolute_error: 0.7524 - val_loss: 1.3204 - val_mean_absolute_error: 0.8482\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0020 - mean_absolute_error: 0.7545 - val_loss: 1.3251 - val_mean_absolute_error: 0.8484\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0141 - mean_absolute_error: 0.7570 - val_loss: 1.3048 - val_mean_absolute_error: 0.8463\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0122 - mean_absolute_error: 0.7616 - val_loss: 1.2921 - val_mean_absolute_error: 0.8447\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0041 - mean_absolute_error: 0.7552 - val_loss: 1.2968 - val_mean_absolute_error: 0.8457\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0049 - mean_absolute_error: 0.7583 - val_loss: 1.3017 - val_mean_absolute_error: 0.8460\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9894 - mean_absolute_error: 0.7508 - val_loss: 1.3072 - val_mean_absolute_error: 0.8470\n",
      "Epoch 261/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9948 - mean_absolute_error: 0.7551 - val_loss: 1.3096 - val_mean_absolute_error: 0.8474\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0054 - mean_absolute_error: 0.7563 - val_loss: 1.2992 - val_mean_absolute_error: 0.8462\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7527 - val_loss: 1.3032 - val_mean_absolute_error: 0.8466\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9795 - mean_absolute_error: 0.7480 - val_loss: 1.3092 - val_mean_absolute_error: 0.8471\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9968 - mean_absolute_error: 0.7541 - val_loss: 1.2995 - val_mean_absolute_error: 0.8460\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9976 - mean_absolute_error: 0.7561 - val_loss: 1.3021 - val_mean_absolute_error: 0.8472\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9990 - mean_absolute_error: 0.7557 - val_loss: 1.2996 - val_mean_absolute_error: 0.8466\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9972 - mean_absolute_error: 0.7530 - val_loss: 1.3019 - val_mean_absolute_error: 0.8473\n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7536 - val_loss: 1.2927 - val_mean_absolute_error: 0.8465\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7487 - val_loss: 1.2960 - val_mean_absolute_error: 0.8467\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9924 - mean_absolute_error: 0.7557 - val_loss: 1.2943 - val_mean_absolute_error: 0.8465\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9909 - mean_absolute_error: 0.7523 - val_loss: 1.2955 - val_mean_absolute_error: 0.8466\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9911 - mean_absolute_error: 0.7555 - val_loss: 1.2998 - val_mean_absolute_error: 0.8471\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0031 - mean_absolute_error: 0.7565 - val_loss: 1.3007 - val_mean_absolute_error: 0.8478\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9854 - mean_absolute_error: 0.7470 - val_loss: 1.2985 - val_mean_absolute_error: 0.8475\n",
      "Epoch 276/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9966 - mean_absolute_error: 0.7553 - val_loss: 1.3006 - val_mean_absolute_error: 0.8480\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9875 - mean_absolute_error: 0.7501 - val_loss: 1.3024 - val_mean_absolute_error: 0.8481\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9785 - mean_absolute_error: 0.7418 - val_loss: 1.3067 - val_mean_absolute_error: 0.8487\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0028 - mean_absolute_error: 0.7580 - val_loss: 1.2956 - val_mean_absolute_error: 0.8481\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7501 - val_loss: 1.2989 - val_mean_absolute_error: 0.8487\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9910 - mean_absolute_error: 0.7561 - val_loss: 1.3017 - val_mean_absolute_error: 0.8491\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7516 - val_loss: 1.2971 - val_mean_absolute_error: 0.8482\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9747 - mean_absolute_error: 0.7454 - val_loss: 1.3026 - val_mean_absolute_error: 0.8492\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9773 - mean_absolute_error: 0.7497 - val_loss: 1.2939 - val_mean_absolute_error: 0.8483\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9811 - mean_absolute_error: 0.7492 - val_loss: 1.2934 - val_mean_absolute_error: 0.8487\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7533 - val_loss: 1.2927 - val_mean_absolute_error: 0.8479\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9923 - mean_absolute_error: 0.7587 - val_loss: 1.2955 - val_mean_absolute_error: 0.8475\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9882 - mean_absolute_error: 0.7493 - val_loss: 1.2885 - val_mean_absolute_error: 0.8468\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7527 - val_loss: 1.2918 - val_mean_absolute_error: 0.8474\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9899 - mean_absolute_error: 0.7537 - val_loss: 1.2957 - val_mean_absolute_error: 0.8476\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9885 - mean_absolute_error: 0.7517 - val_loss: 1.2764 - val_mean_absolute_error: 0.8454\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9943 - mean_absolute_error: 0.7537 - val_loss: 1.2643 - val_mean_absolute_error: 0.8452\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9962 - mean_absolute_error: 0.7559 - val_loss: 1.2670 - val_mean_absolute_error: 0.8457\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9929 - mean_absolute_error: 0.7558 - val_loss: 1.2704 - val_mean_absolute_error: 0.8471\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9916 - mean_absolute_error: 0.7562 - val_loss: 1.2761 - val_mean_absolute_error: 0.8478\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9890 - mean_absolute_error: 0.7585 - val_loss: 1.2743 - val_mean_absolute_error: 0.8481\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9816 - mean_absolute_error: 0.7517 - val_loss: 1.2739 - val_mean_absolute_error: 0.8479\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9877 - mean_absolute_error: 0.7518 - val_loss: 1.2777 - val_mean_absolute_error: 0.8486\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9825 - mean_absolute_error: 0.7519 - val_loss: 1.2835 - val_mean_absolute_error: 0.8490\n",
      "Epoch 300/500\n",
      "28/43 [==================>...........] - ETA: 0s - loss: 0.9725 - mean_absolute_error: 0.7515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m RNN_shallow_tuner_RS \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m      2\u001b[0m     build_model,\n\u001b[1;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      5\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mRNN_shallow_tuner_RS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_RS = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_RS.search(train_rnn, epochs=500, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 08s]\n",
      "val_loss: 1.227628469467163\n",
      "\n",
      "Best val_loss So Far: 1.1422590017318726\n",
      "Total elapsed time: 00h 07m 13s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_BO = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    num_initial_points=2,\n",
    "    overwrite=True\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_BO.search(train_rnn, epochs=50, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Hyperband tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 34s]\n",
      "val_loss: 1.2451832294464111\n",
      "\n",
      "Best val_loss So Far: 1.0942782163619995\n",
      "Total elapsed time: 07h 40m 01s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_HB = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_HB.search(train_rnn, \n",
    "                            epochs=600, \n",
    "                            validation_data=val_rnn, \n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save the best shallow RNN model\n",
    "The Hyperband tuner produced the best model based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "43/43 [==============================] - 2s 9ms/step - loss: 1.9077 - mean_absolute_error: 0.9060 - val_loss: 1.6102 - val_mean_absolute_error: 0.8525\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3958 - mean_absolute_error: 0.7943 - val_loss: 1.7082 - val_mean_absolute_error: 0.8732\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1835 - mean_absolute_error: 0.7711 - val_loss: 1.3277 - val_mean_absolute_error: 0.8421\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1280 - mean_absolute_error: 0.7745 - val_loss: 1.1457 - val_mean_absolute_error: 0.8015\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0538 - mean_absolute_error: 0.7519 - val_loss: 1.3006 - val_mean_absolute_error: 0.8337\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0449 - mean_absolute_error: 0.7610 - val_loss: 1.3722 - val_mean_absolute_error: 0.8507\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0194 - mean_absolute_error: 0.7571 - val_loss: 1.3136 - val_mean_absolute_error: 0.8405\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0197 - mean_absolute_error: 0.7586 - val_loss: 1.4211 - val_mean_absolute_error: 0.8577\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0209 - mean_absolute_error: 0.7611 - val_loss: 1.2839 - val_mean_absolute_error: 0.8407\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0282 - mean_absolute_error: 0.7602 - val_loss: 1.6559 - val_mean_absolute_error: 0.8737\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0320 - mean_absolute_error: 0.7592 - val_loss: 1.4446 - val_mean_absolute_error: 0.8567\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0010 - mean_absolute_error: 0.7594 - val_loss: 1.3710 - val_mean_absolute_error: 0.8454\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0042 - mean_absolute_error: 0.7577 - val_loss: 1.2030 - val_mean_absolute_error: 0.8310\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0076 - mean_absolute_error: 0.7594 - val_loss: 1.3729 - val_mean_absolute_error: 0.8553\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7576 - val_loss: 1.2823 - val_mean_absolute_error: 0.8451\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0010 - mean_absolute_error: 0.7632 - val_loss: 1.2467 - val_mean_absolute_error: 0.8377\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9953 - mean_absolute_error: 0.7504 - val_loss: 1.3444 - val_mean_absolute_error: 0.8467\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9910 - mean_absolute_error: 0.7517 - val_loss: 1.3334 - val_mean_absolute_error: 0.8527\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9882 - mean_absolute_error: 0.7593 - val_loss: 1.3639 - val_mean_absolute_error: 0.8475\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9834 - mean_absolute_error: 0.7471 - val_loss: 1.2822 - val_mean_absolute_error: 0.8402\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0009 - mean_absolute_error: 0.7593 - val_loss: 1.2243 - val_mean_absolute_error: 0.8306\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7597 - val_loss: 1.2742 - val_mean_absolute_error: 0.8417\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7497 - val_loss: 1.3250 - val_mean_absolute_error: 0.8499\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9949 - mean_absolute_error: 0.7557 - val_loss: 1.3276 - val_mean_absolute_error: 0.8348\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9920 - mean_absolute_error: 0.7535 - val_loss: 1.3549 - val_mean_absolute_error: 0.8423\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9926 - mean_absolute_error: 0.7559 - val_loss: 1.5073 - val_mean_absolute_error: 0.8591\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7461 - val_loss: 1.2561 - val_mean_absolute_error: 0.8300\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9933 - mean_absolute_error: 0.7580 - val_loss: 1.1956 - val_mean_absolute_error: 0.8384\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9971 - mean_absolute_error: 0.7483 - val_loss: 1.2734 - val_mean_absolute_error: 0.8441\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9947 - mean_absolute_error: 0.7608 - val_loss: 1.1871 - val_mean_absolute_error: 0.8148\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9814 - mean_absolute_error: 0.7463 - val_loss: 1.2507 - val_mean_absolute_error: 0.8313\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9924 - mean_absolute_error: 0.7499 - val_loss: 1.3397 - val_mean_absolute_error: 0.8515\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9809 - mean_absolute_error: 0.7558 - val_loss: 1.3108 - val_mean_absolute_error: 0.8442\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9724 - mean_absolute_error: 0.7470 - val_loss: 1.2937 - val_mean_absolute_error: 0.8381\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7461 - val_loss: 1.3305 - val_mean_absolute_error: 0.8528\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7524 - val_loss: 1.3085 - val_mean_absolute_error: 0.8503\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9800 - mean_absolute_error: 0.7528 - val_loss: 1.3288 - val_mean_absolute_error: 0.8572\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9731 - mean_absolute_error: 0.7458 - val_loss: 1.3121 - val_mean_absolute_error: 0.8347\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9960 - mean_absolute_error: 0.7594 - val_loss: 1.3154 - val_mean_absolute_error: 0.8518\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9916 - mean_absolute_error: 0.7618 - val_loss: 1.3504 - val_mean_absolute_error: 0.8490\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9913 - mean_absolute_error: 0.7503 - val_loss: 1.3508 - val_mean_absolute_error: 0.8466\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9917 - mean_absolute_error: 0.7552 - val_loss: 1.3175 - val_mean_absolute_error: 0.8467\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9642 - mean_absolute_error: 0.7410 - val_loss: 1.3192 - val_mean_absolute_error: 0.8347\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9900 - mean_absolute_error: 0.7556 - val_loss: 1.3719 - val_mean_absolute_error: 0.8492\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7443 - val_loss: 1.3907 - val_mean_absolute_error: 0.8565\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9812 - mean_absolute_error: 0.7491 - val_loss: 1.3988 - val_mean_absolute_error: 0.8590\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9873 - mean_absolute_error: 0.7471 - val_loss: 1.4085 - val_mean_absolute_error: 0.8489\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9871 - mean_absolute_error: 0.7521 - val_loss: 1.4225 - val_mean_absolute_error: 0.8571\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9848 - mean_absolute_error: 0.7475 - val_loss: 1.3486 - val_mean_absolute_error: 0.8552\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9950 - mean_absolute_error: 0.7573 - val_loss: 1.2066 - val_mean_absolute_error: 0.8389\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9786 - mean_absolute_error: 0.7450 - val_loss: 1.2899 - val_mean_absolute_error: 0.8505\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9826 - mean_absolute_error: 0.7497 - val_loss: 1.3009 - val_mean_absolute_error: 0.8481\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9727 - mean_absolute_error: 0.7483 - val_loss: 1.4481 - val_mean_absolute_error: 0.8668\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9933 - mean_absolute_error: 0.7531 - val_loss: 1.4069 - val_mean_absolute_error: 0.8549\n",
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = RNN_shallow_tuner_HB.get_best_hyperparameters(num_trials=1)[0]\n",
    "RNN_shallow_model = RNN_shallow_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# TensorBoard setup\n",
    "!rm -rf ./logs/flights_ontime/RNN_shallow/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/RNN_shallow/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = RNN_shallow_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback])\n",
    "\n",
    "# Save the best trained model\n",
    "RNN_shallow_model.save('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6013 (pid 49139), started 0:02:24 ago. (Use '!kill 49139' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-19c2c908334d8da9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-19c2c908334d8da9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/RNN_shallow/tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best shallow RNN model (from Hyperband tuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "RNN_shallow_model = models.load_model('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best shallow RNN model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 14\n",
      "- Learning Rate: 0.006576617683751118\n",
      "- Dropout Rate: 0.24480591203927254\n",
      "- Recurrent Dropout Rate: 0.35738857946677854\n",
      "- Kernel Regularization: 0.0010046913205416215\n",
      "- Recurrent Regularization: 0.04379999321621059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Recurrent Dropout Rate: {best_hps.get('recurrent_dropout_rate')}\n",
    "- Kernel Regularization: {best_hps.get('kernel_reg')}\n",
    "- Recurrent Regularization: {best_hps.get('recurr_reg')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_4 (Dropout)         (None, None, 75)          0         \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 14)                1260      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1275 (4.98 KB)\n",
      "Trainable params: 1275 (4.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the best shallow RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 934us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 250.52\n",
      "- Validation MSE: 113235.65\n",
      "- Validation R^2: -0.090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = RNN_shallow_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "shallow_rnn_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {shallow_rnn_val_mae:.2f}\n",
    "- Validation MSE: {shallow_rnn_val_mse:.2f}\n",
    "- Validation R^2: {shallow_rnn_val_r2:.3f}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EN_data = pd.read_csv(\"\")\n",
    "# Linear Regression Metrics from \"3.daily_linear_regression.ipynb\"\n",
    "LR_mae = 125.729\n",
    "LR_MSE = 34900.9\n",
    "\n",
    "# Bar graph of the inversed scaled validation MAE and MSE from the three models\n",
    "\n",
    "models = ['OneNeuron', 'SDNN_model', 'OneRNN', 'RNN_shallow']\n",
    "mae = [OneNeuron_val_mae, SDNN_val_mae,  OneRNN_val_mae, shallow_rnn_val_mae]\n",
    "mse = [OneNeuron_val_mse, SDNN_val_mse, OneRNN_val_mse, shallow_rnn_val_mse]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "bar_width = 0.35\n",
    "\n",
    "fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "\n",
    "# MAE\n",
    "axes[0].bar(x, mae, bar_width, label='MAE')\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('MAE Scores')\n",
    "axes[0].set_title('MAE Scores by model')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(models)\n",
    "axes[0].legend()\n",
    "\n",
    "# MSE\n",
    "axes[1].bar(x, mse, bar_width, label='MSE')\n",
    "axes[1].set_xlabel('Models')\n",
    "axes[1].set_ylabel('MSE Scores')\n",
    "axes[1].set_title('MSE Scores by model')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(models)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Choose best shallow RNN model tuner\n",
    "2. get weights and evaluate best shallow RNN model \n",
    "3. figure out TensorBoard Plots\n",
    "4. figure out model architecture\n",
    "4. change filenames \n",
    "5. push to github\n",
    "6. write up analysis\n",
    "7. submit to coursera\n",
    "\n",
    "## After submission\n",
    "8. add XGBoost or Adaboost\n",
    "9. update the raw data (selenium)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-rTmYhf-l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
