{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "\n",
    "from keras import layers, models, Sequential, regularizers\n",
    "from keras.layers import SimpleRNN, Dense, Dropout, Embedding, LSTM, GRU\n",
    "from keras.optimizers.legacy import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data & column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA_PATH = \"data.v3/daily\" \n",
    "\n",
    "df = pd.read_parquet(os.path.join(DAILY_DATA_PATH, \"daily_flights_and_weather_merged.parquet\"))\n",
    "\n",
    "# Flights column groups\n",
    "flights_terminal_cols = ['flights_arr_A', 'flights_arr_B', 'flights_arr_C', 'flights_arr_D', 'flights_arr_E',\n",
    "                         'flights_dep_A', 'flights_dep_B', 'flights_dep_C', 'flights_dep_D', 'flights_dep_E']\n",
    "\n",
    "flights_non_terminal_cols = ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime',\n",
    "                             'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel',\n",
    "                             'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel']\n",
    "\n",
    "flights_percentage_cols = ['flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct',\n",
    "                            'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct',\n",
    "                            'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
    "\n",
    "# Date column groups\n",
    "date_cols = ['date', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day']\n",
    "\n",
    "# Weather column groups\n",
    "weather_cols = ['wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction']\n",
    "\n",
    "# Lag column groups\n",
    "lag_cols =  ['flights_total_lag_1', 'flights_total_lag_2', 'flights_total_lag_3', 'flights_total_lag_4', 'flights_total_lag_5', 'flights_total_lag_6', 'flights_total_lag_7', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split - \"flights_ontime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full shape: (1516, 47)\n",
      "y_train_full shape: (1516,)\n",
      "X_train shape: (1364, 47)\n",
      "y_train shape: (1364,)\n",
      "X_Test shape: (169, 47)\n",
      "y_Test shape: (169,)\n"
     ]
    }
   ],
   "source": [
    "# Select features and targets\n",
    "train_features = ['random'] + date_cols + weather_cols + lag_cols\n",
    "targets = flights_non_terminal_cols + flights_percentage_cols\n",
    "\n",
    "# Create X and y\n",
    "X = df[train_features].drop('date', axis=1)\n",
    "y = df[targets]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y['flights_ontime'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Split data into X_train_rull and y_train_full into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes\n",
    "print(\"X_train_full shape:\", X_train_full.shape)\n",
    "print(\"y_train_full shape:\", y_train_full.shape)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_Test shape:\", X_test.shape)\n",
    "print(\"y_Test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS FOR DENSE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['random', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day', 'wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction', 'flights_total_lag_1', 'flights_total_lag_2', 'flights_total_lag_3', 'flights_total_lag_4', 'flights_total_lag_5', 'flights_total_lag_6', 'flights_total_lag_7', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7']\n",
      "Target columns: ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime', 'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel', 'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel', 'flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct', 'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct', 'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
      "\n",
      "Unique data types in X\n",
      "float64    23\n",
      "object     11\n",
      "int64       7\n",
      "float32     4\n",
      "int32       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns to one-hot-encode: ['covid', 'month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "print(f\"Target columns: {y.columns.tolist()}\", end=\"\\n\\n\")\n",
    "print(\"Unique data types in X\", X.dtypes.value_counts(), sep = '\\n')\n",
    "\n",
    "# Identify categorical and numeric columns in X\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include = ['float64', 'float32', 'int32', 'int64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns to one-hot-encode: {categorical_cols}\")\n",
    "\n",
    "# Fit transformers to the training data\n",
    "f_scaler = StandardScaler()\n",
    "f_scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # Some observed holidays may not be in the training data\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "t_scaler = StandardScaler()\n",
    "t_scaler.fit(y_train.values.reshape(-1, 1)) # reshape y_train to be 2D\n",
    "\n",
    "# Define preprocessor\n",
    "def preprocess(features, target, set_global_scaler = False):\n",
    "    global global_targer_scaler\n",
    "\n",
    "    scaled_features = f_scaler.transform(features[numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1))\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "\n",
    "    if set_global_scaler:\n",
    "        global_targer_scaler = t_scaler\n",
    "\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_d, y_train_d = preprocess(X_train, y_train, set_global_scaler=True)\n",
    "X_val_d, y_val_d = preprocess(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-NEURON \"LINEAR MODEL\"\n",
    "\n",
    "The goal of this section is to simulate linear regression using a neural newtork with one neuron and no activation function. I'll use L1 and L2 regularization to simulate elastic net regression and compare results to those found in 3.daily_linear_regression.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow datasets\n",
    "train_ds_flights_ontime_d = Dataset.from_tensor_slices((X_train_d, y_train_d)).shuffle(len(X_train_d))\n",
    "val_ds_flights_ontime_d = Dataset.from_tensor_slices((X_val_d, y_val_d)).shuffle(len(X_val_d))\n",
    "\n",
    "# Batch and prefetch\n",
    "batch_size = 32\n",
    "train_ds_flights_ontime_d = train_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n",
    "val_ds_flights_ontime_d = val_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create R-squared metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    y_true_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_true], tf.float32)\n",
    "    y_pred_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_pred], tf.float32)\n",
    "    SS_res =  K.sum(K.square(y_true_inv - y_pred_inv)) \n",
    "    SS_tot = K.sum(K.square(y_true_inv - K.mean(y_true_inv))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    l1_regularization = hp.Float('l1_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(units = 1, \n",
    "            input_dim=X_train_d.shape[1], \n",
    "            kernel_regularizer=L1L2(l1_regularization, l2_regularization))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one-neuron hyperparameters using Keras random search tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 04s]\n",
      "val_loss: 0.4642547070980072\n",
      "\n",
      "Best val_loss So Far: 0.4110903888940811\n",
      "Total elapsed time: 00h 10m 56s\n"
     ]
    }
   ],
   "source": [
    "# Callbacks & Tensorboard Setup\n",
    "early_stopping_1n_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Create a Keras Tuner\n",
    "OneNeuron_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory='logs/flights_ontime/dense_lr/',\n",
    "    project_name='tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneNeuron_tuner_RS.search(train_ds_flights_ontime_d, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             callbacks=[early_stopping_1n_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best 3 one-model fits: hyperparameters and validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in logs/flights_ontime/dense_lr/tuner\n",
      "Showing 3 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 012 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.006842507100027634\n",
      "l1_regularization: 5.026554730743739e-05\n",
      "l2_regularization: 0.00012316317658612945\n",
      "Score: 0.4110903888940811\n",
      "\n",
      "Trial 024 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.008530202096475512\n",
      "l1_regularization: 0.00012170421860683753\n",
      "l2_regularization: 1.1011211773991691e-05\n",
      "Score: 0.41599664092063904\n",
      "\n",
      "Trial 046 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.00359824300326137\n",
      "l1_regularization: 0.00025769328883230635\n",
      "l2_regularization: 0.0004753203574656876\n",
      "Score: 0.4249129742383957\n"
     ]
    }
   ],
   "source": [
    "OneNeuron_tuner_RS.results_summary(num_trials=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save best one-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Tensorboard setup\n",
    "!rm -rf ./logs/flights_ontime/OneNeuron/tensorboard/ \n",
    "log_dir = \"logs/flights_ontime/OneNeuron/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_best = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneNeuron_LR_model = OneNeuron_tuner_RS.hypermodel.build(best_hps)\n",
    "history = OneNeuron_LR_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneNeuron_LR_model.save('models/flights_ontime/OneNeuron_LR_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TensorBoard for best 1-neuron model\n",
    "The TensorBoard dashboard shows plots generated from training logs that provide insight into the training of a model. \n",
    "\n",
    "The time series tab shows several plots within expandable windows for our one-neuronal model, \"dense_#\" and for the loss and training metrics by epoch.  Under dense_#, TesnorBoard shows histograms of the bias values \"bias_0\" and weight values, \"kernel_0\" by epoch. The epoch number is on the y-axis with the first epochs at the top and the most recent epoch at the bottom. These plots show how the bias and weight distributions change with training. For the one-neuron model, the weights appear to stabilize well before the training ended, at around 50 to 60 epochs, while the bias terms continued to drift downwards with training.\n",
    "\n",
    "The other plots under Time Series show how the loss and metrics change with training epoch or iteration (batch number). Based on these plots, the one-neuron model appears to have high bias and high variance. High bias is indicated by the large difference in loss and performance metrics between the train and validation datasets. High variance is indicated by the large variation in the validation loss, mae, and r-squared metrics that persists through training, even after these metrics stabilize on the training set at around epoch 40. Taken together, the one-neuron model appears to lack flexibility and would also benefit from having more data to train the weights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 3470), started 10:23:51 ago. (Use '!kill 3470' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-213b8de153dc2086\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-213b8de153dc2086\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneNeuron/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evalute the best 1-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 580us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 122.72\n",
      "- Validation MSE: 32874.14\n",
      "- Validation R^2: 0.679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "OneNeuron_LR_model = models.load_model('models/flights_ontime/OneNeuron_LR_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneNeuron_LR_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "OneNeuron_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneNeuron_val_mae:.2f}\n",
    "- Validation MSE: {OneNeuron_val_mse:.2f}\n",
    "- Validation R^2: {OneNeuron_val_r2:.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW DENSE NEURAL NETWORK (SDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SDNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=1, max_value=2, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.02, max_value=0.03, default=0.0)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=n_neurons, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=L2(l2_regularization)))\n",
    "    \n",
    "    for layer in range(n_hidden-1):\n",
    "        model.add(Dense(units=n_neurons, \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=L2(l2_regularization)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    if n_hidden > 0:\n",
    "        model.add(Dense(units=n_neurons, \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=L2(l2_regularization)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 02s]\n",
      "val_loss: 0.4439461827278137\n",
      "\n",
      "Best val_loss So Far: 0.38801226019859314\n",
      "Total elapsed time: 00h 08m 06s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_BO = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_BO = kt.BayesianOptimization(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    num_initial_points=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"bayesian_optimization_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_BO.search(train_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             callbacks=[early_stopping_BO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 04s]\n",
      "val_loss: 0.4617564529180527\n",
      "\n",
      "Best val_loss So Far: 0.3983249217271805\n",
      "Total elapsed time: 00h 09m 17s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"random_search_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_RS.search(train_ds_flights_ontime_d,\n",
    "                epochs=500, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for best SDNN model using hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 05s]\n",
      "val_loss: 0.7675652503967285\n",
      "\n",
      "Best val_loss So Far: 0.3679744005203247\n",
      "Total elapsed time: 00h 16m 34s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_HB = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"hyperband_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_HB.search(train_ds_flights_ontime_d,\n",
    "                epochs=600, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_HB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best SDNN model (from hyperband search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters from Hyperband tuner\n",
    "best_hps = SDNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Initialize Early Stopping\n",
    "early_stopping_SDNN_best = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/SDNN_HB/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/SDNN_HB/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "SDNN_model = SDNN_tuner_HB.hypermodel.build(best_hps)\n",
    "history = SDNN_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_SDNN_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "SDNN_model.save('models/flights_ontime/SDNN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 27548), started 14:03:26 ago. (Use '!kill 27548' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-21ff156c93709da5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-21ff156c93709da5\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard\n",
    "%tensorboard --logdir logs/flights_ontime/SDNN_HB/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 8\n",
      "- Learning Rate: 0.006415517608465564\n",
      "- Dropout Rate: 0.024849650762982137\n",
      "- L2 Regularization: 0.0007243411260176605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "SDNN_model = models.load_model('models/flights_ontime/SDNN_model')\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- L2 Regularization: {best_hps.get('l2_regularization')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 720       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801 (3.13 KB)\n",
      "Trainable params: 801 (3.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SDNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 510us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 115.27\n",
      "- Validation MSE: 30386.71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inverse transform the predicted values and get validation MAE, MSE\n",
    "y_pred = SDNN_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "SDNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "SDNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {SDNN_val_mae:.2f}\n",
    "- Validation MSE: {SDNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECURRENT NEURAL NETWORK (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lag variables from X train, val, and test sets\n",
    "The lag variables are redundant with the recurrent loops of an RNN that feed historical information into each neuron. I dropped the lag variables to reduce the redundancy and dimensionality in the RNN datasets. However, the lag variables may have value in an RNN despite introducing redundancy and multicolinearity. Time permitting, I'll retain the lag variables and train the RNN's a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_X_train_full = X_train_full.drop(lag_cols, axis=1)\n",
    "rnn_X_train = X_train.drop(lag_cols, axis=1)\n",
    "rnn_X_val = X_val.drop(lag_cols, axis=1)\n",
    "rnn_X_test = X_test.drop(lag_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN column transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_numeric_cols = [col for col in numeric_cols if col not in lag_cols]\n",
    "\n",
    "# Fit transformers to the training data\n",
    "rnn_f_scaler = StandardScaler()\n",
    "rnn_f_scaler.fit(rnn_X_train[rnn_numeric_cols])\n",
    "\n",
    "# Create a function to preprocess TensorFlow datasets\n",
    "def rnn_preprocess(features, target):\n",
    "    scaled_features = rnn_f_scaler.transform(features[rnn_numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1)) # Scaling the target can speed up training, improve convergence, and reduce the impact of outliers for RNNs\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Transform the data\n",
    "X_train_rnn, y_train_rnn = rnn_preprocess(X_train, y_train)\n",
    "X_val_rnn, y_val_rnn = rnn_preprocess(X_val, y_val)\n",
    "X_test_rnn, y_test_rnn = rnn_preprocess(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create timeseries datasets\n",
    "\n",
    "The timeseries datasets below use a sequence length of 7 and a time step of 1. Each recurrent neuron will process the sequences in 7 recurrent steps, updating its hidden state based on the current input and the previous hidden state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "seq_length = 7\n",
    "batch_size = 32\n",
    "\n",
    "train_rnn = timeseries_dataset_from_array(\n",
    "    data = X_train_rnn, \n",
    "    targets = y_train_rnn,\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "val_rnn = timeseries_dataset_from_array(\n",
    "    data = X_val_rnn, \n",
    "    targets = y_val_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_rnn = timeseries_dataset_from_array(\n",
    "    data = X_test_rnn, \n",
    "    targets = y_test_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE RECURRENT NEURON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron RNN hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build one-neuron RNN hypermodel\n",
    "def OneRNN_model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units = 1, \n",
    "                  input_shape = (None, X_train_rnn.shape[1]), \n",
    "                  kernel_regularizer=L2(kernel_reg),\n",
    "                  recurrent_regularizer=L2(recurr_reg),\n",
    "                  )\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 21s]\n",
      "val_loss: 1.2453628778457642\n",
      "\n",
      "Best val_loss So Far: 1.1035436391830444\n",
      "Total elapsed time: 00h 49m 19s\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Hyperband tuner\n",
    "OneRNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = OneRNN_model_builder,\n",
    "    objective='val_loss',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    directory='logs/flights_ontime/OneRNN',\n",
    "    project_name='hyperband_tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneRNN_tuner_HB.search(train_rnn, \n",
    "             validation_data=val_rnn, \n",
    "             epochs=100, \n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best one-neuron RNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "best_hps = OneRNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneRNN_model = OneRNN_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/OneRNN/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/OneRNN/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = OneRNN_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneRNN_model.save('models/flights_ontime/OneRNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 41285), started 0:00:05 ago. (Use '!kill 41285' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ea377e98d930e2ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ea377e98d930e2ca\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneRNN/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evaluate the best one-neuron RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 840us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 252.07\n",
      "- Validation MSE: 107981.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OneRNN_model = models.load_model('models/flights_ontime/OneRNN_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneRNN_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "OneRNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneRNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneRNN_val_mae:.2f}\n",
    "- Validation MSE: {OneRNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build shallow RNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=1, max_value=2, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    recurrent_dropout_rate = hp.Float('recurrent_dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer with dropout\n",
    "    model.add(Dropout(dropout_rate, \n",
    "                      input_shape=(None, X_train_rnn.shape[1])))\n",
    "\n",
    "    # First n-1 Hidden layers\n",
    "    for _ in range(n_hidden-1):\n",
    "        model.add(SimpleRNN(units=n_neurons, \n",
    "                            activation='relu', \n",
    "                            return_sequences=True,\n",
    "                            kernel_regularizer=L2(kernel_reg),\n",
    "                            recurrent_regularizer=L2(recurr_reg),\n",
    "                            dropout = dropout_rate,\n",
    "                            recurrent_dropout = recurrent_dropout_rate))\n",
    "\n",
    "    # Last hidden layer\n",
    "    if n_hidden > 0:\n",
    "        model.add(SimpleRNN(units=n_neurons, \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=L2(kernel_reg),\n",
    "                            recurrent_regularizer=L2(recurr_reg),\n",
    "                            dropout = dropout_rate,\n",
    "                            recurrent_dropout = recurrent_dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using a random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 15s]\n",
      "val_loss: 1.264518141746521\n",
      "\n",
      "Best val_loss So Far: 1.124204158782959\n",
      "Total elapsed time: 00h 10m 11s\n",
      "\n",
      "Search: Running Trial #26\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |1                 |n_hidden\n",
      "13                |26                |n_neurons\n",
      "0.00030422        |0.0055101         |learning_rate\n",
      "0.32277           |0.21213           |dropout_rate\n",
      "0.43681           |0.47244           |recurrent_dropout_rate\n",
      "0.00017468        |0.006274          |kernel_reg\n",
      "0.03678           |0.01079           |recurr_reg\n",
      "\n",
      "Epoch 1/500\n",
      "43/43 [==============================] - 1s 5ms/step - loss: 23.9736 - mean_absolute_error: 3.4789 - val_loss: 5.0717 - val_mean_absolute_error: 1.7508\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14.4724 - mean_absolute_error: 2.6433 - val_loss: 3.7997 - val_mean_absolute_error: 1.4154\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 10.0611 - mean_absolute_error: 2.2159 - val_loss: 3.3012 - val_mean_absolute_error: 1.2457\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 7.4112 - mean_absolute_error: 1.9309 - val_loss: 3.0874 - val_mean_absolute_error: 1.1624\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 6.2317 - mean_absolute_error: 1.7917 - val_loss: 2.9503 - val_mean_absolute_error: 1.1073\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.9081 - mean_absolute_error: 1.5558 - val_loss: 2.8335 - val_mean_absolute_error: 1.0714\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3530 - mean_absolute_error: 1.4997 - val_loss: 2.7405 - val_mean_absolute_error: 1.0453\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3267 - mean_absolute_error: 1.4833 - val_loss: 2.7089 - val_mean_absolute_error: 1.0280\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.8107 - mean_absolute_error: 1.3574 - val_loss: 2.6490 - val_mean_absolute_error: 1.0106\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 3.3602 - mean_absolute_error: 1.3215 - val_loss: 2.6128 - val_mean_absolute_error: 0.9944\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.1781 - mean_absolute_error: 1.2638 - val_loss: 2.5835 - val_mean_absolute_error: 0.9791\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9005 - mean_absolute_error: 1.2213 - val_loss: 2.5635 - val_mean_absolute_error: 0.9660\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.0156 - mean_absolute_error: 1.2109 - val_loss: 2.5116 - val_mean_absolute_error: 0.9554\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9074 - mean_absolute_error: 1.1719 - val_loss: 2.4666 - val_mean_absolute_error: 0.9443\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5431 - mean_absolute_error: 1.1325 - val_loss: 2.4584 - val_mean_absolute_error: 0.9397\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7084 - mean_absolute_error: 1.1457 - val_loss: 2.4308 - val_mean_absolute_error: 0.9354\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3295 - mean_absolute_error: 1.0736 - val_loss: 2.4289 - val_mean_absolute_error: 0.9328\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4867 - mean_absolute_error: 1.0968 - val_loss: 2.3907 - val_mean_absolute_error: 0.9292\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2197 - mean_absolute_error: 1.0403 - val_loss: 2.3882 - val_mean_absolute_error: 0.9256\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2441 - mean_absolute_error: 1.0208 - val_loss: 2.3810 - val_mean_absolute_error: 0.9229\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2777 - mean_absolute_error: 1.0340 - val_loss: 2.3497 - val_mean_absolute_error: 0.9194\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1225 - mean_absolute_error: 1.0031 - val_loss: 2.3459 - val_mean_absolute_error: 0.9174\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0509 - mean_absolute_error: 0.9860 - val_loss: 2.3447 - val_mean_absolute_error: 0.9159\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1264 - mean_absolute_error: 0.9712 - val_loss: 2.3254 - val_mean_absolute_error: 0.9154\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0405 - mean_absolute_error: 0.9633 - val_loss: 2.3194 - val_mean_absolute_error: 0.9145\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9489 - mean_absolute_error: 0.9468 - val_loss: 2.3067 - val_mean_absolute_error: 0.9125\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0341 - mean_absolute_error: 0.9544 - val_loss: 2.2887 - val_mean_absolute_error: 0.9103\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9666 - mean_absolute_error: 0.9293 - val_loss: 2.2627 - val_mean_absolute_error: 0.9073\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8668 - mean_absolute_error: 0.9219 - val_loss: 2.2590 - val_mean_absolute_error: 0.9057\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7993 - mean_absolute_error: 0.9042 - val_loss: 2.2507 - val_mean_absolute_error: 0.9046\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8423 - mean_absolute_error: 0.9018 - val_loss: 2.2453 - val_mean_absolute_error: 0.9041\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8046 - mean_absolute_error: 0.9005 - val_loss: 2.2348 - val_mean_absolute_error: 0.9030\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8740 - mean_absolute_error: 0.9107 - val_loss: 2.2089 - val_mean_absolute_error: 0.9003\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8210 - mean_absolute_error: 0.9112 - val_loss: 2.1976 - val_mean_absolute_error: 0.8987\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7867 - mean_absolute_error: 0.8874 - val_loss: 2.1895 - val_mean_absolute_error: 0.8984\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7248 - mean_absolute_error: 0.8639 - val_loss: 2.1714 - val_mean_absolute_error: 0.8973\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7682 - mean_absolute_error: 0.8911 - val_loss: 2.1600 - val_mean_absolute_error: 0.8960\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6994 - mean_absolute_error: 0.8700 - val_loss: 2.1487 - val_mean_absolute_error: 0.8957\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6544 - mean_absolute_error: 0.8563 - val_loss: 2.1398 - val_mean_absolute_error: 0.8947\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6671 - mean_absolute_error: 0.8621 - val_loss: 2.1301 - val_mean_absolute_error: 0.8927\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7000 - mean_absolute_error: 0.8653 - val_loss: 2.1212 - val_mean_absolute_error: 0.8911\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6268 - mean_absolute_error: 0.8496 - val_loss: 2.1146 - val_mean_absolute_error: 0.8895\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7034 - mean_absolute_error: 0.8517 - val_loss: 2.0866 - val_mean_absolute_error: 0.8873\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6061 - mean_absolute_error: 0.8471 - val_loss: 2.0841 - val_mean_absolute_error: 0.8865\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5636 - mean_absolute_error: 0.8335 - val_loss: 2.0798 - val_mean_absolute_error: 0.8857\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6267 - mean_absolute_error: 0.8450 - val_loss: 2.0733 - val_mean_absolute_error: 0.8848\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5709 - mean_absolute_error: 0.8269 - val_loss: 2.0602 - val_mean_absolute_error: 0.8839\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5516 - mean_absolute_error: 0.8195 - val_loss: 2.0471 - val_mean_absolute_error: 0.8831\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5353 - mean_absolute_error: 0.8183 - val_loss: 2.0362 - val_mean_absolute_error: 0.8821\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6000 - mean_absolute_error: 0.8185 - val_loss: 2.0152 - val_mean_absolute_error: 0.8801\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5312 - mean_absolute_error: 0.8216 - val_loss: 2.0079 - val_mean_absolute_error: 0.8794\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5829 - mean_absolute_error: 0.8311 - val_loss: 1.9987 - val_mean_absolute_error: 0.8782\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4742 - mean_absolute_error: 0.7980 - val_loss: 1.9940 - val_mean_absolute_error: 0.8778\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5477 - mean_absolute_error: 0.8248 - val_loss: 1.9909 - val_mean_absolute_error: 0.8761\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5039 - mean_absolute_error: 0.8046 - val_loss: 1.9855 - val_mean_absolute_error: 0.8756\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4895 - mean_absolute_error: 0.8087 - val_loss: 1.9826 - val_mean_absolute_error: 0.8750\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5167 - mean_absolute_error: 0.8194 - val_loss: 1.9774 - val_mean_absolute_error: 0.8746\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4949 - mean_absolute_error: 0.8058 - val_loss: 1.9694 - val_mean_absolute_error: 0.8743\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5130 - mean_absolute_error: 0.8178 - val_loss: 1.9693 - val_mean_absolute_error: 0.8740\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5503 - mean_absolute_error: 0.8112 - val_loss: 1.9426 - val_mean_absolute_error: 0.8724\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4768 - mean_absolute_error: 0.8075 - val_loss: 1.9366 - val_mean_absolute_error: 0.8713\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4812 - mean_absolute_error: 0.7979 - val_loss: 1.9356 - val_mean_absolute_error: 0.8709\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4937 - mean_absolute_error: 0.7993 - val_loss: 1.9271 - val_mean_absolute_error: 0.8698\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5001 - mean_absolute_error: 0.8151 - val_loss: 1.9187 - val_mean_absolute_error: 0.8689\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4172 - mean_absolute_error: 0.7882 - val_loss: 1.9112 - val_mean_absolute_error: 0.8683\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4511 - mean_absolute_error: 0.7913 - val_loss: 1.9067 - val_mean_absolute_error: 0.8682\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4918 - mean_absolute_error: 0.8159 - val_loss: 1.8992 - val_mean_absolute_error: 0.8678\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4588 - mean_absolute_error: 0.7920 - val_loss: 1.8788 - val_mean_absolute_error: 0.8663\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4541 - mean_absolute_error: 0.8056 - val_loss: 1.8776 - val_mean_absolute_error: 0.8660\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4304 - mean_absolute_error: 0.7920 - val_loss: 1.8743 - val_mean_absolute_error: 0.8655\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4189 - mean_absolute_error: 0.7895 - val_loss: 1.8701 - val_mean_absolute_error: 0.8651\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4331 - mean_absolute_error: 0.7855 - val_loss: 1.8502 - val_mean_absolute_error: 0.8643\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3735 - mean_absolute_error: 0.7680 - val_loss: 1.8472 - val_mean_absolute_error: 0.8639\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4076 - mean_absolute_error: 0.7912 - val_loss: 1.8442 - val_mean_absolute_error: 0.8636\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4083 - mean_absolute_error: 0.7830 - val_loss: 1.8416 - val_mean_absolute_error: 0.8638\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3836 - mean_absolute_error: 0.7686 - val_loss: 1.8358 - val_mean_absolute_error: 0.8637\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4060 - mean_absolute_error: 0.7873 - val_loss: 1.8318 - val_mean_absolute_error: 0.8633\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3745 - mean_absolute_error: 0.7836 - val_loss: 1.8239 - val_mean_absolute_error: 0.8628\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4426 - mean_absolute_error: 0.7986 - val_loss: 1.7989 - val_mean_absolute_error: 0.8607\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4210 - mean_absolute_error: 0.7939 - val_loss: 1.7898 - val_mean_absolute_error: 0.8596\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3899 - mean_absolute_error: 0.7771 - val_loss: 1.7824 - val_mean_absolute_error: 0.8591\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3663 - mean_absolute_error: 0.7779 - val_loss: 1.7789 - val_mean_absolute_error: 0.8584\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3860 - mean_absolute_error: 0.7773 - val_loss: 1.7722 - val_mean_absolute_error: 0.8581\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3950 - mean_absolute_error: 0.7866 - val_loss: 1.7546 - val_mean_absolute_error: 0.8566\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3490 - mean_absolute_error: 0.7732 - val_loss: 1.7526 - val_mean_absolute_error: 0.8564\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3243 - mean_absolute_error: 0.7676 - val_loss: 1.7486 - val_mean_absolute_error: 0.8558\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3517 - mean_absolute_error: 0.7779 - val_loss: 1.7453 - val_mean_absolute_error: 0.8550\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3238 - mean_absolute_error: 0.7646 - val_loss: 1.7446 - val_mean_absolute_error: 0.8549\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3432 - mean_absolute_error: 0.7740 - val_loss: 1.7416 - val_mean_absolute_error: 0.8550\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3355 - mean_absolute_error: 0.7764 - val_loss: 1.7379 - val_mean_absolute_error: 0.8550\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3341 - mean_absolute_error: 0.7731 - val_loss: 1.7350 - val_mean_absolute_error: 0.8548\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3329 - mean_absolute_error: 0.7754 - val_loss: 1.7304 - val_mean_absolute_error: 0.8541\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3138 - mean_absolute_error: 0.7702 - val_loss: 1.7252 - val_mean_absolute_error: 0.8534\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3429 - mean_absolute_error: 0.7726 - val_loss: 1.7053 - val_mean_absolute_error: 0.8523\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3093 - mean_absolute_error: 0.7694 - val_loss: 1.6992 - val_mean_absolute_error: 0.8523\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2986 - mean_absolute_error: 0.7705 - val_loss: 1.6948 - val_mean_absolute_error: 0.8523\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3242 - mean_absolute_error: 0.7670 - val_loss: 1.6762 - val_mean_absolute_error: 0.8510\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3420 - mean_absolute_error: 0.7816 - val_loss: 1.6747 - val_mean_absolute_error: 0.8507\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3058 - mean_absolute_error: 0.7717 - val_loss: 1.6718 - val_mean_absolute_error: 0.8505\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2822 - mean_absolute_error: 0.7643 - val_loss: 1.6676 - val_mean_absolute_error: 0.8508\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3065 - mean_absolute_error: 0.7718 - val_loss: 1.6638 - val_mean_absolute_error: 0.8510\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3101 - mean_absolute_error: 0.7751 - val_loss: 1.6457 - val_mean_absolute_error: 0.8499\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2878 - mean_absolute_error: 0.7657 - val_loss: 1.6418 - val_mean_absolute_error: 0.8493\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2806 - mean_absolute_error: 0.7665 - val_loss: 1.6383 - val_mean_absolute_error: 0.8490\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3142 - mean_absolute_error: 0.7764 - val_loss: 1.6189 - val_mean_absolute_error: 0.8481\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2601 - mean_absolute_error: 0.7593 - val_loss: 1.6052 - val_mean_absolute_error: 0.8466\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2682 - mean_absolute_error: 0.7658 - val_loss: 1.6036 - val_mean_absolute_error: 0.8462\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2552 - mean_absolute_error: 0.7584 - val_loss: 1.6019 - val_mean_absolute_error: 0.8465\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2804 - mean_absolute_error: 0.7732 - val_loss: 1.5973 - val_mean_absolute_error: 0.8462\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2818 - mean_absolute_error: 0.7773 - val_loss: 1.5983 - val_mean_absolute_error: 0.8458\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2510 - mean_absolute_error: 0.7634 - val_loss: 1.5962 - val_mean_absolute_error: 0.8458\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2573 - mean_absolute_error: 0.7699 - val_loss: 1.5946 - val_mean_absolute_error: 0.8458\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2676 - mean_absolute_error: 0.7712 - val_loss: 1.5944 - val_mean_absolute_error: 0.8453\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2393 - mean_absolute_error: 0.7553 - val_loss: 1.5900 - val_mean_absolute_error: 0.8451\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2269 - mean_absolute_error: 0.7590 - val_loss: 1.5870 - val_mean_absolute_error: 0.8454\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2386 - mean_absolute_error: 0.7640 - val_loss: 1.5837 - val_mean_absolute_error: 0.8452\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2495 - mean_absolute_error: 0.7636 - val_loss: 1.5824 - val_mean_absolute_error: 0.8452\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2427 - mean_absolute_error: 0.7660 - val_loss: 1.5783 - val_mean_absolute_error: 0.8450\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2319 - mean_absolute_error: 0.7634 - val_loss: 1.5601 - val_mean_absolute_error: 0.8433\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2361 - mean_absolute_error: 0.7630 - val_loss: 1.5574 - val_mean_absolute_error: 0.8434\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2363 - mean_absolute_error: 0.7651 - val_loss: 1.5455 - val_mean_absolute_error: 0.8423\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2295 - mean_absolute_error: 0.7611 - val_loss: 1.5303 - val_mean_absolute_error: 0.8414\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2168 - mean_absolute_error: 0.7589 - val_loss: 1.5297 - val_mean_absolute_error: 0.8415\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2436 - mean_absolute_error: 0.7659 - val_loss: 1.5193 - val_mean_absolute_error: 0.8403\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2326 - mean_absolute_error: 0.7617 - val_loss: 1.5171 - val_mean_absolute_error: 0.8404\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2133 - mean_absolute_error: 0.7675 - val_loss: 1.5140 - val_mean_absolute_error: 0.8407\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2113 - mean_absolute_error: 0.7617 - val_loss: 1.5092 - val_mean_absolute_error: 0.8403\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2060 - mean_absolute_error: 0.7598 - val_loss: 1.5087 - val_mean_absolute_error: 0.8406\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2075 - mean_absolute_error: 0.7639 - val_loss: 1.5091 - val_mean_absolute_error: 0.8409\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1946 - mean_absolute_error: 0.7569 - val_loss: 1.5056 - val_mean_absolute_error: 0.8409\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2001 - mean_absolute_error: 0.7659 - val_loss: 1.5052 - val_mean_absolute_error: 0.8409\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1951 - mean_absolute_error: 0.7614 - val_loss: 1.4952 - val_mean_absolute_error: 0.8409\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1998 - mean_absolute_error: 0.7623 - val_loss: 1.4944 - val_mean_absolute_error: 0.8414\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1884 - mean_absolute_error: 0.7581 - val_loss: 1.4934 - val_mean_absolute_error: 0.8417\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1950 - mean_absolute_error: 0.7605 - val_loss: 1.4891 - val_mean_absolute_error: 0.8418\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1767 - mean_absolute_error: 0.7564 - val_loss: 1.4871 - val_mean_absolute_error: 0.8422\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1787 - mean_absolute_error: 0.7615 - val_loss: 1.4876 - val_mean_absolute_error: 0.8428\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1905 - mean_absolute_error: 0.7634 - val_loss: 1.4848 - val_mean_absolute_error: 0.8431\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1775 - mean_absolute_error: 0.7660 - val_loss: 1.4836 - val_mean_absolute_error: 0.8433\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1624 - mean_absolute_error: 0.7570 - val_loss: 1.4790 - val_mean_absolute_error: 0.8436\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1668 - mean_absolute_error: 0.7600 - val_loss: 1.4785 - val_mean_absolute_error: 0.8442\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1639 - mean_absolute_error: 0.7569 - val_loss: 1.4788 - val_mean_absolute_error: 0.8444\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1695 - mean_absolute_error: 0.7629 - val_loss: 1.4767 - val_mean_absolute_error: 0.8442\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1540 - mean_absolute_error: 0.7583 - val_loss: 1.4766 - val_mean_absolute_error: 0.8442\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1592 - mean_absolute_error: 0.7572 - val_loss: 1.4726 - val_mean_absolute_error: 0.8444\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1734 - mean_absolute_error: 0.7626 - val_loss: 1.4577 - val_mean_absolute_error: 0.8433\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1582 - mean_absolute_error: 0.7627 - val_loss: 1.4501 - val_mean_absolute_error: 0.8426\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1553 - mean_absolute_error: 0.7595 - val_loss: 1.4507 - val_mean_absolute_error: 0.8425\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1436 - mean_absolute_error: 0.7596 - val_loss: 1.4479 - val_mean_absolute_error: 0.8428\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1411 - mean_absolute_error: 0.7548 - val_loss: 1.4383 - val_mean_absolute_error: 0.8425\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1398 - mean_absolute_error: 0.7557 - val_loss: 1.4359 - val_mean_absolute_error: 0.8426\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1364 - mean_absolute_error: 0.7591 - val_loss: 1.4330 - val_mean_absolute_error: 0.8425\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1469 - mean_absolute_error: 0.7661 - val_loss: 1.4337 - val_mean_absolute_error: 0.8430\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1270 - mean_absolute_error: 0.7571 - val_loss: 1.4353 - val_mean_absolute_error: 0.8432\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1347 - mean_absolute_error: 0.7561 - val_loss: 1.4345 - val_mean_absolute_error: 0.8437\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1419 - mean_absolute_error: 0.7632 - val_loss: 1.4387 - val_mean_absolute_error: 0.8445\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1173 - mean_absolute_error: 0.7551 - val_loss: 1.4388 - val_mean_absolute_error: 0.8451\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1341 - mean_absolute_error: 0.7611 - val_loss: 1.4376 - val_mean_absolute_error: 0.8453\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1217 - mean_absolute_error: 0.7559 - val_loss: 1.4386 - val_mean_absolute_error: 0.8460\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1054 - mean_absolute_error: 0.7516 - val_loss: 1.4393 - val_mean_absolute_error: 0.8463\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1305 - mean_absolute_error: 0.7594 - val_loss: 1.4219 - val_mean_absolute_error: 0.8446\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1160 - mean_absolute_error: 0.7575 - val_loss: 1.4191 - val_mean_absolute_error: 0.8448\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1029 - mean_absolute_error: 0.7577 - val_loss: 1.4167 - val_mean_absolute_error: 0.8446\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1178 - mean_absolute_error: 0.7596 - val_loss: 1.4180 - val_mean_absolute_error: 0.8447\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1209 - mean_absolute_error: 0.7617 - val_loss: 1.4060 - val_mean_absolute_error: 0.8438\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1096 - mean_absolute_error: 0.7589 - val_loss: 1.4034 - val_mean_absolute_error: 0.8438\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1045 - mean_absolute_error: 0.7605 - val_loss: 1.4026 - val_mean_absolute_error: 0.8441\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0944 - mean_absolute_error: 0.7525 - val_loss: 1.4018 - val_mean_absolute_error: 0.8443\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0921 - mean_absolute_error: 0.7508 - val_loss: 1.4007 - val_mean_absolute_error: 0.8444\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0991 - mean_absolute_error: 0.7569 - val_loss: 1.4022 - val_mean_absolute_error: 0.8449\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1065 - mean_absolute_error: 0.7595 - val_loss: 1.4047 - val_mean_absolute_error: 0.8456\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1046 - mean_absolute_error: 0.7592 - val_loss: 1.3913 - val_mean_absolute_error: 0.8446\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0986 - mean_absolute_error: 0.7611 - val_loss: 1.3915 - val_mean_absolute_error: 0.8448\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0975 - mean_absolute_error: 0.7625 - val_loss: 1.3803 - val_mean_absolute_error: 0.8441\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0921 - mean_absolute_error: 0.7560 - val_loss: 1.3807 - val_mean_absolute_error: 0.8447\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0946 - mean_absolute_error: 0.7612 - val_loss: 1.3784 - val_mean_absolute_error: 0.8445\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0876 - mean_absolute_error: 0.7587 - val_loss: 1.3780 - val_mean_absolute_error: 0.8446\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0984 - mean_absolute_error: 0.7595 - val_loss: 1.3681 - val_mean_absolute_error: 0.8439\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0777 - mean_absolute_error: 0.7573 - val_loss: 1.3661 - val_mean_absolute_error: 0.8438\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0880 - mean_absolute_error: 0.7613 - val_loss: 1.3646 - val_mean_absolute_error: 0.8439\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0839 - mean_absolute_error: 0.7620 - val_loss: 1.3623 - val_mean_absolute_error: 0.8437\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0776 - mean_absolute_error: 0.7585 - val_loss: 1.3626 - val_mean_absolute_error: 0.8439\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0720 - mean_absolute_error: 0.7561 - val_loss: 1.3613 - val_mean_absolute_error: 0.8439\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0665 - mean_absolute_error: 0.7571 - val_loss: 1.3644 - val_mean_absolute_error: 0.8445\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0662 - mean_absolute_error: 0.7521 - val_loss: 1.3651 - val_mean_absolute_error: 0.8446\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0604 - mean_absolute_error: 0.7555 - val_loss: 1.3661 - val_mean_absolute_error: 0.8450\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0682 - mean_absolute_error: 0.7597 - val_loss: 1.3640 - val_mean_absolute_error: 0.8450\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0628 - mean_absolute_error: 0.7549 - val_loss: 1.3540 - val_mean_absolute_error: 0.8442\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0731 - mean_absolute_error: 0.7604 - val_loss: 1.3438 - val_mean_absolute_error: 0.8437\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0626 - mean_absolute_error: 0.7553 - val_loss: 1.3443 - val_mean_absolute_error: 0.8441\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0556 - mean_absolute_error: 0.7575 - val_loss: 1.3359 - val_mean_absolute_error: 0.8433\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0645 - mean_absolute_error: 0.7618 - val_loss: 1.3365 - val_mean_absolute_error: 0.8435\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0526 - mean_absolute_error: 0.7555 - val_loss: 1.3356 - val_mean_absolute_error: 0.8434\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0575 - mean_absolute_error: 0.7569 - val_loss: 1.3300 - val_mean_absolute_error: 0.8429\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0468 - mean_absolute_error: 0.7546 - val_loss: 1.3294 - val_mean_absolute_error: 0.8431\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0548 - mean_absolute_error: 0.7575 - val_loss: 1.3328 - val_mean_absolute_error: 0.8441\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0551 - mean_absolute_error: 0.7565 - val_loss: 1.3310 - val_mean_absolute_error: 0.8442\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0562 - mean_absolute_error: 0.7607 - val_loss: 1.3320 - val_mean_absolute_error: 0.8446\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0505 - mean_absolute_error: 0.7548 - val_loss: 1.3323 - val_mean_absolute_error: 0.8450\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0538 - mean_absolute_error: 0.7590 - val_loss: 1.3266 - val_mean_absolute_error: 0.8448\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0397 - mean_absolute_error: 0.7537 - val_loss: 1.3274 - val_mean_absolute_error: 0.8449\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0413 - mean_absolute_error: 0.7531 - val_loss: 1.3265 - val_mean_absolute_error: 0.8449\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0469 - mean_absolute_error: 0.7603 - val_loss: 1.3199 - val_mean_absolute_error: 0.8444\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0388 - mean_absolute_error: 0.7561 - val_loss: 1.3224 - val_mean_absolute_error: 0.8443\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.7595 - val_loss: 1.3213 - val_mean_absolute_error: 0.8443\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0397 - mean_absolute_error: 0.7566 - val_loss: 1.3231 - val_mean_absolute_error: 0.8446\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0413 - mean_absolute_error: 0.7592 - val_loss: 1.3244 - val_mean_absolute_error: 0.8449\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0336 - mean_absolute_error: 0.7533 - val_loss: 1.3238 - val_mean_absolute_error: 0.8453\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0372 - mean_absolute_error: 0.7542 - val_loss: 1.3216 - val_mean_absolute_error: 0.8449\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0362 - mean_absolute_error: 0.7556 - val_loss: 1.3213 - val_mean_absolute_error: 0.8449\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0286 - mean_absolute_error: 0.7547 - val_loss: 1.3207 - val_mean_absolute_error: 0.8449\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0221 - mean_absolute_error: 0.7520 - val_loss: 1.3221 - val_mean_absolute_error: 0.8452\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.0382 - mean_absolute_error: 0.7593 - val_loss: 1.3219 - val_mean_absolute_error: 0.8452\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0184 - mean_absolute_error: 0.7502 - val_loss: 1.3246 - val_mean_absolute_error: 0.8456\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0240 - mean_absolute_error: 0.7533 - val_loss: 1.3268 - val_mean_absolute_error: 0.8460\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0344 - mean_absolute_error: 0.7593 - val_loss: 1.3278 - val_mean_absolute_error: 0.8461\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0239 - mean_absolute_error: 0.7509 - val_loss: 1.3278 - val_mean_absolute_error: 0.8458\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0278 - mean_absolute_error: 0.7592 - val_loss: 1.3286 - val_mean_absolute_error: 0.8461\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0292 - mean_absolute_error: 0.7571 - val_loss: 1.3317 - val_mean_absolute_error: 0.8465\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0272 - mean_absolute_error: 0.7557 - val_loss: 1.3338 - val_mean_absolute_error: 0.8469\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0279 - mean_absolute_error: 0.7587 - val_loss: 1.3362 - val_mean_absolute_error: 0.8477\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0263 - mean_absolute_error: 0.7576 - val_loss: 1.3265 - val_mean_absolute_error: 0.8469\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0238 - mean_absolute_error: 0.7559 - val_loss: 1.3316 - val_mean_absolute_error: 0.8473\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0278 - mean_absolute_error: 0.7553 - val_loss: 1.3225 - val_mean_absolute_error: 0.8465\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0221 - mean_absolute_error: 0.7570 - val_loss: 1.3203 - val_mean_absolute_error: 0.8463\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0201 - mean_absolute_error: 0.7586 - val_loss: 1.3235 - val_mean_absolute_error: 0.8469\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0180 - mean_absolute_error: 0.7590 - val_loss: 1.3133 - val_mean_absolute_error: 0.8455\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0191 - mean_absolute_error: 0.7561 - val_loss: 1.3020 - val_mean_absolute_error: 0.8442\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0226 - mean_absolute_error: 0.7637 - val_loss: 1.3029 - val_mean_absolute_error: 0.8442\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0192 - mean_absolute_error: 0.7529 - val_loss: 1.3064 - val_mean_absolute_error: 0.8446\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0107 - mean_absolute_error: 0.7532 - val_loss: 1.3068 - val_mean_absolute_error: 0.8445\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0007 - mean_absolute_error: 0.7522 - val_loss: 1.3073 - val_mean_absolute_error: 0.8446\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0189 - mean_absolute_error: 0.7571 - val_loss: 1.3083 - val_mean_absolute_error: 0.8447\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0132 - mean_absolute_error: 0.7548 - val_loss: 1.3088 - val_mean_absolute_error: 0.8446\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0139 - mean_absolute_error: 0.7573 - val_loss: 1.3120 - val_mean_absolute_error: 0.8447\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0118 - mean_absolute_error: 0.7552 - val_loss: 1.3159 - val_mean_absolute_error: 0.8451\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0048 - mean_absolute_error: 0.7553 - val_loss: 1.3237 - val_mean_absolute_error: 0.8463\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0096 - mean_absolute_error: 0.7521 - val_loss: 1.3288 - val_mean_absolute_error: 0.8471\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0109 - mean_absolute_error: 0.7574 - val_loss: 1.3248 - val_mean_absolute_error: 0.8467\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0143 - mean_absolute_error: 0.7553 - val_loss: 1.3288 - val_mean_absolute_error: 0.8473\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0023 - mean_absolute_error: 0.7523 - val_loss: 1.3385 - val_mean_absolute_error: 0.8487\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0019 - mean_absolute_error: 0.7525 - val_loss: 1.3410 - val_mean_absolute_error: 0.8490\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0022 - mean_absolute_error: 0.7534 - val_loss: 1.3385 - val_mean_absolute_error: 0.8488\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0026 - mean_absolute_error: 0.7536 - val_loss: 1.3377 - val_mean_absolute_error: 0.8488\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0078 - mean_absolute_error: 0.7564 - val_loss: 1.3407 - val_mean_absolute_error: 0.8494\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0040 - mean_absolute_error: 0.7546 - val_loss: 1.3417 - val_mean_absolute_error: 0.8494\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0084 - mean_absolute_error: 0.7551 - val_loss: 1.3401 - val_mean_absolute_error: 0.8494\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0119 - mean_absolute_error: 0.7591 - val_loss: 1.3441 - val_mean_absolute_error: 0.8497\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0081 - mean_absolute_error: 0.7552 - val_loss: 1.3429 - val_mean_absolute_error: 0.8498\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0055 - mean_absolute_error: 0.7542 - val_loss: 1.3384 - val_mean_absolute_error: 0.8498\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9962 - mean_absolute_error: 0.7519 - val_loss: 1.3388 - val_mean_absolute_error: 0.8498\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9965 - mean_absolute_error: 0.7546 - val_loss: 1.3342 - val_mean_absolute_error: 0.8491\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0067 - mean_absolute_error: 0.7576 - val_loss: 1.3337 - val_mean_absolute_error: 0.8492\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9985 - mean_absolute_error: 0.7524 - val_loss: 1.3204 - val_mean_absolute_error: 0.8482\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0020 - mean_absolute_error: 0.7545 - val_loss: 1.3251 - val_mean_absolute_error: 0.8484\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0141 - mean_absolute_error: 0.7570 - val_loss: 1.3048 - val_mean_absolute_error: 0.8463\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0122 - mean_absolute_error: 0.7616 - val_loss: 1.2921 - val_mean_absolute_error: 0.8447\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0041 - mean_absolute_error: 0.7552 - val_loss: 1.2968 - val_mean_absolute_error: 0.8457\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0049 - mean_absolute_error: 0.7583 - val_loss: 1.3017 - val_mean_absolute_error: 0.8460\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9894 - mean_absolute_error: 0.7508 - val_loss: 1.3072 - val_mean_absolute_error: 0.8470\n",
      "Epoch 261/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9948 - mean_absolute_error: 0.7551 - val_loss: 1.3096 - val_mean_absolute_error: 0.8474\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0054 - mean_absolute_error: 0.7563 - val_loss: 1.2992 - val_mean_absolute_error: 0.8462\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7527 - val_loss: 1.3032 - val_mean_absolute_error: 0.8466\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9795 - mean_absolute_error: 0.7480 - val_loss: 1.3092 - val_mean_absolute_error: 0.8471\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9968 - mean_absolute_error: 0.7541 - val_loss: 1.2995 - val_mean_absolute_error: 0.8460\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9976 - mean_absolute_error: 0.7561 - val_loss: 1.3021 - val_mean_absolute_error: 0.8472\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9990 - mean_absolute_error: 0.7557 - val_loss: 1.2996 - val_mean_absolute_error: 0.8466\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9972 - mean_absolute_error: 0.7530 - val_loss: 1.3019 - val_mean_absolute_error: 0.8473\n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7536 - val_loss: 1.2927 - val_mean_absolute_error: 0.8465\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7487 - val_loss: 1.2960 - val_mean_absolute_error: 0.8467\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9924 - mean_absolute_error: 0.7557 - val_loss: 1.2943 - val_mean_absolute_error: 0.8465\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9909 - mean_absolute_error: 0.7523 - val_loss: 1.2955 - val_mean_absolute_error: 0.8466\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9911 - mean_absolute_error: 0.7555 - val_loss: 1.2998 - val_mean_absolute_error: 0.8471\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0031 - mean_absolute_error: 0.7565 - val_loss: 1.3007 - val_mean_absolute_error: 0.8478\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9854 - mean_absolute_error: 0.7470 - val_loss: 1.2985 - val_mean_absolute_error: 0.8475\n",
      "Epoch 276/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9966 - mean_absolute_error: 0.7553 - val_loss: 1.3006 - val_mean_absolute_error: 0.8480\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9875 - mean_absolute_error: 0.7501 - val_loss: 1.3024 - val_mean_absolute_error: 0.8481\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9785 - mean_absolute_error: 0.7418 - val_loss: 1.3067 - val_mean_absolute_error: 0.8487\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0028 - mean_absolute_error: 0.7580 - val_loss: 1.2956 - val_mean_absolute_error: 0.8481\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7501 - val_loss: 1.2989 - val_mean_absolute_error: 0.8487\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9910 - mean_absolute_error: 0.7561 - val_loss: 1.3017 - val_mean_absolute_error: 0.8491\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7516 - val_loss: 1.2971 - val_mean_absolute_error: 0.8482\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9747 - mean_absolute_error: 0.7454 - val_loss: 1.3026 - val_mean_absolute_error: 0.8492\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9773 - mean_absolute_error: 0.7497 - val_loss: 1.2939 - val_mean_absolute_error: 0.8483\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9811 - mean_absolute_error: 0.7492 - val_loss: 1.2934 - val_mean_absolute_error: 0.8487\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7533 - val_loss: 1.2927 - val_mean_absolute_error: 0.8479\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9923 - mean_absolute_error: 0.7587 - val_loss: 1.2955 - val_mean_absolute_error: 0.8475\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9882 - mean_absolute_error: 0.7493 - val_loss: 1.2885 - val_mean_absolute_error: 0.8468\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7527 - val_loss: 1.2918 - val_mean_absolute_error: 0.8474\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9899 - mean_absolute_error: 0.7537 - val_loss: 1.2957 - val_mean_absolute_error: 0.8476\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9885 - mean_absolute_error: 0.7517 - val_loss: 1.2764 - val_mean_absolute_error: 0.8454\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9943 - mean_absolute_error: 0.7537 - val_loss: 1.2643 - val_mean_absolute_error: 0.8452\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9962 - mean_absolute_error: 0.7559 - val_loss: 1.2670 - val_mean_absolute_error: 0.8457\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9929 - mean_absolute_error: 0.7558 - val_loss: 1.2704 - val_mean_absolute_error: 0.8471\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9916 - mean_absolute_error: 0.7562 - val_loss: 1.2761 - val_mean_absolute_error: 0.8478\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9890 - mean_absolute_error: 0.7585 - val_loss: 1.2743 - val_mean_absolute_error: 0.8481\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9816 - mean_absolute_error: 0.7517 - val_loss: 1.2739 - val_mean_absolute_error: 0.8479\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9877 - mean_absolute_error: 0.7518 - val_loss: 1.2777 - val_mean_absolute_error: 0.8486\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9825 - mean_absolute_error: 0.7519 - val_loss: 1.2835 - val_mean_absolute_error: 0.8490\n",
      "Epoch 300/500\n",
      "28/43 [==================>...........] - ETA: 0s - loss: 0.9725 - mean_absolute_error: 0.7515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m RNN_shallow_tuner_RS \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m      2\u001b[0m     build_model,\n\u001b[1;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      5\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mRNN_shallow_tuner_RS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_RS = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_RS.search(train_rnn, epochs=500, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 08s]\n",
      "val_loss: 1.227628469467163\n",
      "\n",
      "Best val_loss So Far: 1.1422590017318726\n",
      "Total elapsed time: 00h 07m 13s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_BO = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    num_initial_points=2,\n",
    "    overwrite=True\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_BO.search(train_rnn, epochs=50, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Hyperband tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 34s]\n",
      "val_loss: 1.2451832294464111\n",
      "\n",
      "Best val_loss So Far: 1.0942782163619995\n",
      "Total elapsed time: 07h 40m 01s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_HB = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_HB.search(train_rnn, \n",
    "                            epochs=600, \n",
    "                            validation_data=val_rnn, \n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save the best shallow RNN model\n",
    "The Hyperband tuner produced the best model based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "43/43 [==============================] - 2s 9ms/step - loss: 1.9077 - mean_absolute_error: 0.9060 - val_loss: 1.6102 - val_mean_absolute_error: 0.8525\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3958 - mean_absolute_error: 0.7943 - val_loss: 1.7082 - val_mean_absolute_error: 0.8732\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1835 - mean_absolute_error: 0.7711 - val_loss: 1.3277 - val_mean_absolute_error: 0.8421\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1280 - mean_absolute_error: 0.7745 - val_loss: 1.1457 - val_mean_absolute_error: 0.8015\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0538 - mean_absolute_error: 0.7519 - val_loss: 1.3006 - val_mean_absolute_error: 0.8337\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0449 - mean_absolute_error: 0.7610 - val_loss: 1.3722 - val_mean_absolute_error: 0.8507\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0194 - mean_absolute_error: 0.7571 - val_loss: 1.3136 - val_mean_absolute_error: 0.8405\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0197 - mean_absolute_error: 0.7586 - val_loss: 1.4211 - val_mean_absolute_error: 0.8577\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0209 - mean_absolute_error: 0.7611 - val_loss: 1.2839 - val_mean_absolute_error: 0.8407\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0282 - mean_absolute_error: 0.7602 - val_loss: 1.6559 - val_mean_absolute_error: 0.8737\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0320 - mean_absolute_error: 0.7592 - val_loss: 1.4446 - val_mean_absolute_error: 0.8567\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0010 - mean_absolute_error: 0.7594 - val_loss: 1.3710 - val_mean_absolute_error: 0.8454\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0042 - mean_absolute_error: 0.7577 - val_loss: 1.2030 - val_mean_absolute_error: 0.8310\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0076 - mean_absolute_error: 0.7594 - val_loss: 1.3729 - val_mean_absolute_error: 0.8553\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7576 - val_loss: 1.2823 - val_mean_absolute_error: 0.8451\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0010 - mean_absolute_error: 0.7632 - val_loss: 1.2467 - val_mean_absolute_error: 0.8377\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9953 - mean_absolute_error: 0.7504 - val_loss: 1.3444 - val_mean_absolute_error: 0.8467\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9910 - mean_absolute_error: 0.7517 - val_loss: 1.3334 - val_mean_absolute_error: 0.8527\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9882 - mean_absolute_error: 0.7593 - val_loss: 1.3639 - val_mean_absolute_error: 0.8475\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9834 - mean_absolute_error: 0.7471 - val_loss: 1.2822 - val_mean_absolute_error: 0.8402\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0009 - mean_absolute_error: 0.7593 - val_loss: 1.2243 - val_mean_absolute_error: 0.8306\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7597 - val_loss: 1.2742 - val_mean_absolute_error: 0.8417\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7497 - val_loss: 1.3250 - val_mean_absolute_error: 0.8499\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9949 - mean_absolute_error: 0.7557 - val_loss: 1.3276 - val_mean_absolute_error: 0.8348\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9920 - mean_absolute_error: 0.7535 - val_loss: 1.3549 - val_mean_absolute_error: 0.8423\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9926 - mean_absolute_error: 0.7559 - val_loss: 1.5073 - val_mean_absolute_error: 0.8591\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7461 - val_loss: 1.2561 - val_mean_absolute_error: 0.8300\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9933 - mean_absolute_error: 0.7580 - val_loss: 1.1956 - val_mean_absolute_error: 0.8384\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9971 - mean_absolute_error: 0.7483 - val_loss: 1.2734 - val_mean_absolute_error: 0.8441\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9947 - mean_absolute_error: 0.7608 - val_loss: 1.1871 - val_mean_absolute_error: 0.8148\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9814 - mean_absolute_error: 0.7463 - val_loss: 1.2507 - val_mean_absolute_error: 0.8313\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9924 - mean_absolute_error: 0.7499 - val_loss: 1.3397 - val_mean_absolute_error: 0.8515\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9809 - mean_absolute_error: 0.7558 - val_loss: 1.3108 - val_mean_absolute_error: 0.8442\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9724 - mean_absolute_error: 0.7470 - val_loss: 1.2937 - val_mean_absolute_error: 0.8381\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7461 - val_loss: 1.3305 - val_mean_absolute_error: 0.8528\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7524 - val_loss: 1.3085 - val_mean_absolute_error: 0.8503\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9800 - mean_absolute_error: 0.7528 - val_loss: 1.3288 - val_mean_absolute_error: 0.8572\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9731 - mean_absolute_error: 0.7458 - val_loss: 1.3121 - val_mean_absolute_error: 0.8347\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9960 - mean_absolute_error: 0.7594 - val_loss: 1.3154 - val_mean_absolute_error: 0.8518\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9916 - mean_absolute_error: 0.7618 - val_loss: 1.3504 - val_mean_absolute_error: 0.8490\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9913 - mean_absolute_error: 0.7503 - val_loss: 1.3508 - val_mean_absolute_error: 0.8466\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9917 - mean_absolute_error: 0.7552 - val_loss: 1.3175 - val_mean_absolute_error: 0.8467\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9642 - mean_absolute_error: 0.7410 - val_loss: 1.3192 - val_mean_absolute_error: 0.8347\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9900 - mean_absolute_error: 0.7556 - val_loss: 1.3719 - val_mean_absolute_error: 0.8492\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7443 - val_loss: 1.3907 - val_mean_absolute_error: 0.8565\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9812 - mean_absolute_error: 0.7491 - val_loss: 1.3988 - val_mean_absolute_error: 0.8590\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9873 - mean_absolute_error: 0.7471 - val_loss: 1.4085 - val_mean_absolute_error: 0.8489\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9871 - mean_absolute_error: 0.7521 - val_loss: 1.4225 - val_mean_absolute_error: 0.8571\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9848 - mean_absolute_error: 0.7475 - val_loss: 1.3486 - val_mean_absolute_error: 0.8552\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9950 - mean_absolute_error: 0.7573 - val_loss: 1.2066 - val_mean_absolute_error: 0.8389\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9786 - mean_absolute_error: 0.7450 - val_loss: 1.2899 - val_mean_absolute_error: 0.8505\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9826 - mean_absolute_error: 0.7497 - val_loss: 1.3009 - val_mean_absolute_error: 0.8481\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9727 - mean_absolute_error: 0.7483 - val_loss: 1.4481 - val_mean_absolute_error: 0.8668\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9933 - mean_absolute_error: 0.7531 - val_loss: 1.4069 - val_mean_absolute_error: 0.8549\n",
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = RNN_shallow_tuner_HB.get_best_hyperparameters(num_trials=1)[0]\n",
    "RNN_shallow_model = RNN_shallow_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# TensorBoard setup\n",
    "!rm -rf ./logs/flights_ontime/RNN_shallow/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/RNN_shallow/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = RNN_shallow_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback])\n",
    "\n",
    "# Save the best trained model\n",
    "RNN_shallow_model.save('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6013 (pid 49139), started 0:02:24 ago. (Use '!kill 49139' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-19c2c908334d8da9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-19c2c908334d8da9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/RNN_shallow/tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best shallow RNN model (from Hyperband tuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "RNN_shallow_model = models.load_model('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best shallow RNN model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 14\n",
      "- Learning Rate: 0.006576617683751118\n",
      "- Dropout Rate: 0.24480591203927254\n",
      "- Recurrent Dropout Rate: 0.35738857946677854\n",
      "- Kernel Regularization: 0.0010046913205416215\n",
      "- Recurrent Regularization: 0.04379999321621059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Recurrent Dropout Rate: {best_hps.get('recurrent_dropout_rate')}\n",
    "- Kernel Regularization: {best_hps.get('kernel_reg')}\n",
    "- Recurrent Regularization: {best_hps.get('recurr_reg')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_4 (Dropout)         (None, None, 75)          0         \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 14)                1260      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1275 (4.98 KB)\n",
      "Trainable params: 1275 (4.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best shallow RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 934us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 250.52\n",
      "- Validation MSE: 113235.65\n",
      "- Validation R^2: -0.090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = RNN_shallow_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "shallow_rnn_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {shallow_rnn_val_mae:.2f}\n",
    "- Validation MSE: {shallow_rnn_val_mse:.2f}\n",
    "- Validation R^2: {shallow_rnn_val_r2:.3f}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TYPE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the Elastic Net metrics\n",
    "EN_data = pd.read_csv(\"model_output/elastic_net_results.csv\")\n",
    "LR_mae = EN_data.loc[EN_data['TARGET'] == 'flights_ontime', 'MAE'].values[0]\n",
    "LR_mse = EN_data.loc[EN_data['TARGET'] == 'flights_ontime', 'MSE'].values[0]\n",
    "\n",
    "models = ['Linear Reg', 'One Neuron', 'Shallow NN', 'One RN', 'Shallow RNN']\n",
    "mae = [LR_mae, OneNeuron_val_mae, SDNN_val_mae,  OneRNN_val_mae, shallow_rnn_val_mae]\n",
    "mse = [LR_mse, OneNeuron_val_mse, SDNN_val_mse, OneRNN_val_mse, shallow_rnn_val_mse]\n",
    "\n",
    "# Sort by MAE\n",
    "sorted_indices_mae = np.argsort(mae)\n",
    "sorted_models_mae = [models[i] for i in sorted_indices_mae]\n",
    "sorted_mae = [mae[i] for i in sorted_indices_mae]\n",
    "\n",
    "# Sort by MSE\n",
    "sorted_indices_mse = np.argsort(mse)\n",
    "sorted_models_mse = [models[i] for i in sorted_indices_mse]\n",
    "sorted_mse = [mse[i] for i in sorted_indices_mse]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "bar_width = 0.35\n",
    "\n",
    "fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "\n",
    "# MAE\n",
    "axes[0].bar(x, sorted_mae, bar_width, label='MAE')\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('MAE Scores')\n",
    "axes[0].set_title('MAE Scores by model')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(sorted_models_mae)\n",
    "axes[0].legend()\n",
    "\n",
    "# MSE\n",
    "axes[1].bar(x, sorted_mse, bar_width, label='MSE')\n",
    "axes[1].set_xlabel('Models')\n",
    "axes[1].set_ylabel('MSE Scores')\n",
    "axes[1].set_title('MSE Scores by model')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(sorted_models_mse)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "4. change filenames \n",
    "5. push to github\n",
    "6. write up analysis\n",
    "7. submit to coursera\n",
    "\n",
    "## After submission\n",
    "8. add XGBoost or Adaboost\n",
    "9. update the raw data (selenium)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-rTmYhf-l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
