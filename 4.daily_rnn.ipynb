{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "\n",
    "from keras import layers, models, Sequential, regularizers\n",
    "from keras.layers import SimpleRNN, Dense, Dropout, Embedding, LSTM, GRU\n",
    "from keras.optimizers.legacy import Adam, RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import L1, L2, L1L2\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data & column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA_PATH = \"data.v3/daily\" \n",
    "\n",
    "df = pd.read_parquet(os.path.join(DAILY_DATA_PATH, \"daily_flights_and_weather_merged.parquet\"))\n",
    "\n",
    "# Flights column groups\n",
    "flights_terminal_cols = ['flights_arr_A', 'flights_arr_B', 'flights_arr_C', 'flights_arr_D', 'flights_arr_E',\n",
    "                         'flights_dep_A', 'flights_dep_B', 'flights_dep_C', 'flights_dep_D', 'flights_dep_E']\n",
    "\n",
    "flights_non_terminal_cols = ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime',\n",
    "                             'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel',\n",
    "                             'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel']\n",
    "\n",
    "flights_percentage_cols = ['flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct',\n",
    "                            'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct',\n",
    "                            'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
    "\n",
    "# Date column groups\n",
    "date_cols = ['date', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day']\n",
    "\n",
    "# Weather column groups\n",
    "weather_cols = ['wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction']\n",
    "\n",
    "# Lag column groups\n",
    "lag_cols =  ['flights_total_lag_1', 'flights_total_lag_2', 'flights_total_lag_3', 'flights_total_lag_4', 'flights_total_lag_5', 'flights_total_lag_6', 'flights_total_lag_7', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split - \"flights_ontime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_full shape: (1516, 47)\n",
      "y_train_full shape: (1516,)\n",
      "X_train shape: (1364, 47)\n",
      "y_train shape: (1364,)\n",
      "X_Test shape: (169, 47)\n",
      "y_Test shape: (169,)\n"
     ]
    }
   ],
   "source": [
    "# Select features and targets\n",
    "train_features = ['random'] + date_cols + weather_cols + lag_cols\n",
    "targets = flights_non_terminal_cols + flights_percentage_cols\n",
    "\n",
    "# Create X and y\n",
    "X = df[train_features].drop('date', axis=1)\n",
    "y = df[targets]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y['flights_ontime'], test_size=0.1, random_state=42)\n",
    "\n",
    "# Split data into X_train_rull and y_train_full into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes\n",
    "print(\"X_train_full shape:\", X_train_full.shape)\n",
    "print(\"y_train_full shape:\", y_train_full.shape)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_Test shape:\", X_test.shape)\n",
    "print(\"y_Test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS FOR DENSE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['random', 'covid', 'ordinal_date', 'year', 'month', 'day_of_month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter', 'days_until_xmas', 'days_until_thanksgiving', 'days_until_july_4th', 'days_until_labor_day', 'days_until_memorial_day', 'wx_temperature_max', 'wx_temperature_min', 'wx_apcp', 'wx_prate', 'wx_asnow', 'wx_frozr', 'wx_vis', 'wx_gust', 'wx_maxref', 'wx_cape', 'wx_lftx', 'wx_wind_speed', 'wx_wind_direction', 'flights_total_lag_1', 'flights_total_lag_2', 'flights_total_lag_3', 'flights_total_lag_4', 'flights_total_lag_5', 'flights_total_lag_6', 'flights_total_lag_7', 'flights_cancel_lag_1', 'flights_cancel_lag_2', 'flights_cancel_lag_3', 'flights_cancel_lag_4', 'flights_cancel_lag_5', 'flights_cancel_lag_6', 'flights_cancel_lag_7']\n",
      "Target columns: ['flights_total', 'flights_cancel', 'flights_delay', 'flights_ontime', 'flights_arr_ontime', 'flights_arr_delay', 'flights_arr_cancel', 'flights_dep_ontime', 'flights_dep_delay', 'flights_dep_cancel', 'flights_cancel_pct', 'flights_delay_pct', 'flights_ontime_pct', 'flights_arr_delay_pct', 'flights_arr_ontime_pct', 'flights_arr_cancel_pct', 'flights_dep_delay_pct', 'flights_dep_ontime_pct', 'flights_dep_cancel_pct']\n",
      "\n",
      "Unique data types in X\n",
      "float64    23\n",
      "object     11\n",
      "int64       7\n",
      "float32     4\n",
      "int32       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Categorical columns to one-hot-encode: ['covid', 'month', 'day_of_week', 'season', 'holiday', 'halloween', 'xmas_eve', 'new_years_eve', 'jan_2', 'jan_3', 'day_before_easter']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature names: {X.columns.tolist()}\")\n",
    "print(f\"Target columns: {y.columns.tolist()}\", end=\"\\n\\n\")\n",
    "print(\"Unique data types in X\", X.dtypes.value_counts(), sep = '\\n')\n",
    "\n",
    "# Identify categorical and numeric columns in X\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include = ['float64', 'float32', 'int32', 'int64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns to one-hot-encode: {categorical_cols}\")\n",
    "\n",
    "# Fit transformers to the training data\n",
    "f_scaler = StandardScaler()\n",
    "f_scaler.fit(X_train[numeric_cols])\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore') # Some observed holidays may not be in the training data\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "t_scaler = StandardScaler()\n",
    "t_scaler.fit(y_train.values.reshape(-1, 1)) # reshape y_train to be 2D\n",
    "\n",
    "# Define preprocessor\n",
    "def preprocess(features, target, set_global_scaler = False):\n",
    "    global global_targer_scaler\n",
    "\n",
    "    scaled_features = f_scaler.transform(features[numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1))\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "\n",
    "    if set_global_scaler:\n",
    "        global_targer_scaler = t_scaler\n",
    "\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_d, y_train_d = preprocess(X_train, y_train, set_global_scaler=True)\n",
    "X_val_d, y_val_d = preprocess(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-NEURON \"LINEAR MODEL\"\n",
    "\n",
    "The goal of this section is to simulate linear regression using a neural newtork with one neuron and no activation function. I'll use L1 and L2 regularization to simulate elastic net regression and compare results to those found in 3.daily_linear_regression.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow datasets\n",
    "train_ds_flights_ontime_d = Dataset.from_tensor_slices((X_train_d, y_train_d)).shuffle(len(X_train_d))\n",
    "val_ds_flights_ontime_d = Dataset.from_tensor_slices((X_val_d, y_val_d)).shuffle(len(X_val_d))\n",
    "\n",
    "# Batch and prefetch\n",
    "batch_size = 32\n",
    "train_ds_flights_ontime_d = train_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n",
    "val_ds_flights_ontime_d = val_ds_flights_ontime_d.batch(batch_size).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create R-squared metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r_squared(y_true, y_pred):\n",
    "    y_true_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_true], tf.float32)\n",
    "    y_pred_inv = tf.numpy_function(global_targer_scaler.inverse_transform, [y_pred], tf.float32)\n",
    "    SS_res =  K.sum(K.square(y_true_inv - y_pred_inv)) \n",
    "    SS_tot = K.sum(K.square(y_true_inv - K.mean(y_true_inv))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    l1_regularization = hp.Float('l1_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(units = 1, \n",
    "            input_dim=X_train_d.shape[1], \n",
    "            kernel_regularizer=L1L2(l1_regularization, l2_regularization))\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one-neuron hyperparameters using Keras random search tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 04s]\n",
      "val_loss: 0.4642547070980072\n",
      "\n",
      "Best val_loss So Far: 0.4110903888940811\n",
      "Total elapsed time: 00h 10m 56s\n"
     ]
    }
   ],
   "source": [
    "# Callbacks & Tensorboard Setup\n",
    "early_stopping_1n_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Create a Keras Tuner\n",
    "OneNeuron_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory='logs/flights_ontime/dense_lr/',\n",
    "    project_name='tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneNeuron_tuner_RS.search(train_ds_flights_ontime_d, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             callbacks=[early_stopping_1n_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best 3 one-model fits: hyperparameters and validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in logs/flights_ontime/dense_lr/tuner\n",
      "Showing 3 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 012 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.006842507100027634\n",
      "l1_regularization: 5.026554730743739e-05\n",
      "l2_regularization: 0.00012316317658612945\n",
      "Score: 0.4110903888940811\n",
      "\n",
      "Trial 024 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.008530202096475512\n",
      "l1_regularization: 0.00012170421860683753\n",
      "l2_regularization: 1.1011211773991691e-05\n",
      "Score: 0.41599664092063904\n",
      "\n",
      "Trial 046 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.00359824300326137\n",
      "l1_regularization: 0.00025769328883230635\n",
      "l2_regularization: 0.0004753203574656876\n",
      "Score: 0.4249129742383957\n"
     ]
    }
   ],
   "source": [
    "OneNeuron_tuner_RS.results_summary(num_trials=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save best one-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneNeuron_LR_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Tensorboard setup\n",
    "!rm -rf ./logs/flights_ontime/OneNeuron/tensorboard/ \n",
    "log_dir = \"logs/flights_ontime/OneNeuron/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_best = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "best_hps = OneNeuron_tuner_RS.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneNeuron_LR_model = OneNeuron_tuner_RS.hypermodel.build(best_hps)\n",
    "history = OneNeuron_LR_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneNeuron_LR_model.save('models/flights_ontime/OneNeuron_LR_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TensorBoard for best 1-neuron model\n",
    "The TensorBoard dashboard shows plots generated from training logs that provide insight into the training of a model. \n",
    "\n",
    "The time series tab shows several plots within expandable windows for our one-neuronal model, \"dense_#\" and for the loss and training metrics by epoch.  Under dense_#, TesnorBoard shows histograms of the bias values \"bias_0\" and weight values, \"kernel_0\" by epoch. The epoch number is on the y-axis with the first epochs at the top and the most recent epoch at the bottom. These plots show how the bias and weight distributions change with training. For the one-neuron model, the weights appear to stabilize well before the training ended, at around 50 to 60 epochs, while the bias terms continued to drift downwards with training.\n",
    "\n",
    "The other plots under Time Series show how the loss and metrics change with training epoch or iteration (batch number). Based on these plots, the one-neuron model appears to have high bias and high variance. High bias is indicated by the large difference in loss and performance metrics between the train and validation datasets. High variance is indicated by the large variation in the validation loss, mae, and r-squared metrics that persists through training, even after these metrics stabilize on the training set at around epoch 40. Taken together, the one-neuron model appears to lack flexibility and would also benefit from having more data to train the weights.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 3470), started 10:23:51 ago. (Use '!kill 3470' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-213b8de153dc2086\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-213b8de153dc2086\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneNeuron/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evalute the best 1-neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 580us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 122.72\n",
      "- Validation MSE: 32874.14\n",
      "- Validation R^2: 0.679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "OneNeuron_LR_model = models.load_model('models/flights_ontime/OneNeuron_LR_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneNeuron_LR_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "OneNeuron_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "OneNeuron_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneNeuron_val_mae:.2f}\n",
    "- Validation MSE: {OneNeuron_val_mse:.2f}\n",
    "- Validation R^2: {OneNeuron_val_r2:.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW DENSE NEURAL NETWORK (SDNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build SDNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=1, max_value=2, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.02, max_value=0.03, default=0.0)\n",
    "    l2_regularization =  hp.Float('l2_regularization', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=n_neurons, \n",
    "                    activation='relu', \n",
    "                    kernel_regularizer=L2(l2_regularization)))\n",
    "    \n",
    "    for layer in range(n_hidden-1):\n",
    "        model.add(Dense(units=n_neurons, \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=L2(l2_regularization)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    if n_hidden > 0:\n",
    "        model.add(Dense(units=n_neurons, \n",
    "                        activation='relu', \n",
    "                        kernel_regularizer=L2(l2_regularization)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 02s]\n",
      "val_loss: 0.4439461827278137\n",
      "\n",
      "Best val_loss So Far: 0.38801226019859314\n",
      "Total elapsed time: 00h 08m 06s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_BO = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_BO = kt.BayesianOptimization(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    num_initial_points=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"bayesian_optimization_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_BO.search(train_ds_flights_ontime_d, \n",
    "             epochs=500, \n",
    "             validation_data=val_ds_flights_ontime_d, \n",
    "             callbacks=[early_stopping_BO])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for SDNN using random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 04s]\n",
      "val_loss: 0.4617564529180527\n",
      "\n",
      "Best val_loss So Far: 0.3983249217271805\n",
      "Total elapsed time: 00h 09m 17s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_RS = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_RS = kt.RandomSearch(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"random_search_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_RS.search(train_ds_flights_ontime_d,\n",
    "                epochs=500, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_RS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for best SDNN model using hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 05s]\n",
      "val_loss: 0.7675652503967285\n",
      "\n",
      "Best val_loss So Far: 0.3679744005203247\n",
      "Total elapsed time: 00h 16m 34s\n"
     ]
    }
   ],
   "source": [
    "early_stopping_HB = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "SDNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    directory = \"logs/flights_ontime/SDNN\",\n",
    "    project_name = \"hyperband_tuner\",\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "SDNN_tuner_HB.search(train_ds_flights_ontime_d,\n",
    "                epochs=600, \n",
    "                validation_data=val_ds_flights_ontime_d, \n",
    "                callbacks=[early_stopping_HB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best SDNN model (from hyperband search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/SDNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters from Hyperband tuner\n",
    "best_hps = SDNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Initialize Early Stopping\n",
    "early_stopping_SDNN_best = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/SDNN_HB/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/SDNN_HB/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "SDNN_model = SDNN_tuner_HB.hypermodel.build(best_hps)\n",
    "history = SDNN_model.fit(train_ds_flights_ontime_d, \n",
    "                    validation_data=val_ds_flights_ontime_d, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping_SDNN_best, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "SDNN_model.save('models/flights_ontime/SDNN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 27548), started 14:03:26 ago. (Use '!kill 27548' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-21ff156c93709da5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-21ff156c93709da5\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TensorBoard\n",
    "%tensorboard --logdir logs/flights_ontime/SDNN_HB/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 8\n",
      "- Learning Rate: 0.006415517608465564\n",
      "- Dropout Rate: 0.024849650762982137\n",
      "- L2 Regularization: 0.0007243411260176605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "SDNN_model = models.load_model('models/flights_ontime/SDNN_model')\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- L2 Regularization: {best_hps.get('l2_regularization')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 8)                 720       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 801 (3.13 KB)\n",
      "Trainable params: 801 (3.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "SDNN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best SDNN model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 527us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 109.17\n",
      "- Validation MSE: 31593.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inverse transform the predicted values and get validation MAE, MSE\n",
    "y_pred = SDNN_model.predict(X_val_d)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_d)\n",
    "\n",
    "SDNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "SDNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {SDNN_val_mae:.2f}\n",
    "- Validation MSE: {SDNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECURRENT NEURAL NETWORK (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lag variables from X train, val, and test sets\n",
    "The lag variables are redundant with the recurrent loops of an RNN that feed historical information into each neuron. I dropped the lag variables to reduce the redundancy and dimensionality in the RNN datasets. However, the lag variables may have value in an RNN despite introducing redundancy and multicolinearity. Time permitting, I'll retain the lag variables and train the RNN's a second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_X_train_full = X_train_full.drop(lag_cols, axis=1)\n",
    "rnn_X_train = X_train.drop(lag_cols, axis=1)\n",
    "rnn_X_val = X_val.drop(lag_cols, axis=1)\n",
    "rnn_X_test = X_test.drop(lag_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN column transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_numeric_cols = [col for col in numeric_cols if col not in lag_cols]\n",
    "\n",
    "# Fit transformers to the training data\n",
    "rnn_f_scaler = StandardScaler()\n",
    "rnn_f_scaler.fit(rnn_X_train[rnn_numeric_cols])\n",
    "\n",
    "# Create a function to preprocess TensorFlow datasets\n",
    "def rnn_preprocess(features, target):\n",
    "    scaled_features = rnn_f_scaler.transform(features[rnn_numeric_cols])\n",
    "    encoded_features = ohe.transform(features[categorical_cols])\n",
    "    scaled_target = t_scaler.transform(target.values.reshape(-1, 1)) # Scaling the target can speed up training, improve convergence, and reduce the impact of outliers for RNNs\n",
    "    processed_features = np.concatenate([scaled_features, encoded_features], axis=1)\n",
    "    return processed_features, scaled_target\n",
    "\n",
    "# Transform the data\n",
    "X_train_rnn, y_train_rnn = rnn_preprocess(X_train, y_train)\n",
    "X_val_rnn, y_val_rnn = rnn_preprocess(X_val, y_val)\n",
    "X_test_rnn, y_test_rnn = rnn_preprocess(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create timeseries datasets\n",
    "\n",
    "The timeseries datasets below use a sequence length of 7 and a time step of 1. Each recurrent neuron will process the sequences in 7 recurrent steps, updating its hidden state based on the current input and the previous hidden state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "seq_length = 7\n",
    "batch_size = 32\n",
    "\n",
    "train_rnn = timeseries_dataset_from_array(\n",
    "    data = X_train_rnn, \n",
    "    targets = y_train_rnn,\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "val_rnn = timeseries_dataset_from_array(\n",
    "    data = X_val_rnn, \n",
    "    targets = y_val_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_rnn = timeseries_dataset_from_array(\n",
    "    data = X_test_rnn, \n",
    "    targets = y_test_rnn[seq_length-1:],\n",
    "    sequence_length = seq_length,\n",
    "    sequence_stride = 1,\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE RECURRENT NEURON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build one-neuron RNN hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build one-neuron RNN hypermodel\n",
    "def OneRNN_model_builder(hp):\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-5, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units = 1, \n",
    "                  input_shape = (None, X_train_rnn.shape[1]), \n",
    "                  kernel_regularizer=L2(kernel_reg),\n",
    "                  recurrent_regularizer=L2(recurr_reg),\n",
    "                  )\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                loss='mean_squared_error', \n",
    "                metrics=['mean_absolute_error', r_squared])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 254 Complete [00h 00m 21s]\n",
      "val_loss: 1.2453628778457642\n",
      "\n",
      "Best val_loss So Far: 1.1035436391830444\n",
      "Total elapsed time: 00h 49m 19s\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Hyperband tuner\n",
    "OneRNN_tuner_HB = kt.Hyperband(\n",
    "    hypermodel = OneRNN_model_builder,\n",
    "    objective='val_loss',\n",
    "    max_epochs=100,\n",
    "    factor=3,\n",
    "    directory='logs/flights_ontime/OneRNN',\n",
    "    project_name='hyperband_tuner',\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "OneRNN_tuner_HB.search(train_rnn, \n",
    "             validation_data=val_rnn, \n",
    "             epochs=100, \n",
    "             callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weights and save best one-neuron RNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/OneRNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "best_hps = OneRNN_tuner_HB.get_best_hyperparameters(num_trials = 1)[0]\n",
    "OneRNN_model = OneRNN_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# Setup TensoreBoard\n",
    "!rm -rf ./logs/flights_ontime/OneRNN/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/OneRNN/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "history = OneRNN_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback],\n",
    "                    verbose=0)\n",
    "\n",
    "# Save the trained model\n",
    "OneRNN_model.save('models/flights_ontime/OneRNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 41285), started 0:00:05 ago. (Use '!kill 41285' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ea377e98d930e2ca\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ea377e98d930e2ca\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/OneRNN/tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and evaluate the best one-neuron RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 868us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 246.84\n",
      "- Validation MSE: 105378.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OneRNN_model = models.load_model('models/flights_ontime/OneRNN_model', custom_objects={'r_squared': r_squared})\n",
    "\n",
    "# Inverse transform the predicted values and get validation MAE, MSE, and R^2\n",
    "y_pred = OneRNN_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "OneRNN_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "OneRNN_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {OneRNN_val_mae:.2f}\n",
    "- Validation MSE: {OneRNN_val_mse:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHALLOW RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build shallow RNN Hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=1, max_value=2, default=2)\n",
    "    n_neurons = hp.Int('n_neurons', min_value=1, max_value=32, default=16)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG', default=1e-3)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    recurrent_dropout_rate = hp.Float('recurrent_dropout_rate', min_value=0.0, max_value=0.5, default=0.0)\n",
    "    kernel_reg = hp.Float('kernel_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "    recurr_reg = hp.Float('recurr_reg', min_value=1e-4, max_value=1e-1, sampling='LOG', default=1e-2)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input layer with dropout\n",
    "    model.add(Dropout(dropout_rate, \n",
    "                      input_shape=(None, X_train_rnn.shape[1])))\n",
    "\n",
    "    # First n-1 Hidden layers\n",
    "    for _ in range(n_hidden-1):\n",
    "        model.add(SimpleRNN(units=n_neurons, \n",
    "                            activation='relu', \n",
    "                            return_sequences=True,\n",
    "                            kernel_regularizer=L2(kernel_reg),\n",
    "                            recurrent_regularizer=L2(recurr_reg),\n",
    "                            dropout = dropout_rate,\n",
    "                            recurrent_dropout = recurrent_dropout_rate))\n",
    "\n",
    "    # Last hidden layer\n",
    "    if n_hidden > 0:\n",
    "        model.add(SimpleRNN(units=n_neurons, \n",
    "                            activation='relu', \n",
    "                            kernel_regularizer=L2(kernel_reg),\n",
    "                            recurrent_regularizer=L2(recurr_reg),\n",
    "                            dropout = dropout_rate,\n",
    "                            recurrent_dropout = recurrent_dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using a random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 15s]\n",
      "val_loss: 1.264518141746521\n",
      "\n",
      "Best val_loss So Far: 1.124204158782959\n",
      "Total elapsed time: 00h 10m 11s\n",
      "\n",
      "Search: Running Trial #26\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |1                 |n_hidden\n",
      "13                |26                |n_neurons\n",
      "0.00030422        |0.0055101         |learning_rate\n",
      "0.32277           |0.21213           |dropout_rate\n",
      "0.43681           |0.47244           |recurrent_dropout_rate\n",
      "0.00017468        |0.006274          |kernel_reg\n",
      "0.03678           |0.01079           |recurr_reg\n",
      "\n",
      "Epoch 1/500\n",
      "43/43 [==============================] - 1s 5ms/step - loss: 23.9736 - mean_absolute_error: 3.4789 - val_loss: 5.0717 - val_mean_absolute_error: 1.7508\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 14.4724 - mean_absolute_error: 2.6433 - val_loss: 3.7997 - val_mean_absolute_error: 1.4154\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 10.0611 - mean_absolute_error: 2.2159 - val_loss: 3.3012 - val_mean_absolute_error: 1.2457\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 7.4112 - mean_absolute_error: 1.9309 - val_loss: 3.0874 - val_mean_absolute_error: 1.1624\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 6.2317 - mean_absolute_error: 1.7917 - val_loss: 2.9503 - val_mean_absolute_error: 1.1073\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.9081 - mean_absolute_error: 1.5558 - val_loss: 2.8335 - val_mean_absolute_error: 1.0714\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3530 - mean_absolute_error: 1.4997 - val_loss: 2.7405 - val_mean_absolute_error: 1.0453\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 4.3267 - mean_absolute_error: 1.4833 - val_loss: 2.7089 - val_mean_absolute_error: 1.0280\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.8107 - mean_absolute_error: 1.3574 - val_loss: 2.6490 - val_mean_absolute_error: 1.0106\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 3.3602 - mean_absolute_error: 1.3215 - val_loss: 2.6128 - val_mean_absolute_error: 0.9944\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.1781 - mean_absolute_error: 1.2638 - val_loss: 2.5835 - val_mean_absolute_error: 0.9791\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9005 - mean_absolute_error: 1.2213 - val_loss: 2.5635 - val_mean_absolute_error: 0.9660\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.0156 - mean_absolute_error: 1.2109 - val_loss: 2.5116 - val_mean_absolute_error: 0.9554\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9074 - mean_absolute_error: 1.1719 - val_loss: 2.4666 - val_mean_absolute_error: 0.9443\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5431 - mean_absolute_error: 1.1325 - val_loss: 2.4584 - val_mean_absolute_error: 0.9397\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7084 - mean_absolute_error: 1.1457 - val_loss: 2.4308 - val_mean_absolute_error: 0.9354\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3295 - mean_absolute_error: 1.0736 - val_loss: 2.4289 - val_mean_absolute_error: 0.9328\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4867 - mean_absolute_error: 1.0968 - val_loss: 2.3907 - val_mean_absolute_error: 0.9292\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2197 - mean_absolute_error: 1.0403 - val_loss: 2.3882 - val_mean_absolute_error: 0.9256\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2441 - mean_absolute_error: 1.0208 - val_loss: 2.3810 - val_mean_absolute_error: 0.9229\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2777 - mean_absolute_error: 1.0340 - val_loss: 2.3497 - val_mean_absolute_error: 0.9194\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1225 - mean_absolute_error: 1.0031 - val_loss: 2.3459 - val_mean_absolute_error: 0.9174\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0509 - mean_absolute_error: 0.9860 - val_loss: 2.3447 - val_mean_absolute_error: 0.9159\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1264 - mean_absolute_error: 0.9712 - val_loss: 2.3254 - val_mean_absolute_error: 0.9154\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0405 - mean_absolute_error: 0.9633 - val_loss: 2.3194 - val_mean_absolute_error: 0.9145\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9489 - mean_absolute_error: 0.9468 - val_loss: 2.3067 - val_mean_absolute_error: 0.9125\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0341 - mean_absolute_error: 0.9544 - val_loss: 2.2887 - val_mean_absolute_error: 0.9103\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9666 - mean_absolute_error: 0.9293 - val_loss: 2.2627 - val_mean_absolute_error: 0.9073\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8668 - mean_absolute_error: 0.9219 - val_loss: 2.2590 - val_mean_absolute_error: 0.9057\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7993 - mean_absolute_error: 0.9042 - val_loss: 2.2507 - val_mean_absolute_error: 0.9046\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8423 - mean_absolute_error: 0.9018 - val_loss: 2.2453 - val_mean_absolute_error: 0.9041\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8046 - mean_absolute_error: 0.9005 - val_loss: 2.2348 - val_mean_absolute_error: 0.9030\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8740 - mean_absolute_error: 0.9107 - val_loss: 2.2089 - val_mean_absolute_error: 0.9003\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8210 - mean_absolute_error: 0.9112 - val_loss: 2.1976 - val_mean_absolute_error: 0.8987\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7867 - mean_absolute_error: 0.8874 - val_loss: 2.1895 - val_mean_absolute_error: 0.8984\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7248 - mean_absolute_error: 0.8639 - val_loss: 2.1714 - val_mean_absolute_error: 0.8973\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7682 - mean_absolute_error: 0.8911 - val_loss: 2.1600 - val_mean_absolute_error: 0.8960\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6994 - mean_absolute_error: 0.8700 - val_loss: 2.1487 - val_mean_absolute_error: 0.8957\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6544 - mean_absolute_error: 0.8563 - val_loss: 2.1398 - val_mean_absolute_error: 0.8947\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6671 - mean_absolute_error: 0.8621 - val_loss: 2.1301 - val_mean_absolute_error: 0.8927\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7000 - mean_absolute_error: 0.8653 - val_loss: 2.1212 - val_mean_absolute_error: 0.8911\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6268 - mean_absolute_error: 0.8496 - val_loss: 2.1146 - val_mean_absolute_error: 0.8895\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7034 - mean_absolute_error: 0.8517 - val_loss: 2.0866 - val_mean_absolute_error: 0.8873\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6061 - mean_absolute_error: 0.8471 - val_loss: 2.0841 - val_mean_absolute_error: 0.8865\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5636 - mean_absolute_error: 0.8335 - val_loss: 2.0798 - val_mean_absolute_error: 0.8857\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6267 - mean_absolute_error: 0.8450 - val_loss: 2.0733 - val_mean_absolute_error: 0.8848\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5709 - mean_absolute_error: 0.8269 - val_loss: 2.0602 - val_mean_absolute_error: 0.8839\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5516 - mean_absolute_error: 0.8195 - val_loss: 2.0471 - val_mean_absolute_error: 0.8831\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5353 - mean_absolute_error: 0.8183 - val_loss: 2.0362 - val_mean_absolute_error: 0.8821\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6000 - mean_absolute_error: 0.8185 - val_loss: 2.0152 - val_mean_absolute_error: 0.8801\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5312 - mean_absolute_error: 0.8216 - val_loss: 2.0079 - val_mean_absolute_error: 0.8794\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5829 - mean_absolute_error: 0.8311 - val_loss: 1.9987 - val_mean_absolute_error: 0.8782\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4742 - mean_absolute_error: 0.7980 - val_loss: 1.9940 - val_mean_absolute_error: 0.8778\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5477 - mean_absolute_error: 0.8248 - val_loss: 1.9909 - val_mean_absolute_error: 0.8761\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5039 - mean_absolute_error: 0.8046 - val_loss: 1.9855 - val_mean_absolute_error: 0.8756\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4895 - mean_absolute_error: 0.8087 - val_loss: 1.9826 - val_mean_absolute_error: 0.8750\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5167 - mean_absolute_error: 0.8194 - val_loss: 1.9774 - val_mean_absolute_error: 0.8746\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4949 - mean_absolute_error: 0.8058 - val_loss: 1.9694 - val_mean_absolute_error: 0.8743\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5130 - mean_absolute_error: 0.8178 - val_loss: 1.9693 - val_mean_absolute_error: 0.8740\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5503 - mean_absolute_error: 0.8112 - val_loss: 1.9426 - val_mean_absolute_error: 0.8724\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4768 - mean_absolute_error: 0.8075 - val_loss: 1.9366 - val_mean_absolute_error: 0.8713\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4812 - mean_absolute_error: 0.7979 - val_loss: 1.9356 - val_mean_absolute_error: 0.8709\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4937 - mean_absolute_error: 0.7993 - val_loss: 1.9271 - val_mean_absolute_error: 0.8698\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5001 - mean_absolute_error: 0.8151 - val_loss: 1.9187 - val_mean_absolute_error: 0.8689\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4172 - mean_absolute_error: 0.7882 - val_loss: 1.9112 - val_mean_absolute_error: 0.8683\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4511 - mean_absolute_error: 0.7913 - val_loss: 1.9067 - val_mean_absolute_error: 0.8682\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4918 - mean_absolute_error: 0.8159 - val_loss: 1.8992 - val_mean_absolute_error: 0.8678\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4588 - mean_absolute_error: 0.7920 - val_loss: 1.8788 - val_mean_absolute_error: 0.8663\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4541 - mean_absolute_error: 0.8056 - val_loss: 1.8776 - val_mean_absolute_error: 0.8660\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4304 - mean_absolute_error: 0.7920 - val_loss: 1.8743 - val_mean_absolute_error: 0.8655\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4189 - mean_absolute_error: 0.7895 - val_loss: 1.8701 - val_mean_absolute_error: 0.8651\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4331 - mean_absolute_error: 0.7855 - val_loss: 1.8502 - val_mean_absolute_error: 0.8643\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3735 - mean_absolute_error: 0.7680 - val_loss: 1.8472 - val_mean_absolute_error: 0.8639\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4076 - mean_absolute_error: 0.7912 - val_loss: 1.8442 - val_mean_absolute_error: 0.8636\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4083 - mean_absolute_error: 0.7830 - val_loss: 1.8416 - val_mean_absolute_error: 0.8638\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3836 - mean_absolute_error: 0.7686 - val_loss: 1.8358 - val_mean_absolute_error: 0.8637\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4060 - mean_absolute_error: 0.7873 - val_loss: 1.8318 - val_mean_absolute_error: 0.8633\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3745 - mean_absolute_error: 0.7836 - val_loss: 1.8239 - val_mean_absolute_error: 0.8628\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4426 - mean_absolute_error: 0.7986 - val_loss: 1.7989 - val_mean_absolute_error: 0.8607\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4210 - mean_absolute_error: 0.7939 - val_loss: 1.7898 - val_mean_absolute_error: 0.8596\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3899 - mean_absolute_error: 0.7771 - val_loss: 1.7824 - val_mean_absolute_error: 0.8591\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3663 - mean_absolute_error: 0.7779 - val_loss: 1.7789 - val_mean_absolute_error: 0.8584\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3860 - mean_absolute_error: 0.7773 - val_loss: 1.7722 - val_mean_absolute_error: 0.8581\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3950 - mean_absolute_error: 0.7866 - val_loss: 1.7546 - val_mean_absolute_error: 0.8566\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3490 - mean_absolute_error: 0.7732 - val_loss: 1.7526 - val_mean_absolute_error: 0.8564\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3243 - mean_absolute_error: 0.7676 - val_loss: 1.7486 - val_mean_absolute_error: 0.8558\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3517 - mean_absolute_error: 0.7779 - val_loss: 1.7453 - val_mean_absolute_error: 0.8550\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3238 - mean_absolute_error: 0.7646 - val_loss: 1.7446 - val_mean_absolute_error: 0.8549\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3432 - mean_absolute_error: 0.7740 - val_loss: 1.7416 - val_mean_absolute_error: 0.8550\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3355 - mean_absolute_error: 0.7764 - val_loss: 1.7379 - val_mean_absolute_error: 0.8550\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3341 - mean_absolute_error: 0.7731 - val_loss: 1.7350 - val_mean_absolute_error: 0.8548\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3329 - mean_absolute_error: 0.7754 - val_loss: 1.7304 - val_mean_absolute_error: 0.8541\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3138 - mean_absolute_error: 0.7702 - val_loss: 1.7252 - val_mean_absolute_error: 0.8534\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3429 - mean_absolute_error: 0.7726 - val_loss: 1.7053 - val_mean_absolute_error: 0.8523\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3093 - mean_absolute_error: 0.7694 - val_loss: 1.6992 - val_mean_absolute_error: 0.8523\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2986 - mean_absolute_error: 0.7705 - val_loss: 1.6948 - val_mean_absolute_error: 0.8523\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3242 - mean_absolute_error: 0.7670 - val_loss: 1.6762 - val_mean_absolute_error: 0.8510\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3420 - mean_absolute_error: 0.7816 - val_loss: 1.6747 - val_mean_absolute_error: 0.8507\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3058 - mean_absolute_error: 0.7717 - val_loss: 1.6718 - val_mean_absolute_error: 0.8505\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2822 - mean_absolute_error: 0.7643 - val_loss: 1.6676 - val_mean_absolute_error: 0.8508\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3065 - mean_absolute_error: 0.7718 - val_loss: 1.6638 - val_mean_absolute_error: 0.8510\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3101 - mean_absolute_error: 0.7751 - val_loss: 1.6457 - val_mean_absolute_error: 0.8499\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2878 - mean_absolute_error: 0.7657 - val_loss: 1.6418 - val_mean_absolute_error: 0.8493\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2806 - mean_absolute_error: 0.7665 - val_loss: 1.6383 - val_mean_absolute_error: 0.8490\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3142 - mean_absolute_error: 0.7764 - val_loss: 1.6189 - val_mean_absolute_error: 0.8481\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2601 - mean_absolute_error: 0.7593 - val_loss: 1.6052 - val_mean_absolute_error: 0.8466\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2682 - mean_absolute_error: 0.7658 - val_loss: 1.6036 - val_mean_absolute_error: 0.8462\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2552 - mean_absolute_error: 0.7584 - val_loss: 1.6019 - val_mean_absolute_error: 0.8465\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2804 - mean_absolute_error: 0.7732 - val_loss: 1.5973 - val_mean_absolute_error: 0.8462\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2818 - mean_absolute_error: 0.7773 - val_loss: 1.5983 - val_mean_absolute_error: 0.8458\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2510 - mean_absolute_error: 0.7634 - val_loss: 1.5962 - val_mean_absolute_error: 0.8458\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2573 - mean_absolute_error: 0.7699 - val_loss: 1.5946 - val_mean_absolute_error: 0.8458\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2676 - mean_absolute_error: 0.7712 - val_loss: 1.5944 - val_mean_absolute_error: 0.8453\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2393 - mean_absolute_error: 0.7553 - val_loss: 1.5900 - val_mean_absolute_error: 0.8451\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2269 - mean_absolute_error: 0.7590 - val_loss: 1.5870 - val_mean_absolute_error: 0.8454\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2386 - mean_absolute_error: 0.7640 - val_loss: 1.5837 - val_mean_absolute_error: 0.8452\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2495 - mean_absolute_error: 0.7636 - val_loss: 1.5824 - val_mean_absolute_error: 0.8452\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2427 - mean_absolute_error: 0.7660 - val_loss: 1.5783 - val_mean_absolute_error: 0.8450\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2319 - mean_absolute_error: 0.7634 - val_loss: 1.5601 - val_mean_absolute_error: 0.8433\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2361 - mean_absolute_error: 0.7630 - val_loss: 1.5574 - val_mean_absolute_error: 0.8434\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2363 - mean_absolute_error: 0.7651 - val_loss: 1.5455 - val_mean_absolute_error: 0.8423\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2295 - mean_absolute_error: 0.7611 - val_loss: 1.5303 - val_mean_absolute_error: 0.8414\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2168 - mean_absolute_error: 0.7589 - val_loss: 1.5297 - val_mean_absolute_error: 0.8415\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2436 - mean_absolute_error: 0.7659 - val_loss: 1.5193 - val_mean_absolute_error: 0.8403\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2326 - mean_absolute_error: 0.7617 - val_loss: 1.5171 - val_mean_absolute_error: 0.8404\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2133 - mean_absolute_error: 0.7675 - val_loss: 1.5140 - val_mean_absolute_error: 0.8407\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2113 - mean_absolute_error: 0.7617 - val_loss: 1.5092 - val_mean_absolute_error: 0.8403\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2060 - mean_absolute_error: 0.7598 - val_loss: 1.5087 - val_mean_absolute_error: 0.8406\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2075 - mean_absolute_error: 0.7639 - val_loss: 1.5091 - val_mean_absolute_error: 0.8409\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1946 - mean_absolute_error: 0.7569 - val_loss: 1.5056 - val_mean_absolute_error: 0.8409\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2001 - mean_absolute_error: 0.7659 - val_loss: 1.5052 - val_mean_absolute_error: 0.8409\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1951 - mean_absolute_error: 0.7614 - val_loss: 1.4952 - val_mean_absolute_error: 0.8409\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1998 - mean_absolute_error: 0.7623 - val_loss: 1.4944 - val_mean_absolute_error: 0.8414\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1884 - mean_absolute_error: 0.7581 - val_loss: 1.4934 - val_mean_absolute_error: 0.8417\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1950 - mean_absolute_error: 0.7605 - val_loss: 1.4891 - val_mean_absolute_error: 0.8418\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1767 - mean_absolute_error: 0.7564 - val_loss: 1.4871 - val_mean_absolute_error: 0.8422\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1787 - mean_absolute_error: 0.7615 - val_loss: 1.4876 - val_mean_absolute_error: 0.8428\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1905 - mean_absolute_error: 0.7634 - val_loss: 1.4848 - val_mean_absolute_error: 0.8431\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1775 - mean_absolute_error: 0.7660 - val_loss: 1.4836 - val_mean_absolute_error: 0.8433\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1624 - mean_absolute_error: 0.7570 - val_loss: 1.4790 - val_mean_absolute_error: 0.8436\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1668 - mean_absolute_error: 0.7600 - val_loss: 1.4785 - val_mean_absolute_error: 0.8442\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1639 - mean_absolute_error: 0.7569 - val_loss: 1.4788 - val_mean_absolute_error: 0.8444\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1695 - mean_absolute_error: 0.7629 - val_loss: 1.4767 - val_mean_absolute_error: 0.8442\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1540 - mean_absolute_error: 0.7583 - val_loss: 1.4766 - val_mean_absolute_error: 0.8442\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1592 - mean_absolute_error: 0.7572 - val_loss: 1.4726 - val_mean_absolute_error: 0.8444\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1734 - mean_absolute_error: 0.7626 - val_loss: 1.4577 - val_mean_absolute_error: 0.8433\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1582 - mean_absolute_error: 0.7627 - val_loss: 1.4501 - val_mean_absolute_error: 0.8426\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1553 - mean_absolute_error: 0.7595 - val_loss: 1.4507 - val_mean_absolute_error: 0.8425\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1436 - mean_absolute_error: 0.7596 - val_loss: 1.4479 - val_mean_absolute_error: 0.8428\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1411 - mean_absolute_error: 0.7548 - val_loss: 1.4383 - val_mean_absolute_error: 0.8425\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1398 - mean_absolute_error: 0.7557 - val_loss: 1.4359 - val_mean_absolute_error: 0.8426\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1364 - mean_absolute_error: 0.7591 - val_loss: 1.4330 - val_mean_absolute_error: 0.8425\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1469 - mean_absolute_error: 0.7661 - val_loss: 1.4337 - val_mean_absolute_error: 0.8430\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1270 - mean_absolute_error: 0.7571 - val_loss: 1.4353 - val_mean_absolute_error: 0.8432\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1347 - mean_absolute_error: 0.7561 - val_loss: 1.4345 - val_mean_absolute_error: 0.8437\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1419 - mean_absolute_error: 0.7632 - val_loss: 1.4387 - val_mean_absolute_error: 0.8445\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1173 - mean_absolute_error: 0.7551 - val_loss: 1.4388 - val_mean_absolute_error: 0.8451\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1341 - mean_absolute_error: 0.7611 - val_loss: 1.4376 - val_mean_absolute_error: 0.8453\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1217 - mean_absolute_error: 0.7559 - val_loss: 1.4386 - val_mean_absolute_error: 0.8460\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1054 - mean_absolute_error: 0.7516 - val_loss: 1.4393 - val_mean_absolute_error: 0.8463\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1305 - mean_absolute_error: 0.7594 - val_loss: 1.4219 - val_mean_absolute_error: 0.8446\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1160 - mean_absolute_error: 0.7575 - val_loss: 1.4191 - val_mean_absolute_error: 0.8448\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1029 - mean_absolute_error: 0.7577 - val_loss: 1.4167 - val_mean_absolute_error: 0.8446\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1178 - mean_absolute_error: 0.7596 - val_loss: 1.4180 - val_mean_absolute_error: 0.8447\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1209 - mean_absolute_error: 0.7617 - val_loss: 1.4060 - val_mean_absolute_error: 0.8438\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1096 - mean_absolute_error: 0.7589 - val_loss: 1.4034 - val_mean_absolute_error: 0.8438\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1045 - mean_absolute_error: 0.7605 - val_loss: 1.4026 - val_mean_absolute_error: 0.8441\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0944 - mean_absolute_error: 0.7525 - val_loss: 1.4018 - val_mean_absolute_error: 0.8443\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0921 - mean_absolute_error: 0.7508 - val_loss: 1.4007 - val_mean_absolute_error: 0.8444\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0991 - mean_absolute_error: 0.7569 - val_loss: 1.4022 - val_mean_absolute_error: 0.8449\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1065 - mean_absolute_error: 0.7595 - val_loss: 1.4047 - val_mean_absolute_error: 0.8456\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1046 - mean_absolute_error: 0.7592 - val_loss: 1.3913 - val_mean_absolute_error: 0.8446\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0986 - mean_absolute_error: 0.7611 - val_loss: 1.3915 - val_mean_absolute_error: 0.8448\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0975 - mean_absolute_error: 0.7625 - val_loss: 1.3803 - val_mean_absolute_error: 0.8441\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0921 - mean_absolute_error: 0.7560 - val_loss: 1.3807 - val_mean_absolute_error: 0.8447\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0946 - mean_absolute_error: 0.7612 - val_loss: 1.3784 - val_mean_absolute_error: 0.8445\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0876 - mean_absolute_error: 0.7587 - val_loss: 1.3780 - val_mean_absolute_error: 0.8446\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0984 - mean_absolute_error: 0.7595 - val_loss: 1.3681 - val_mean_absolute_error: 0.8439\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0777 - mean_absolute_error: 0.7573 - val_loss: 1.3661 - val_mean_absolute_error: 0.8438\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0880 - mean_absolute_error: 0.7613 - val_loss: 1.3646 - val_mean_absolute_error: 0.8439\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0839 - mean_absolute_error: 0.7620 - val_loss: 1.3623 - val_mean_absolute_error: 0.8437\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0776 - mean_absolute_error: 0.7585 - val_loss: 1.3626 - val_mean_absolute_error: 0.8439\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0720 - mean_absolute_error: 0.7561 - val_loss: 1.3613 - val_mean_absolute_error: 0.8439\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0665 - mean_absolute_error: 0.7571 - val_loss: 1.3644 - val_mean_absolute_error: 0.8445\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0662 - mean_absolute_error: 0.7521 - val_loss: 1.3651 - val_mean_absolute_error: 0.8446\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0604 - mean_absolute_error: 0.7555 - val_loss: 1.3661 - val_mean_absolute_error: 0.8450\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0682 - mean_absolute_error: 0.7597 - val_loss: 1.3640 - val_mean_absolute_error: 0.8450\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0628 - mean_absolute_error: 0.7549 - val_loss: 1.3540 - val_mean_absolute_error: 0.8442\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0731 - mean_absolute_error: 0.7604 - val_loss: 1.3438 - val_mean_absolute_error: 0.8437\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0626 - mean_absolute_error: 0.7553 - val_loss: 1.3443 - val_mean_absolute_error: 0.8441\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0556 - mean_absolute_error: 0.7575 - val_loss: 1.3359 - val_mean_absolute_error: 0.8433\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0645 - mean_absolute_error: 0.7618 - val_loss: 1.3365 - val_mean_absolute_error: 0.8435\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0526 - mean_absolute_error: 0.7555 - val_loss: 1.3356 - val_mean_absolute_error: 0.8434\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0575 - mean_absolute_error: 0.7569 - val_loss: 1.3300 - val_mean_absolute_error: 0.8429\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0468 - mean_absolute_error: 0.7546 - val_loss: 1.3294 - val_mean_absolute_error: 0.8431\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0548 - mean_absolute_error: 0.7575 - val_loss: 1.3328 - val_mean_absolute_error: 0.8441\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0551 - mean_absolute_error: 0.7565 - val_loss: 1.3310 - val_mean_absolute_error: 0.8442\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0562 - mean_absolute_error: 0.7607 - val_loss: 1.3320 - val_mean_absolute_error: 0.8446\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0505 - mean_absolute_error: 0.7548 - val_loss: 1.3323 - val_mean_absolute_error: 0.8450\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0538 - mean_absolute_error: 0.7590 - val_loss: 1.3266 - val_mean_absolute_error: 0.8448\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0397 - mean_absolute_error: 0.7537 - val_loss: 1.3274 - val_mean_absolute_error: 0.8449\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0413 - mean_absolute_error: 0.7531 - val_loss: 1.3265 - val_mean_absolute_error: 0.8449\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0469 - mean_absolute_error: 0.7603 - val_loss: 1.3199 - val_mean_absolute_error: 0.8444\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0388 - mean_absolute_error: 0.7561 - val_loss: 1.3224 - val_mean_absolute_error: 0.8443\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0390 - mean_absolute_error: 0.7595 - val_loss: 1.3213 - val_mean_absolute_error: 0.8443\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0397 - mean_absolute_error: 0.7566 - val_loss: 1.3231 - val_mean_absolute_error: 0.8446\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0413 - mean_absolute_error: 0.7592 - val_loss: 1.3244 - val_mean_absolute_error: 0.8449\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0336 - mean_absolute_error: 0.7533 - val_loss: 1.3238 - val_mean_absolute_error: 0.8453\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0372 - mean_absolute_error: 0.7542 - val_loss: 1.3216 - val_mean_absolute_error: 0.8449\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0362 - mean_absolute_error: 0.7556 - val_loss: 1.3213 - val_mean_absolute_error: 0.8449\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0286 - mean_absolute_error: 0.7547 - val_loss: 1.3207 - val_mean_absolute_error: 0.8449\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0221 - mean_absolute_error: 0.7520 - val_loss: 1.3221 - val_mean_absolute_error: 0.8452\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 1.0382 - mean_absolute_error: 0.7593 - val_loss: 1.3219 - val_mean_absolute_error: 0.8452\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0184 - mean_absolute_error: 0.7502 - val_loss: 1.3246 - val_mean_absolute_error: 0.8456\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0240 - mean_absolute_error: 0.7533 - val_loss: 1.3268 - val_mean_absolute_error: 0.8460\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0344 - mean_absolute_error: 0.7593 - val_loss: 1.3278 - val_mean_absolute_error: 0.8461\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0239 - mean_absolute_error: 0.7509 - val_loss: 1.3278 - val_mean_absolute_error: 0.8458\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0278 - mean_absolute_error: 0.7592 - val_loss: 1.3286 - val_mean_absolute_error: 0.8461\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0292 - mean_absolute_error: 0.7571 - val_loss: 1.3317 - val_mean_absolute_error: 0.8465\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0272 - mean_absolute_error: 0.7557 - val_loss: 1.3338 - val_mean_absolute_error: 0.8469\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0279 - mean_absolute_error: 0.7587 - val_loss: 1.3362 - val_mean_absolute_error: 0.8477\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0263 - mean_absolute_error: 0.7576 - val_loss: 1.3265 - val_mean_absolute_error: 0.8469\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0238 - mean_absolute_error: 0.7559 - val_loss: 1.3316 - val_mean_absolute_error: 0.8473\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0278 - mean_absolute_error: 0.7553 - val_loss: 1.3225 - val_mean_absolute_error: 0.8465\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0221 - mean_absolute_error: 0.7570 - val_loss: 1.3203 - val_mean_absolute_error: 0.8463\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0201 - mean_absolute_error: 0.7586 - val_loss: 1.3235 - val_mean_absolute_error: 0.8469\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0180 - mean_absolute_error: 0.7590 - val_loss: 1.3133 - val_mean_absolute_error: 0.8455\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0191 - mean_absolute_error: 0.7561 - val_loss: 1.3020 - val_mean_absolute_error: 0.8442\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0226 - mean_absolute_error: 0.7637 - val_loss: 1.3029 - val_mean_absolute_error: 0.8442\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0192 - mean_absolute_error: 0.7529 - val_loss: 1.3064 - val_mean_absolute_error: 0.8446\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0107 - mean_absolute_error: 0.7532 - val_loss: 1.3068 - val_mean_absolute_error: 0.8445\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0007 - mean_absolute_error: 0.7522 - val_loss: 1.3073 - val_mean_absolute_error: 0.8446\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0189 - mean_absolute_error: 0.7571 - val_loss: 1.3083 - val_mean_absolute_error: 0.8447\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0132 - mean_absolute_error: 0.7548 - val_loss: 1.3088 - val_mean_absolute_error: 0.8446\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0139 - mean_absolute_error: 0.7573 - val_loss: 1.3120 - val_mean_absolute_error: 0.8447\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0118 - mean_absolute_error: 0.7552 - val_loss: 1.3159 - val_mean_absolute_error: 0.8451\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0048 - mean_absolute_error: 0.7553 - val_loss: 1.3237 - val_mean_absolute_error: 0.8463\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0096 - mean_absolute_error: 0.7521 - val_loss: 1.3288 - val_mean_absolute_error: 0.8471\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0109 - mean_absolute_error: 0.7574 - val_loss: 1.3248 - val_mean_absolute_error: 0.8467\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0143 - mean_absolute_error: 0.7553 - val_loss: 1.3288 - val_mean_absolute_error: 0.8473\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0023 - mean_absolute_error: 0.7523 - val_loss: 1.3385 - val_mean_absolute_error: 0.8487\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0019 - mean_absolute_error: 0.7525 - val_loss: 1.3410 - val_mean_absolute_error: 0.8490\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0022 - mean_absolute_error: 0.7534 - val_loss: 1.3385 - val_mean_absolute_error: 0.8488\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0026 - mean_absolute_error: 0.7536 - val_loss: 1.3377 - val_mean_absolute_error: 0.8488\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0078 - mean_absolute_error: 0.7564 - val_loss: 1.3407 - val_mean_absolute_error: 0.8494\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0040 - mean_absolute_error: 0.7546 - val_loss: 1.3417 - val_mean_absolute_error: 0.8494\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0084 - mean_absolute_error: 0.7551 - val_loss: 1.3401 - val_mean_absolute_error: 0.8494\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0119 - mean_absolute_error: 0.7591 - val_loss: 1.3441 - val_mean_absolute_error: 0.8497\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0081 - mean_absolute_error: 0.7552 - val_loss: 1.3429 - val_mean_absolute_error: 0.8498\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0055 - mean_absolute_error: 0.7542 - val_loss: 1.3384 - val_mean_absolute_error: 0.8498\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9962 - mean_absolute_error: 0.7519 - val_loss: 1.3388 - val_mean_absolute_error: 0.8498\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9965 - mean_absolute_error: 0.7546 - val_loss: 1.3342 - val_mean_absolute_error: 0.8491\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0067 - mean_absolute_error: 0.7576 - val_loss: 1.3337 - val_mean_absolute_error: 0.8492\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9985 - mean_absolute_error: 0.7524 - val_loss: 1.3204 - val_mean_absolute_error: 0.8482\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0020 - mean_absolute_error: 0.7545 - val_loss: 1.3251 - val_mean_absolute_error: 0.8484\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0141 - mean_absolute_error: 0.7570 - val_loss: 1.3048 - val_mean_absolute_error: 0.8463\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0122 - mean_absolute_error: 0.7616 - val_loss: 1.2921 - val_mean_absolute_error: 0.8447\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0041 - mean_absolute_error: 0.7552 - val_loss: 1.2968 - val_mean_absolute_error: 0.8457\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0049 - mean_absolute_error: 0.7583 - val_loss: 1.3017 - val_mean_absolute_error: 0.8460\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9894 - mean_absolute_error: 0.7508 - val_loss: 1.3072 - val_mean_absolute_error: 0.8470\n",
      "Epoch 261/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9948 - mean_absolute_error: 0.7551 - val_loss: 1.3096 - val_mean_absolute_error: 0.8474\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0054 - mean_absolute_error: 0.7563 - val_loss: 1.2992 - val_mean_absolute_error: 0.8462\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7527 - val_loss: 1.3032 - val_mean_absolute_error: 0.8466\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9795 - mean_absolute_error: 0.7480 - val_loss: 1.3092 - val_mean_absolute_error: 0.8471\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9968 - mean_absolute_error: 0.7541 - val_loss: 1.2995 - val_mean_absolute_error: 0.8460\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9976 - mean_absolute_error: 0.7561 - val_loss: 1.3021 - val_mean_absolute_error: 0.8472\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9990 - mean_absolute_error: 0.7557 - val_loss: 1.2996 - val_mean_absolute_error: 0.8466\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9972 - mean_absolute_error: 0.7530 - val_loss: 1.3019 - val_mean_absolute_error: 0.8473\n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7536 - val_loss: 1.2927 - val_mean_absolute_error: 0.8465\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7487 - val_loss: 1.2960 - val_mean_absolute_error: 0.8467\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9924 - mean_absolute_error: 0.7557 - val_loss: 1.2943 - val_mean_absolute_error: 0.8465\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9909 - mean_absolute_error: 0.7523 - val_loss: 1.2955 - val_mean_absolute_error: 0.8466\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9911 - mean_absolute_error: 0.7555 - val_loss: 1.2998 - val_mean_absolute_error: 0.8471\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0031 - mean_absolute_error: 0.7565 - val_loss: 1.3007 - val_mean_absolute_error: 0.8478\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9854 - mean_absolute_error: 0.7470 - val_loss: 1.2985 - val_mean_absolute_error: 0.8475\n",
      "Epoch 276/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9966 - mean_absolute_error: 0.7553 - val_loss: 1.3006 - val_mean_absolute_error: 0.8480\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9875 - mean_absolute_error: 0.7501 - val_loss: 1.3024 - val_mean_absolute_error: 0.8481\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9785 - mean_absolute_error: 0.7418 - val_loss: 1.3067 - val_mean_absolute_error: 0.8487\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0028 - mean_absolute_error: 0.7580 - val_loss: 1.2956 - val_mean_absolute_error: 0.8481\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7501 - val_loss: 1.2989 - val_mean_absolute_error: 0.8487\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9910 - mean_absolute_error: 0.7561 - val_loss: 1.3017 - val_mean_absolute_error: 0.8491\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9895 - mean_absolute_error: 0.7516 - val_loss: 1.2971 - val_mean_absolute_error: 0.8482\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9747 - mean_absolute_error: 0.7454 - val_loss: 1.3026 - val_mean_absolute_error: 0.8492\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9773 - mean_absolute_error: 0.7497 - val_loss: 1.2939 - val_mean_absolute_error: 0.8483\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9811 - mean_absolute_error: 0.7492 - val_loss: 1.2934 - val_mean_absolute_error: 0.8487\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9865 - mean_absolute_error: 0.7533 - val_loss: 1.2927 - val_mean_absolute_error: 0.8479\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9923 - mean_absolute_error: 0.7587 - val_loss: 1.2955 - val_mean_absolute_error: 0.8475\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9882 - mean_absolute_error: 0.7493 - val_loss: 1.2885 - val_mean_absolute_error: 0.8468\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7527 - val_loss: 1.2918 - val_mean_absolute_error: 0.8474\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9899 - mean_absolute_error: 0.7537 - val_loss: 1.2957 - val_mean_absolute_error: 0.8476\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9885 - mean_absolute_error: 0.7517 - val_loss: 1.2764 - val_mean_absolute_error: 0.8454\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9943 - mean_absolute_error: 0.7537 - val_loss: 1.2643 - val_mean_absolute_error: 0.8452\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.9962 - mean_absolute_error: 0.7559 - val_loss: 1.2670 - val_mean_absolute_error: 0.8457\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9929 - mean_absolute_error: 0.7558 - val_loss: 1.2704 - val_mean_absolute_error: 0.8471\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9916 - mean_absolute_error: 0.7562 - val_loss: 1.2761 - val_mean_absolute_error: 0.8478\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9890 - mean_absolute_error: 0.7585 - val_loss: 1.2743 - val_mean_absolute_error: 0.8481\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9816 - mean_absolute_error: 0.7517 - val_loss: 1.2739 - val_mean_absolute_error: 0.8479\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9877 - mean_absolute_error: 0.7518 - val_loss: 1.2777 - val_mean_absolute_error: 0.8486\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9825 - mean_absolute_error: 0.7519 - val_loss: 1.2835 - val_mean_absolute_error: 0.8490\n",
      "Epoch 300/500\n",
      "28/43 [==================>...........] - ETA: 0s - loss: 0.9725 - mean_absolute_error: 0.7515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m RNN_shallow_tuner_RS \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m      2\u001b[0m     build_model,\n\u001b[1;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m      5\u001b[0m     overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mRNN_shallow_tuner_RS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:1856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1842\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1843\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1855\u001b[0m     )\n\u001b[0;32m-> 1856\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1869\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1870\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1871\u001b[0m }\n\u001b[1;32m   1872\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:2296\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2294\u001b[0m             ):\n\u001b[1;32m   2295\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2296\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2297\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2298\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2303\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/keras/src/engine/training.py:4108\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4108\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4110\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/predicting_flight_traffic-wZNm__h8/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_RS = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_RS.search(train_rnn, epochs=500, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 08s]\n",
      "val_loss: 1.227628469467163\n",
      "\n",
      "Best val_loss So Far: 1.1422590017318726\n",
      "Total elapsed time: 00h 07m 13s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_BO = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    num_initial_points=2,\n",
    "    overwrite=True\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_BO.search(train_rnn, epochs=50, validation_data=val_rnn, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hyperparameters for shallow RNN using Hyperband tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 725 Complete [00h 00m 34s]\n",
      "val_loss: 1.2451832294464111\n",
      "\n",
      "Best val_loss So Far: 1.0942782163619995\n",
      "Total elapsed time: 07h 40m 01s\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_tuner_HB = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=600,\n",
    "    factor=3,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "RNN_shallow_tuner_HB.search(train_rnn, \n",
    "                            epochs=600, \n",
    "                            validation_data=val_rnn, \n",
    "                            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model weights and save the best shallow RNN model\n",
    "The Hyperband tuner produced the best model based on validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "43/43 [==============================] - 2s 9ms/step - loss: 1.9077 - mean_absolute_error: 0.9060 - val_loss: 1.6102 - val_mean_absolute_error: 0.8525\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3958 - mean_absolute_error: 0.7943 - val_loss: 1.7082 - val_mean_absolute_error: 0.8732\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1835 - mean_absolute_error: 0.7711 - val_loss: 1.3277 - val_mean_absolute_error: 0.8421\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1280 - mean_absolute_error: 0.7745 - val_loss: 1.1457 - val_mean_absolute_error: 0.8015\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0538 - mean_absolute_error: 0.7519 - val_loss: 1.3006 - val_mean_absolute_error: 0.8337\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0449 - mean_absolute_error: 0.7610 - val_loss: 1.3722 - val_mean_absolute_error: 0.8507\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0194 - mean_absolute_error: 0.7571 - val_loss: 1.3136 - val_mean_absolute_error: 0.8405\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0197 - mean_absolute_error: 0.7586 - val_loss: 1.4211 - val_mean_absolute_error: 0.8577\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0209 - mean_absolute_error: 0.7611 - val_loss: 1.2839 - val_mean_absolute_error: 0.8407\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0282 - mean_absolute_error: 0.7602 - val_loss: 1.6559 - val_mean_absolute_error: 0.8737\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0320 - mean_absolute_error: 0.7592 - val_loss: 1.4446 - val_mean_absolute_error: 0.8567\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0010 - mean_absolute_error: 0.7594 - val_loss: 1.3710 - val_mean_absolute_error: 0.8454\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.0042 - mean_absolute_error: 0.7577 - val_loss: 1.2030 - val_mean_absolute_error: 0.8310\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0076 - mean_absolute_error: 0.7594 - val_loss: 1.3729 - val_mean_absolute_error: 0.8553\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7576 - val_loss: 1.2823 - val_mean_absolute_error: 0.8451\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0010 - mean_absolute_error: 0.7632 - val_loss: 1.2467 - val_mean_absolute_error: 0.8377\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9953 - mean_absolute_error: 0.7504 - val_loss: 1.3444 - val_mean_absolute_error: 0.8467\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9910 - mean_absolute_error: 0.7517 - val_loss: 1.3334 - val_mean_absolute_error: 0.8527\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9882 - mean_absolute_error: 0.7593 - val_loss: 1.3639 - val_mean_absolute_error: 0.8475\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9834 - mean_absolute_error: 0.7471 - val_loss: 1.2822 - val_mean_absolute_error: 0.8402\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0009 - mean_absolute_error: 0.7593 - val_loss: 1.2243 - val_mean_absolute_error: 0.8306\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9989 - mean_absolute_error: 0.7597 - val_loss: 1.2742 - val_mean_absolute_error: 0.8417\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7497 - val_loss: 1.3250 - val_mean_absolute_error: 0.8499\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9949 - mean_absolute_error: 0.7557 - val_loss: 1.3276 - val_mean_absolute_error: 0.8348\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9920 - mean_absolute_error: 0.7535 - val_loss: 1.3549 - val_mean_absolute_error: 0.8423\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9926 - mean_absolute_error: 0.7559 - val_loss: 1.5073 - val_mean_absolute_error: 0.8591\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7461 - val_loss: 1.2561 - val_mean_absolute_error: 0.8300\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9933 - mean_absolute_error: 0.7580 - val_loss: 1.1956 - val_mean_absolute_error: 0.8384\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9971 - mean_absolute_error: 0.7483 - val_loss: 1.2734 - val_mean_absolute_error: 0.8441\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9947 - mean_absolute_error: 0.7608 - val_loss: 1.1871 - val_mean_absolute_error: 0.8148\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9814 - mean_absolute_error: 0.7463 - val_loss: 1.2507 - val_mean_absolute_error: 0.8313\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9924 - mean_absolute_error: 0.7499 - val_loss: 1.3397 - val_mean_absolute_error: 0.8515\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9809 - mean_absolute_error: 0.7558 - val_loss: 1.3108 - val_mean_absolute_error: 0.8442\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9724 - mean_absolute_error: 0.7470 - val_loss: 1.2937 - val_mean_absolute_error: 0.8381\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9832 - mean_absolute_error: 0.7461 - val_loss: 1.3305 - val_mean_absolute_error: 0.8528\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9965 - mean_absolute_error: 0.7524 - val_loss: 1.3085 - val_mean_absolute_error: 0.8503\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9800 - mean_absolute_error: 0.7528 - val_loss: 1.3288 - val_mean_absolute_error: 0.8572\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9731 - mean_absolute_error: 0.7458 - val_loss: 1.3121 - val_mean_absolute_error: 0.8347\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9960 - mean_absolute_error: 0.7594 - val_loss: 1.3154 - val_mean_absolute_error: 0.8518\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9916 - mean_absolute_error: 0.7618 - val_loss: 1.3504 - val_mean_absolute_error: 0.8490\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9913 - mean_absolute_error: 0.7503 - val_loss: 1.3508 - val_mean_absolute_error: 0.8466\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9917 - mean_absolute_error: 0.7552 - val_loss: 1.3175 - val_mean_absolute_error: 0.8467\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9642 - mean_absolute_error: 0.7410 - val_loss: 1.3192 - val_mean_absolute_error: 0.8347\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9900 - mean_absolute_error: 0.7556 - val_loss: 1.3719 - val_mean_absolute_error: 0.8492\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9879 - mean_absolute_error: 0.7443 - val_loss: 1.3907 - val_mean_absolute_error: 0.8565\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9812 - mean_absolute_error: 0.7491 - val_loss: 1.3988 - val_mean_absolute_error: 0.8590\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9873 - mean_absolute_error: 0.7471 - val_loss: 1.4085 - val_mean_absolute_error: 0.8489\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9871 - mean_absolute_error: 0.7521 - val_loss: 1.4225 - val_mean_absolute_error: 0.8571\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9848 - mean_absolute_error: 0.7475 - val_loss: 1.3486 - val_mean_absolute_error: 0.8552\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9950 - mean_absolute_error: 0.7573 - val_loss: 1.2066 - val_mean_absolute_error: 0.8389\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.9786 - mean_absolute_error: 0.7450 - val_loss: 1.2899 - val_mean_absolute_error: 0.8505\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9826 - mean_absolute_error: 0.7497 - val_loss: 1.3009 - val_mean_absolute_error: 0.8481\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9727 - mean_absolute_error: 0.7483 - val_loss: 1.4481 - val_mean_absolute_error: 0.8668\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9933 - mean_absolute_error: 0.7531 - val_loss: 1.4069 - val_mean_absolute_error: 0.8549\n",
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/flights_ontime/RNN_shallow_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Get best hyperparameters\n",
    "best_hps = RNN_shallow_tuner_HB.get_best_hyperparameters(num_trials=1)[0]\n",
    "RNN_shallow_model = RNN_shallow_tuner_HB.hypermodel.build(best_hps)\n",
    "\n",
    "# TensorBoard setup\n",
    "!rm -rf ./logs/flights_ontime/RNN_shallow/tensorboard/\n",
    "log_dir = \"logs/flights_ontime/RNN_shallow/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = RNN_shallow_model.fit(train_rnn, \n",
    "                    validation_data=val_rnn, \n",
    "                    epochs=500, \n",
    "                    callbacks=[early_stopping, tensorboard_callback])\n",
    "\n",
    "# Save the best trained model\n",
    "RNN_shallow_model.save('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6013 (pid 49139), started 0:02:24 ago. (Use '!kill 49139' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-19c2c908334d8da9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-19c2c908334d8da9\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/flights_ontime/RNN_shallow/tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best shallow RNN model (from Hyperband tuner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "RNN_shallow_model = models.load_model('models/flights_ontime/RNN_shallow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best shallow RNN model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "- Number of Hidden Layers: 1\n",
      "- Number of Neurons: 14\n",
      "- Learning Rate: 0.006576617683751118\n",
      "- Dropout Rate: 0.24480591203927254\n",
      "- Recurrent Dropout Rate: 0.35738857946677854\n",
      "- Kernel Regularization: 0.0010046913205416215\n",
      "- Recurrent Regularization: 0.04379999321621059\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print(f\"\"\"Best Hyperparameters:\n",
    "- Number of Hidden Layers: {best_hps.get('n_hidden')}\n",
    "- Number of Neurons: {best_hps.get('n_neurons')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Recurrent Dropout Rate: {best_hps.get('recurrent_dropout_rate')}\n",
    "- Kernel Regularization: {best_hps.get('kernel_reg')}\n",
    "- Recurrent Regularization: {best_hps.get('recurr_reg')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_4 (Dropout)         (None, None, 75)          0         \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 14)                1260      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1275 (4.98 KB)\n",
      "Trainable params: 1275 (4.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN_shallow_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the best shallow RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 934us/step\n",
      "Validation Metrics:\n",
      "- Validation MAE: 250.52\n",
      "- Validation MSE: 113235.65\n",
      "- Validation R^2: -0.090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = RNN_shallow_model.predict(val_rnn)\n",
    "y_pred_inv = global_targer_scaler.inverse_transform(y_pred)\n",
    "y_val_inv = global_targer_scaler.inverse_transform(y_val_rnn[seq_length-1:])\n",
    "\n",
    "shallow_rnn_val_mae = mean_absolute_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_mse = mean_squared_error(y_val_inv, y_pred_inv)\n",
    "shallow_rnn_val_r2 = r2_score(y_val_inv, y_pred_inv)\n",
    "\n",
    "print(f\"\"\"Validation Metrics:\n",
    "- Validation MAE: {shallow_rnn_val_mae:.2f}\n",
    "- Validation MSE: {shallow_rnn_val_mse:.2f}\n",
    "- Validation R^2: {shallow_rnn_val_r2:.3f}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TYPE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the Elastic Net metrics\n",
    "EN_data = pd.read_csv(\"model_output/elastic_net_results.csv\")\n",
    "LR_mae = EN_data.loc[EN_data['TARGET'] == 'flights_ontime', 'MAE'].values[0]\n",
    "LR_mse = EN_data.loc[EN_data['TARGET'] == 'flights_ontime', 'MSE'].values[0]\n",
    "\n",
    "models = ['Linear Reg', 'One Neuron', 'Shallow NN', 'One RN', 'Shallow RNN']\n",
    "mae = [LR_mae, OneNeuron_val_mae, SDNN_val_mae,  OneRNN_val_mae, shallow_rnn_val_mae]\n",
    "mse = [LR_mse, OneNeuron_val_mse, SDNN_val_mse, OneRNN_val_mse, shallow_rnn_val_mse]\n",
    "\n",
    "# Sort by MAE\n",
    "sorted_indices_mae = np.argsort(mae)\n",
    "sorted_models_mae = [models[i] for i in sorted_indices_mae]\n",
    "sorted_mae = [mae[i] for i in sorted_indices_mae]\n",
    "\n",
    "# Sort by MSE\n",
    "sorted_indices_mse = np.argsort(mse)\n",
    "sorted_models_mse = [models[i] for i in sorted_indices_mse]\n",
    "sorted_mse = [mse[i] for i in sorted_indices_mse]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "bar_width = 0.35\n",
    "\n",
    "fix, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "\n",
    "# MAE\n",
    "bars_mae = axes[0].bar(x, sorted_mae, bar_width, label='MAE')\n",
    "axes[0].set_xlabel('Models')\n",
    "axes[0].set_ylabel('MAE Scores')\n",
    "axes[0].set_title('MAE Scores by model')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(sorted_models_mae)\n",
    "axes[0].legend()\n",
    "\n",
    "# Add values above MAE bars\n",
    "for bar, value in zip(bars_mae, sorted_mae):\n",
    "    height = bar.get_height()\n",
    "    axes[0].text(bar.get_x() + bar.get_width() / 2, height + 0.01, f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "# MSE\n",
    "bar_mse = axes[1].bar(x, sorted_mse, bar_width, label='MSE')\n",
    "axes[1].set_xlabel('Models')\n",
    "axes[1].set_ylabel('MSE Scores')\n",
    "axes[1].set_title('MSE Scores by model')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(sorted_models_mse)\n",
    "axes[1].legend()\n",
    "\n",
    "# Add values above MSE bars\n",
    "for bar, value in zip(bar_mse, sorted_mse):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width() / 2, height + 0.01, f'{value:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "4. change filenames \n",
    "5. push to github\n",
    "6. write up analysis\n",
    "7. submit to coursera\n",
    "\n",
    "## After submission\n",
    "8. add XGBoost or Adaboost\n",
    "9. update the raw data (selenium)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-rTmYhf-l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
